<!DOCTYPE html>



  


<html class="theme-next muse use-motion" lang="zh-Hans">
<head><meta name="generator" content="Hexo 3.9.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/favicon.ico?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon.ico?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon.ico?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="redis,">










<meta name="description" content="要掌握的很好的，就是redis架构 安装一个虚拟机集群 安装redis集群 配置持久化 RDB 快照手动设置检查点（etc/redis/redis.conf 里面可以修改save）    高并发，高可用，海量数据，备份，随时可以恢复， redis架构，每秒钟几十万的访问量QPS，99.99%的高可用性，TB级的海量数据，备份和恢复，缓存架构就成功了一半。最最简单的模式，无非就是存取redis，存数">
<meta name="keywords" content="redis">
<meta property="og:type" content="article">
<meta property="og:title" content="redis详解、">
<meta property="og:url" content="http://yoursite.com/2019/10/01/redis详解、/index.html">
<meta property="og:site_name" content="ddd `Blog">
<meta property="og:description" content="要掌握的很好的，就是redis架构 安装一个虚拟机集群 安装redis集群 配置持久化 RDB 快照手动设置检查点（etc/redis/redis.conf 里面可以修改save）    高并发，高可用，海量数据，备份，随时可以恢复， redis架构，每秒钟几十万的访问量QPS，99.99%的高可用性，TB级的海量数据，备份和恢复，缓存架构就成功了一半。最最简单的模式，无非就是存取redis，存数">
<meta property="og:locale" content="zh-Hans">
<meta property="og:updated_time" content="2019-10-01T09:54:07.877Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="redis详解、">
<meta name="twitter:description" content="要掌握的很好的，就是redis架构 安装一个虚拟机集群 安装redis集群 配置持久化 RDB 快照手动设置检查点（etc/redis/redis.conf 里面可以修改save）    高并发，高可用，海量数据，备份，随时可以恢复， redis架构，每秒钟几十万的访问量QPS，99.99%的高可用性，TB级的海量数据，备份和恢复，缓存架构就成功了一半。最最简单的模式，无非就是存取redis，存数">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":true,"scrollpercent":true,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/2019/10/01/redis详解、/">





  <title>redis详解、 | ddd `Blog</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">ddd `Blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">czt的博客</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br>
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br>
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            归档
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br>
            
            搜索
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off" placeholder="搜索..." spellcheck="false" type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/10/01/redis详解、/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Chen ZeTao">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/weixin.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="ddd `Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">redis详解、</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-10-01T17:52:57+08:00">
                2019-10-01
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          
            <span class="post-meta-divider">|</span>
            <span class="page-pv"><i class="fa fa-eye"></i> 阅读次数
            <span class="busuanzi-value" id="busuanzi_value_page_pv"></span>
            </span>
          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  14.5k
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  53
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <h3 id="要掌握的很好的，就是redis架构"><a href="#要掌握的很好的，就是redis架构" class="headerlink" title="要掌握的很好的，就是redis架构"></a>要掌握的很好的，就是redis架构</h3><ul>
<li>安装一个虚拟机集群</li>
<li>安装redis集群</li>
<li>配置持久化<ul>
<li>RDB 快照手动设置检查点（etc/redis/redis.conf 里面可以修改save）</li>
</ul>
</li>
</ul>
<p>高并发，高可用，海量数据，备份，随时可以恢复，</p>
<p>redis架构，每秒钟几十万的访问量QPS，99.99%的高可用性，TB级的海量数据，备份和恢复，缓存架构就成功了一半。最最简单的模式，无非就是存取redis，存数据，取数据。解决各种各样的高并发下缓存面临的难题，缓存架构中不断引入各种解决方案和技术，解决高并发的问题。</p>
<ol>
<li>搭建redis集群，从0开始，一步一步搭建一个4个结点的Centos集群。安装4台虚拟机<ul>
<li>在hosts文件下,配置好所有的机器的ip地址到hostname的映射关系</li>
<li>使用ssh配置每台机器之间免密登录</li>
</ul>
</li>
<li>make install </li>
<li>要把redis作为一个系统的daemon进程去运行，每次系统启动，redis进程一起启动</li>
</ol>
<p>如果没有持久化的话，redis遇到灾难性故障的时候，就会丢失所有的数据</p>
<p>如果通过持久化将数据搞一份儿在磁盘上去，然后定期比如说同步和备份到一些云存储服务上去，那么就可以保证数据不丢失全部，还是可以恢复一部分数据回来的。redis如果单单把数据放在内存中，是没有任何方法应对一些灾难性的工作的，redis 在启动会自动从磁盘中恢复数据到内存中。</p>
<h3 id="redis-持久化RDB-AOF利弊比较"><a href="#redis-持久化RDB-AOF利弊比较" class="headerlink" title="redis 持久化RDB,AOF利弊比较"></a>redis 持久化RDB,AOF利弊比较</h3><p>比如你redis整个挂了，然后redis就不可用了，你要做的事情是让redis变得可用，尽快变得可用</p>
<p>重启redis，尽快让它对外提供服务，但是就像上一讲说，如果你没做数据备份，这个时候redis启动了，也不可用啊，数据都没了</p>
<p>很可能说，大量的请求过来，缓存全部无法命中，在redis里根本找不到数据，这个时候就死定了，缓存雪崩问题，所有请求，没有在redis命中，就会去mysql数据库这种数据源头中去找，一下子mysql承接高并发，然后就挂了</p>
<p>mysql挂掉，你都没法去找数据恢复到redis里面去，redis的数据从哪儿来？从mysql来。。。</p>
<p>具体的完整的缓存雪崩的场景，还有企业级的解决方案，到后面讲</p>
<p>如果你把redis的持久化做好，备份和恢复方案做到企业级的程度，那么即使你的redis故障了，也可以通过备份数据，快速恢复，一旦恢复立即对外提供服务</p>
<p>redis的持久化，跟高可用，是有关系的，企业级redis架构中去讲解</p>
<p>redis持久化：RDB，AOF</p>
<hr>
<p>1、RDB和AOF两种持久化机制的介绍</p>
<p>RDB持久化机制，对redis中的数据执行周期性的持久化</p>
<p>AOF机制对每条写入命令作为日志，以append-only的模式写入一个日志文件中，在redis重启的时候，可以通过回放AOF日志中的写入指令来重新构建整个数据集</p>
<p>如果我们想要redis仅仅作为纯内存的缓存来用，那么可以禁止RDB和AOF所有的持久化机制</p>
<p>通过RDB或AOF，都可以将redis内存中的数据给持久化到磁盘上面来，然后可以将这些数据备份到别的地方去，比如说阿里云，云服务</p>
<p>如果redis挂了，服务器上的内存和磁盘上的数据都丢了，可以从云服务上拷贝回来之前的数据，放到指定的目录中，然后重新启动redis，redis就会自动根据持久化数据文件中的数据，去恢复内存中的数据，继续对外提供服务</p>
<p>如果同时使用RDB和AOF两种持久化机制，那么在redis重启的时候，会使用AOF来重新构建数据，因为AOF中的数据更加完整</p>
<hr>
<p>2、RDB持久化机制的优点</p>
<p>（1）RDB会生成多个数据文件，每个数据文件都代表了某一个时刻中redis的数据，这种多个数据文件的方式，非常适合做冷备，可以将这种完整的数据文件发送到一些远程的安全存储上去，比如说Amazon的S3云服务上去，在国内可以是阿里云的ODPS分布式存储上，以预定好的备份策略来定期备份redis中的数据</p>
<p>（2）RDB对redis对外提供的读写服务，影响非常小，可以让redis保持高性能，因为redis主进程只需要fork一个子进程，让子进程执行磁盘IO操作来进行RDB持久化即可</p>
<p>（3）相对于AOF持久化机制来说，直接基于RDB数据文件来重启和恢复redis进程，更加快速</p>
<hr>
<p>3、RDB持久化机制的缺点</p>
<p>（1）如果想要在redis故障时，尽可能少的丢失数据，那么RDB没有AOF好。一般来说，RDB数据快照文件，都是每隔5分钟，或者更长时间生成一次，这个时候就得接受一旦redis进程宕机，那么会丢失最近5分钟的数据</p>
<p>（2）RDB每次在fork子进程来执行RDB快照数据文件生成的时候，如果数据文件特别大，可能会导致对客户端提供的服务暂停数毫秒，或者甚至数秒</p>
<hr>
<p>4、AOF持久化机制的优点</p>
<p>（1）AOF可以更好的保护数据不丢失，一般AOF会每隔1秒，通过一个后台线程执行一次fsync操作，最多丢失1秒钟的数据</p>
<p>（2）AOF日志文件以append-only模式写入，所以没有任何磁盘寻址的开销，写入性能非常高，而且文件不容易破损，即使文件尾部破损，也很容易修复</p>
<p>（3）AOF日志文件即使过大的时候，出现后台重写操作，也不会影响客户端的读写。因为在rewrite log的时候，会对其中的指导进行压缩，创建出一份需要恢复数据的最小日志出来。再创建新日志文件的时候，老的日志文件还是照常写入。当新的merge后的日志文件ready的时候，再交换新老日志文件即可。</p>
<p>（4）AOF日志文件的命令通过非常可读的方式进行记录，这个特性非常适合做灾难性的误删除的紧急恢复。比如某人不小心用flushall命令清空了所有数据，只要这个时候后台rewrite还没有发生，那么就可以立即拷贝AOF文件，将最后一条flushall命令给删了，然后再将该AOF文件放回去，就可以通过恢复机制，自动恢复所有数据</p>
<hr>
<p>5、AOF持久化机制的缺点</p>
<p>（1）对于同一份数据来说，AOF日志文件通常比RDB数据快照文件更大</p>
<p>（2）AOF开启后，支持的写QPS会比RDB支持的写QPS低，因为AOF一般会配置成每秒fsync一次日志文件，当然，每秒一次fsync，性能也还是很高的</p>
<p>（3）以前AOF发生过bug，就是通过AOF记录的日志，进行数据恢复的时候，没有恢复一模一样的数据出来。所以说，类似AOF这种较为复杂的基于命令日志/merge/回放的方式，比基于RDB每次持久化一份完整的数据快照文件的方式，更加脆弱一些，容易有bug。不过AOF就是为了避免rewrite过程导致的bug，因此每次rewrite并不是基于旧的指令日志进行merge的，而是基于当时内存中的数据进行指令的重新构建，这样健壮性会好很多。</p>
<hr>
<p>6、RDB和AOF到底该如何选择</p>
<p>（1）不要仅仅使用RDB，因为那样会导致你丢失很多数据</p>
<p>（2）也不要仅仅使用AOF，因为那样有两个问题，第一，你通过AOF做冷备，没有RDB做冷备，来的恢复速度更快; 第二，RDB每次简单粗暴生成数据快照，更加健壮，可以避免AOF这种复杂的备份和恢复机制的bug</p>
<p>（3）综合使用AOF和RDB两种持久化机制，用AOF来保证数据不丢失，作为数据恢复的第一选择; 用RDB来做不同程度的冷备，在AOF文件都丢失或损坏不可用的时候，还可以使用RDB来进行快速的数据恢复</p>
<h3 id="RDB持久化详解"><a href="#RDB持久化详解" class="headerlink" title="RDB持久化详解"></a>RDB持久化详解</h3><p>1、如何配置RDB持久化机制<br>2、RDB持久化机制的工作流程<br>3、基于RDB持久化机制的数据恢复实验</p>
<hr>
<p>1、如何配置RDB持久化机制</p>
<p>redis.conf文件，也就是/etc/redis/6379.conf，去配置持久化</p>
<p>save 60 1000</p>
<p>每隔60s，如果有超过1000个key发生了变更，那么就生成一个新的dump.rdb文件，就是当前redis内存中完整的数据快照，这个操作也被称之为snapshotting，快照</p>
<p>也可以手动调用save或者bgsave命令，同步或异步执行rdb快照生成</p>
<p>save可以设置多个，就是多个snapshotting检查点，每到一个检查点，就会去check一下，是否有指定的key数量发生了变更，如果有，就生成一个新的dump.rdb文件</p>
<hr>
<p>2、RDB持久化机制的工作流程</p>
<p>（1）redis根据配置自己尝试去生成rdb快照文件<br>（2）fork一个子进程出来<br>（3）子进程尝试将数据dump到临时的rdb快照文件中<br>（4）完成rdb快照文件的生成之后，就替换之前的旧的快照文件</p>
<p>dump.rdb，每次生成一个新的快照，都会覆盖之前的老快照</p>
<hr>
<p>3、基于RDB持久化机制的数据恢复实验</p>
<p>（1）在redis中保存几条数据，立即停掉redis进程，然后重启redis，看看刚才插入的数据还在不在</p>
<p>数据还在，为什么？</p>
<p>带出来一个知识点，通过redis-cli SHUTDOWN这种方式去停掉redis，其实是一种安全退出的模式，redis在退出的时候会将内存中的数据立即生成一份完整的rdb快照</p>
<p>/var/redis/6379/dump.rdb</p>
<p>（2）在redis中再保存几条新的数据，用kill -9粗暴杀死redis进程，模拟redis故障异常退出，导致内存数据丢失的场景</p>
<p>这次就发现，redis进程异常被杀掉，数据没有进dump文件，几条最新的数据就丢失了</p>
<p>（2）手动设置一个save检查点，save 5 1<br>（3）写入几条数据，等待5秒钟，会发现自动进行了一次dump rdb快照，在dump.rdb中发现了数据<br>（4）异常停掉redis进程，再重新启动redis，看刚才插入的数据还在</p>
<p>rdb的手动配置检查点，以及rdb快照的生成，包括数据的丢失和恢复，全都演示过了</p>
<h3 id="AOF持久化详解"><a href="#AOF持久化详解" class="headerlink" title="AOF持久化详解"></a>AOF持久化详解</h3><p>1、AOF持久化的配置<br>2、AOF持久化的数据恢复实验<br>3、AOF rewrite<br>4、AOF破损文件的修复<br>5、AOF和RDB同时工作</p>
<hr>
<p>1、AOF持久化的配置</p>
<p>AOF持久化，默认是关闭的，默认是打开RDB持久化</p>
<p>appendonly yes，可以打开AOF持久化机制，在生产环境里面，一般来说AOF都是要打开的，除非你说随便丢个几分钟的数据也无所谓。<br>如果开启AOF，就算没有AOF文件，redis在重启时，也会创建一个新的空的AOF文件恢复数据，在这个时候就需要先关闭AOF，拷贝dump.rdb恢复redis先，接着应该直接在命令行热修改redis配置，打开AOF。此时磁盘上的配置文件还是no（关闭）的，还需要在磁盘上将AOF打开。</p>
<p>AOF append-only ，顺序写入，如果AOF文件破损，那么用redis-check-aof fix修复文件<br>打开AOF持久化机制之后，redis每次接收到一条写命令，就会写入日志文件中，当然是先写入os cache的，然后每隔一定时间再fsync一下</p>
<p>而且即使AOF和RDB都开启了，redis重启的时候，也是优先通过AOF进行数据恢复的，因为aof数据比较完整</p>
<p>可以配置AOF的fsync策略，有三种策略可以选择，一种是每次写入一条数据就执行一次fsync; 一种是每隔一秒执行一次fsync; 一种是不主动执行fsync</p>
<p>always: 每次写入一条数据，立即将这个数据对应的写日志fsync到磁盘上去，性能非常非常差，吞吐量很低; 确保说redis里的数据一条都不丢，那就只能这样了</p>
<p>mysql -&gt; 内存策略，大量磁盘，QPS到多少，一两k。QPS，每秒钟的请求数量<br>redis -&gt; 内存，磁盘持久化，QPS到多少，单机，一般来说，上万QPS没问题</p>
<p>everysec: 每秒将os cache中的数据fsync到磁盘，这个最常用的，生产环境一般都这么配置，性能很高，QPS还是可以上万的</p>
<p>no: 仅仅redis负责将数据写入os cache就撒手不管了，然后后面os自己会时不时有自己的策略将数据刷入磁盘，不可控了</p>
<hr>
<p>2、AOF持久化的数据恢复实验</p>
<p>（1）先仅仅打开RDB，写入一些数据，然后kill -9杀掉redis进程，接着重启redis，发现数据没了，因为RDB快照还没生成<br>（2）打开AOF的开关，启用AOF持久化<br>（3）写入一些数据，观察AOF文件中的日志内容</p>
<p>其实你在appendonly.aof文件中，可以看到刚写的日志，它们其实就是先写入os cache的，然后1秒后才fsync到磁盘中，只有fsync到磁盘中了，才是安全的，要不然光是在os cache中，机器只要重启，就什么都没了</p>
<p>（4）kill -9杀掉redis进程，重新启动redis进程，发现数据被恢复回来了，就是从AOF文件中恢复回来的</p>
<p>redis进程启动的时候，直接就会从appendonly.aof中加载所有的日志，把内存中的数据恢复回来</p>
<hr>
<p>3、AOF rewrite</p>
<p>redis中的数据其实有限的，很多数据可能会自动过期，可能会被用户删除，可能会被redis用缓存清除的算法清理掉</p>
<p>redis中的数据会不断淘汰掉旧的，就一部分常用的数据会被自动保留在redis内存中</p>
<p>所以可能很多之前的已经被清理掉的数据，对应的写日志还停留在AOF中，AOF日志文件就一个，会不断的膨胀，到很大很大</p>
<p>所以AOF会自动在后台每隔一定时间做rewrite操作，比如日志里已经存放了针对100w数据的写日志了; redis内存只剩下10万; 基于内存中当前的10万数据构建一套最新的日志，到AOF中; 覆盖之前的老日志; 确保AOF日志文件不会过大，保持跟redis内存数据量一致</p>
<p>redis 2.4之前，还需要手动，开发一些脚本，crontab，通过BGREWRITEAOF命令去执行AOF rewrite，但是redis 2.4之后，会自动进行rewrite操作</p>
<p>在redis.conf中，可以配置rewrite策略</p>
<p>auto-aof-rewrite-percentage 100<br>auto-aof-rewrite-min-size 64mb</p>
<p>比如说上一次AOF rewrite之后，是128mb</p>
<p>然后就会接着128mb继续写AOF的日志，如果发现增长的比例，超过了之前的100%，256mb，就可能会去触发一次rewrite</p>
<p>但是此时还要去跟min-size，64mb去比较，256mb &gt; 64mb，才会去触发rewrite</p>
<p>（1）redis fork一个子进程<br>（2）子进程基于当前内存中的数据，构建日志，开始往一个新的临时的AOF文件中写入日志<br>（3）redis主进程，接收到client新的写操作之后，在内存中写入日志，同时新的日志也继续写入旧的AOF文件<br>（4）子进程写完新的日志文件之后，redis主进程将内存中的新日志再次追加到新的AOF文件中<br>（5）用新的日志文件替换掉旧的日志文件</p>
<hr>
<p>4、AOF破损文件的修复</p>
<p>如果redis在append数据到AOF文件时，机器宕机了，可能会导致AOF文件破损</p>
<p>用redis-check-aof –fix命令来修复破损的AOF文件</p>
<hr>
<p>5、AOF和RDB同时工作</p>
<p>（1）如果RDB在执行snapshotting操作，那么redis不会执行AOF rewrite; 如果redis再执行AOF rewrite，那么就不会执行RDB snapshotting<br>（2）如果RDB在执行snapshotting，此时用户执行BGREWRITEAOF命令，那么等RDB快照生成之后，才会去执行AOF rewrite<br>（3）同时有RDB snapshot文件和AOF日志文件，那么redis重启的时候，会优先使用AOF进行数据恢复，因为其中的日志更完整</p>
<hr>
<p>6、最后一个小实验，让大家对redis的数据恢复有更加深刻的体会</p>
<p>（1）在有rdb的dump和aof的appendonly的同时，rdb里也有部分数据，aof里也有部分数据，这个时候其实会发现，rdb的数据不会恢复到内存中<br>（2）我们模拟让aof破损，然后fix，有一条数据会被fix删除<br>（3）再次用fix得aof文件去重启redis，发现数据只剩下一条了</p>
<p>数据恢复完全是依赖于底层的磁盘的持久化的，主要rdb和aof上都没有数据，那就没了</p>
<h1 id="9-29"><a href="#9-29" class="headerlink" title="9.29"></a>9.29</h1><h3 id="redis在企业级数据备份方案以及数据恢复负灾演练"><a href="#redis在企业级数据备份方案以及数据恢复负灾演练" class="headerlink" title="redis在企业级数据备份方案以及数据恢复负灾演练"></a>redis在企业级数据备份方案以及数据恢复负灾演练</h3><p>到这里为止，其实还是停留在简单学习知识的程度，学会了redis的持久化的原理和操作，但是在企业中，持久化到底是怎么去用得呢？</p>
<p>企业级的数据备份和各种灾难下的数据恢复，是怎么做得呢？</p>
<p>1、企业级的持久化的配置策略</p>
<p>在企业中，RDB的生成策略，用默认的也差不多</p>
<p>save 60 10000：如果你希望尽可能确保说，RDB最多丢1分钟的数据，那么尽量就是每隔1分钟都生成一个快照，低峰期，数据量很少，也没必要</p>
<p>10000-&gt;生成RDB，1000-&gt;RDB，这个根据你自己的应用和业务的数据量，你自己去决定</p>
<p>AOF一定要打开，fsync，everysec</p>
<p>auto-aof-rewrite-percentage 100: 就是当前AOF大小膨胀到超过上次100%，上次的两倍<br>auto-aof-rewrite-min-size 64mb: 根据你的数据量来定，16mb，32mb</p>
<p>2、企业级的数据备份方案</p>
<p>RDB非常适合做冷备，每次生成之后，就不会再有修改了</p>
<p>数据备份方案</p>
<p>（1）写crontab定时调度脚本去做数据备份<br>（2）每小时都copy一份rdb的备份，到一个目录中去，仅仅保留最近48小时的备份<br>（3）每天都保留一份当日的rdb的备份，到一个目录中去，仅仅保留最近1个月的备份<br>（4）每次copy备份的时候，都把太旧的备份给删了<br>（5）每天晚上将当前服务器上所有的数据备份，发送一份到远程的云服务上去</p>
<p>/usr/local/redis</p>
<p>每小时copy一次备份，删除48小时前的数据</p>
<p>crontab -e</p>
<p>0 <em> </em> <em> </em> sh /usr/local/redis/copy/redis_rdb_copy_hourly.sh</p>
<p>redis_rdb_copy_hourly.sh</p>
<p>#!/bin/sh </p>
<p>cur_date=<code>date +%Y%m%d%k</code><br>rm -rf /usr/local/redis/snapshotting/$cur_date<br>mkdir /usr/local/redis/snapshotting/$cur_date<br>cp /var/redis/6379/dump.rdb /usr/local/redis/snapshotting/$cur_date</p>
<p>del_date=<code>date -d -48hour +%Y%m%d%k</code><br>rm -rf /usr/local/redis/snapshotting/$del_date</p>
<p>每天copy一次备份</p>
<p>crontab -e</p>
<p>0 0 <em> </em> * sh /usr/local/redis/copy/redis_rdb_copy_daily.sh</p>
<p>redis_rdb_copy_daily.sh</p>
<p>#!/bin/sh </p>
<p>cur_date=<code>date +%Y%m%d</code><br>rm -rf /usr/local/redis/snapshotting/$cur_date<br>mkdir /usr/local/redis/snapshotting/$cur_date<br>cp /var/redis/6379/dump.rdb /usr/local/redis/snapshotting/$cur_date</p>
<p>del_date=<code>date -d -1month +%Y%m%d</code><br>rm -rf /usr/local/redis/snapshotting/$del_date</p>
<p>每天一次将所有数据上传一次到远程的云服务器上去</p>
<p>3、数据恢复方案</p>
<p>（1）如果是redis进程挂掉，那么重启redis进程即可，直接基于AOF日志文件恢复数据</p>
<p>不演示了，在AOF数据恢复那一块，演示了，fsync everysec，最多就丢一秒的数</p>
<p>（2）如果是redis进程所在机器挂掉，那么重启机器后，尝试重启redis进程，尝试直接基于AOF日志文件进行数据恢复</p>
<p>AOF没有破损，也是可以直接基于AOF恢复的</p>
<p>AOF append-only，顺序写入，如果AOF文件破损，那么用redis-check-aof fix</p>
<p>（3）如果redis当前最新的AOF和RDB文件出现了丢失/损坏，那么可以尝试基于该机器上当前的某个最新的RDB数据副本进行数据恢复</p>
<p>当前最新的AOF和RDB文件都出现了丢失/损坏到无法恢复，一般不是机器的故障，人为</p>
<p>大数据系统，hadoop，有人不小心就把hadoop中存储的大量的数据文件对应的目录，rm -rf一下，我朋友的一个小公司，运维不太靠谱，权限也弄的不太好</p>
<p>/var/redis/6379下的文件给删除了</p>
<p>找到RDB最新的一份备份，小时级的备份可以了，小时级的肯定是最新的，copy到redis里面去，就可以恢复到某一个小时的数据</p>
<p>容灾演练</p>
<p>我跟大家解释一下，我其实上课，为什么大量的讲师可能讲课就是纯PPT，或者是各种复制粘贴，都不是现场讲解和写代码演示的</p>
<p>很容易出错，为了避免出错，一般就会那样玩儿</p>
<p>吐槽，念PPT，效果很差</p>
<p>真实的，备课，讲课不可避免，会出现一些问题，但是我觉得还好，真实</p>
<p>appendonly.aof + dump.rdb，优先用appendonly.aof去恢复数据，但是我们发现redis自动生成的appendonly.aof是没有数据的</p>
<p>然后我们自己的dump.rdb是有数据的，但是明显没用我们的数据</p>
<p>redis启动的时候，自动重新基于内存的数据，生成了一份最新的rdb快照，直接用空的数据，覆盖掉了我们有数据的，拷贝过去的那份dump.rdb</p>
<p>你停止redis之后，其实应该先删除appendonly.aof，然后将我们的dump.rdb拷贝过去，然后再重启redis</p>
<p>很简单，就是虽然你删除了appendonly.aof，但是因为打开了aof持久化，redis就一定会优先基于aof去恢复，即使文件不在，那就创建一个新的空的aof文件</p>
<p>停止redis，暂时在配置中关闭aof，然后拷贝一份rdb过来，再重启redis，数据能不能恢复过来，可以恢复过来</p>
<p>脑子一热，再关掉redis，手动修改配置文件，打开aof，再重启redis，数据又没了，空的aof文件，所有数据又没了</p>
<p>在数据安全丢失的情况下，基于rdb冷备，如何完美的恢复数据，同时还保持aof和rdb的双开</p>
<p>停止redis，关闭aof，拷贝rdb备份，重启redis，确认数据恢复，直接在命令行热修改redis配置，打开aof，这个redis就会将内存中的数据对应的日志，写入aof文件中</p>
<p>此时aof和rdb两份数据文件的数据就同步了</p>
<p>redis config set热修改配置参数，可能配置文件中的实际的参数没有被持久化的修改，再次停止redis，手动修改配置文件，打开aof的命令，再次重启redis</p>
<p>（4）如果当前机器上的所有RDB文件全部损坏，那么从远程的云服务上拉取最新的RDB快照回来恢复数据</p>
<p>（5）如果是发现有重大的数据错误，比如某个小时上线的程序一下子将数据全部污染了，数据全错了，那么可以选择某个更早的时间点，对数据进行恢复</p>
<p>举个例子，12点上线了代码，发现代码有bug，导致代码生成的所有的缓存数据，写入redis，全部错了</p>
<p>找到一份11点的rdb的冷备，然后按照上面的步骤，去恢复到11点的数据，不就可以了吗</p>
<h3 id="redis通过主从架构实现读写分离，完成10万-QPS"><a href="#redis通过主从架构实现读写分离，完成10万-QPS" class="headerlink" title="redis通过主从架构实现读写分离，完成10万+QPS"></a>redis通过主从架构实现读写分离，完成10万+QPS</h3><p>1、redis高并发跟整个系统的高并发之间的关系</p>
<p>redis，你要搞高并发的话，不可避免，要把底层的缓存搞得很好</p>
<p>mysql，高并发，做到了，那么也是通过一系列复杂的分库分表，订单系统，事务要求的，QPS到几万，比较高了</p>
<p>要做一些电商的商品详情页，真正的超高并发，QPS上十万，甚至是百万，一秒钟百万的请求量</p>
<p>光是redis是不够的，但是redis是整个大型的缓存架构中，支撑高并发的架构里面，非常重要的一个环节</p>
<p>首先，你的底层的缓存中间件，缓存系统，必须能够支撑的起我们说的那种高并发，其次，再经过良好的整体的缓存架构的设计（多级缓存架构、热点缓存），支撑真正的上十万，甚至上百万的高并发</p>
<p>2、redis不能支撑高并发的瓶颈在哪里？</p>
<p>单机</p>
<p>3、如果redis要支撑超过10万+的并发，那应该怎么做？</p>
<p>单机的redis几乎不太可能说QPS超过10万+，除非一些特殊情况，比如你的机器性能特别好，配置特别高，物理机，维护做的特别好，而且你的整体的操作不是太复杂</p>
<p>单机在几万</p>
<p>读写分离，一般来说，对缓存，一般都是用来支撑读高并发的，写的请求是比较少的，可能写请求也就一秒钟几千，一两千</p>
<p>大量的请求都是读，一秒钟二十万次读</p>
<p>读写分离</p>
<p>主从架构 -&gt; 读写分离 -&gt; 支撑10万+读QPS的架构</p>
<p>4、接下来要讲解的一个topic</p>
<p>redis replication</p>
<p>redis主从架构 -&gt; 读写分离架构 -&gt; 可支持水平扩展的读高并发架构</p>
<h3 id="redis-replication（主从架构）基本原理"><a href="#redis-replication（主从架构）基本原理" class="headerlink" title="redis replication（主从架构）基本原理"></a>redis replication（主从架构）基本原理</h3><p>课程大纲</p>
<p>1、图解redis replication基本原理<br>2、redis replication的核心机制<br>3、master持久化对于主从架构的安全保障的意义</p>
<p>redis replication -&gt; 主从架构 -&gt; 读写分离 -&gt; 水平扩容支撑读高并发</p>
<p>redis replication的最最基本的原理，铺垫</p>
<hr>
<p>1、图解redis replication基本原理</p>
<hr>
<p>2、redis replication的核心机制</p>
<p>（1）redis采用异步方式复制数据到slave节点，不过redis 2.8开始，slave node会周期性地确认自己每次复制的数据量<br>（2）一个master node是可以配置多个slave node的<br>（3）slave node也可以连接其他的slave node<br>（4）slave node做复制的时候，是不会block master node的正常工作的<br>（5）slave node在做复制的时候，也不会block对自己的查询操作，它会用旧的数据集来提供服务; 但是复制完成的时候，需要删除旧数据集，加载新数据集，这个时候就会暂停对外服务了<br>（6）slave node主要用来进行横向扩容，做读写分离，扩容的slave node可以提高读的吞吐量</p>
<p>slave，高可用性，有很大的关系</p>
<hr>
<p>3、master持久化对于主从架构的安全保障的意义</p>
<p>如果采用了主从架构，那么建议必须开启master node的持久化！</p>
<p>不建议用slave node作为master node的数据热备，因为那样的话，如果你关掉master的持久化，可能在master宕机重启的时候数据是空的，然后可能一经过复制，salve node数据也丢了</p>
<p>master -&gt; RDB和AOF都关闭了 -&gt; 全部在内存中</p>
<p>master宕机，重启，是没有本地数据可以恢复的，然后就会直接认为自己IDE数据是空的</p>
<p>master就会将空的数据集同步到slave上去，所有slave的数据全部清空</p>
<p>100%的数据丢失</p>
<p>master节点，必须要使用持久化机制</p>
<p>第二个，master的各种备份方案，要不要做，万一说本地的所有文件丢失了; 从备份中挑选一份rdb去恢复master; 这样才能确保master启动的时候，是有数据的</p>
<p>即使采用了后续讲解的高可用机制，slave node可以自动接管master node，但是也可能sentinal还没有检测到master failure，master node就自动重启了，还是可能导致上面的所有slave node数据清空故障</p>
<h1 id="9-30"><a href="#9-30" class="headerlink" title="9.30"></a>9.30</h1><h3 id="redis主从复制原理细讲"><a href="#redis主从复制原理细讲" class="headerlink" title="redis主从复制原理细讲"></a>redis主从复制原理细讲</h3><p>1、复制的完整流程</p>
<p>（1）slave node启动，仅仅保存master node的信息，包括master node的host和ip，但是复制流程没开始</p>
<p>master host和ip是从哪儿来的，redis.conf里面的slaveof配置的</p>
<p>（2）slave node内部有个定时任务，每秒检查是否有新的master node要连接和复制，如果发现，就跟master node建立socket网络连接<br>（3）slave node发送ping命令给master node<br>（4）口令认证，如果master设置了requirepass，那么salve node必须发送masterauth的口令过去进行认证<br>（5）master node第一次执行全量复制，将所有数据发给slave node<br>（6）master node后续持续将写命令，异步复制给slave node</p>
<p>2、数据同步相关的核心机制</p>
<p>指的就是第一次slave连接msater的时候，执行的全量复制，那个过程里面你的一些细节的机制</p>
<p>（1）master和slave都会维护一个offset</p>
<p>master会在自身不断累加offset，slave也会在自身不断累加offset<br>slave每秒都会上报自己的offset给master，同时master也会保存每个slave的offset</p>
<p>这个倒不是说特定就用在全量复制的，主要是master和slave都要知道各自的数据的offset，才能知道互相之间的数据不一致的情况</p>
<p>（2）backlog</p>
<p>master node有一个backlog，默认是1MB大小<br>master node给slave node复制数据时，也会将数据在backlog中同步写一份<br>backlog主要是用来做全量复制中断候的增量复制的</p>
<p>（3）master run id</p>
<p>info server，可以看到master run id<br>如果根据host+ip定位master node，是不靠谱的，如果master node重启或者数据出现了变化，那么slave node应该根据不同的run id区分，run id不同就做全量复制<br>如果需要不更改run id重启redis，可以使用redis-cli debug reload命令</p>
<p>（4）psync</p>
<p>从节点使用psync从master node进行复制，psync runid offset<br>master node会根据自身的情况返回响应信息，可能是FULLRESYNC runid offset触发全量复制，可能是CONTINUE触发增量复制</p>
<p>3、全量复制</p>
<p>（1）master执行bgsave，在本地生成一份rdb快照文件<br>（2）master node将rdb快照文件发送给salve node，如果rdb复制时间超过60秒（repl-timeout），那么slave node就会认为复制失败，可以适当调节大这个参数<br>（3）对于千兆网卡的机器，一般每秒传输100MB，6G文件，很可能超过60s<br>（4）master node在生成rdb时，会将所有新的写命令缓存在内存中，在salve node保存了rdb之后，再将新的写命令复制给salve node<br>（5）client-output-buffer-limit slave 256MB 64MB 60，如果在复制期间，内存缓冲区持续消耗超过64MB，或者一次性超过256MB，那么停止复制，复制失败<br>（6）slave node接收到rdb之后，清空自己的旧数据，然后重新加载rdb到自己的内存中，同时基于旧的数据版本对外提供服务<br>（7）如果slave node开启了AOF，那么会立即执行BGREWRITEAOF，重写AOF</p>
<p>rdb生成、rdb通过网络拷贝、slave旧数据的清理、slave aof rewrite，很耗费时间</p>
<p>如果复制的数据量在4G~6G之间，那么很可能全量复制时间消耗到1分半到2分钟</p>
<p>4、增量复制</p>
<p>（1）如果全量复制过程中，master-slave网络连接断掉，那么salve重新连接master时，会触发增量复制<br>（2）master直接从自己的backlog中获取部分丢失的数据，发送给slave node，默认backlog就是1MB<br>（3）msater就是根据slave发送的psync中的offset来从backlog中获取数据的</p>
<p>5、heartbeat</p>
<p>主从节点互相都会发送heartbeat信息</p>
<p>master默认每隔10秒发送一次heartbeat，salve node每隔1秒发送一个heartbeat</p>
<p>6、异步复制</p>
<p>master每次接收到写命令之后，现在内部写入数据，然后异步发送给slave node</p>
<h3 id="搭建redis主从节点"><a href="#搭建redis主从节点" class="headerlink" title="搭建redis主从节点"></a>搭建redis主从节点</h3><p>之前几讲都是在铺垫各种redis replication的原理，和知识，主从，读写分离，画图</p>
<p>知道了这些东西，关键是怎么搭建呢？？？</p>
<p>一主一从，往主节点去写，在从节点去读，可以读到，主从架构就搭建成功了</p>
<p>1、启用复制，部署slave node</p>
<p>wget <a href="http://downloads.sourceforge.net/tcl/tcl8.6.1-src.tar.gz" target="_blank" rel="noopener">http://downloads.sourceforge.net/tcl/tcl8.6.1-src.tar.gz</a><br>tar -xzvf tcl8.6.1-src.tar.gz<br>cd  /usr/local/tcl8.6.1/unix/<br>./configure<br>make &amp;&amp; make install</p>
<p>使用redis-3.2.8.tar.gz（截止2017年4月的最新稳定版）<br>tar -zxvf redis-3.2.8.tar.gz<br>cd redis-3.2.8<br>make &amp;&amp; make test &amp;&amp; make install</p>
<p>（1）redis utils目录下，有个redis_init_script脚本<br>（2）将redis_init_script脚本拷贝到linux的/etc/init.d目录中，将redis_init_script重命名为redis_6379，6379是我们希望这个redis实例监听的端口号<br>（3）修改redis_6379脚本的第6行的REDISPORT，设置为相同的端口号（默认就是6379）<br>（4）创建两个目录：/etc/redis（存放redis的配置文件），/var/redis/6379（存放redis的持久化文件）<br>（5）修改redis配置文件（默认在根目录下，redis.conf），拷贝到/etc/redis目录中，修改名称为6379.conf</p>
<p>（6）修改redis.conf中的部分配置为生产环境</p>
<p>daemonize    yes                            让redis以daemon进程运行<br>pidfile        /var/run/redis_6379.pid     设置redis的pid文件位置<br>port        6379                        设置redis的监听端口号<br>dir         /var/redis/6379                设置持久化文件的存储位置   (设置持久化文件的位置)</p>
<p>（7）让redis跟随系统启动自动启动</p>
<p>在redis_6379脚本中，最上面，加入两行注释</p>
<h1 id="chkconfig-2345-90-10"><a href="#chkconfig-2345-90-10" class="headerlink" title="chkconfig:   2345 90 10"></a>chkconfig:   2345 90 10</h1><h1 id="description-Redis-is-a-persistent-key-value-database"><a href="#description-Redis-is-a-persistent-key-value-database" class="headerlink" title="description:  Redis is a persistent key-value database"></a>description:  Redis is a persistent key-value database</h1><p>chkconfig redis_6379 on（随着系统启动+）</p>
<p>在slave node上配置（redis.conf文件中只要修改slaveof相关配置）：</p>
<p>slaveof 192.168.1.1（主节点） 6379（redis端口号），即可也可以使用slaveof命令</p>
<p>则配置成自己是从节点<br>2、强制读写分离</p>
<p>基于主从复制架构，实现读写分离</p>
<p>redis slave node只读，默认开启，slave-read-only</p>
<p>开启了只读的redis slave node，会拒绝所有的写操作，这样可以强制搭建成读写分离的架构</p>
<p>3、集群安全认证</p>
<p>master上启用安全认证，requirepass<br>master连接口令，masterauth</p>
<p>4、读写分离架构的测试</p>
<p>先启动主节点，eshop-cache01上的redis实例<br>再启动从节点，eshop-cache02上的redis实例</p>
<p>刚才我调试了一下，redis slave node一直说没法连接到主节点的6379的端口</p>
<p>在搭建生产环境的集群的时候，不要忘记修改一个配置，bind</p>
<p>bind 127.0.0.1 -&gt; 本地的开发调试的模式，就只能127.0.0.1本地才能访问到6379的端口</p>
<p>每个redis.conf中的bind 127.0.0.1 -&gt; bind自己的ip地址<br>在每个节点上都: iptables -A INPUT -ptcp –dport  6379 -j ACCEPT</p>
<p>redis-cli -h ipaddr<br>info replication</p>
<p>在主上写，在从上读<br>ps -ef | grep redis<br>查看redis进程是否已经启动</p>
<h3 id="哨兵架构基础知识讲解"><a href="#哨兵架构基础知识讲解" class="headerlink" title="哨兵架构基础知识讲解"></a>哨兵架构基础知识讲解</h3><p>1、哨兵的介绍</p>
<p>sentinal，中文名是哨兵</p>
<p>哨兵是redis集群架构中非常重要的一个组件，主要功能如下</p>
<p>（1）集群监控，负责监控redis master和slave进程是否正常工作<br>（2）消息通知，如果某个redis实例有故障，那么哨兵负责发送消息作为报警通知给管理员<br>（3）故障转移，如果master node挂掉了，会自动转移到slave node上<br>（4）配置中心，如果故障转移发生了，通知client客户端新的master地址</p>
<p>哨兵本身也是分布式的，作为一个哨兵集群去运行，互相协同工作</p>
<p>（1）故障转移时，判断一个master node是宕机了，需要大部分的哨兵都同意才行，涉及到了分布式选举的问题<br>（2）即使部分哨兵节点挂掉了，哨兵集群还是能正常工作的，因为如果一个作为高可用机制重要组成部分的故障转移系统本身是单点的，那就很坑爹了</p>
<p>目前采用的是sentinal 2版本，sentinal 2相对于sentinal 1来说，重写了很多代码，主要是让故障转移的机制和算法变得更加健壮和简单</p>
<p>2、哨兵的核心知识</p>
<p>（1）哨兵至少需要3个实例，来保证自己的健壮性<br>（2）哨兵 + redis主从的部署架构，是不会保证数据零丢失的，只能保证redis集群的高可用性<br>（3）对于哨兵 + redis主从这种复杂的部署架构，尽量在测试环境和生产环境，都进行充足的测试和演练</p>
<p>3、为什么redis哨兵集群只有2个节点无法正常工作？</p>
<p>哨兵集群必须部署2个以上节点</p>
<p>如果哨兵集群仅仅部署了个2个哨兵实例，quorum=1</p>
<p>+—-+         +—-+<br>| M1 |———| R1 |<br>| S1 |         | S2 |<br>+—-+         +—-+</p>
<p>Configuration: quorum = 1</p>
<p>master宕机，s1和s2中只要有1个哨兵认为master宕机就可以还行切换，同时s1和s2中会选举出一个哨兵来执行故障转移</p>
<p>同时这个时候，需要majority，也就是大多数哨兵都是运行的，2个哨兵的majority就是2（2的majority=2，3的majority=2，5的majority=3，4的majority=2），2个哨兵都运行着，就可以允许执行故障转移</p>
<p>但是如果整个M1和S1运行的机器宕机了，那么哨兵只有1个了，此时就没有majority来允许执行故障转移，虽然另外一台机器还有一个R1，但是故障转移不会执行</p>
<p>4、经典的3节点哨兵集群</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">+----+</span><br><span class="line">| M1 |</span><br><span class="line">| S1 |</span><br><span class="line">+----+</span><br><span class="line">   |</span><br></pre></td></tr></table></figure>
<p>+—-+    |    +—-+<br>| R2 |—-+—-| R3 |<br>| S2 |         | S3 |<br>+—-+         +—-+</p>
<p>Configuration: quorum = 2，majority = 2</p>
<p>如果M1所在机器宕机了，那么三个哨兵还剩下2个，S2和S3可以一致认为master宕机，然后选举出一个来执行故障转移</p>
<p>同时3个哨兵的majority是2，所以还剩下的2个哨兵运行着，就可以允许执行故障转移</p>
<h3 id="redis哨兵主备切换的数据丢失问题：异步复制，集群脑裂"><a href="#redis哨兵主备切换的数据丢失问题：异步复制，集群脑裂" class="headerlink" title="redis哨兵主备切换的数据丢失问题：异步复制，集群脑裂"></a>redis哨兵主备切换的数据丢失问题：异步复制，集群脑裂</h3><p>课程大纲</p>
<p>1、两种数据丢失的情况<br>2、解决异步复制和脑裂导致的数据丢失</p>
<hr>
<p>1、两种数据丢失的情况</p>
<p>主备切换的过程，可能会导致数据丢失</p>
<p>（1）异步复制导致的数据丢失</p>
<p>因为master -&gt; slave的复制是异步的，所以可能有部分数据还没复制到slave，master就宕机了，此时这些部分数据就丢失了</p>
<p>（2）脑裂导致的数据丢失</p>
<p>脑裂，也就是说，某个master所在机器突然脱离了正常的网络，跟其他slave机器不能连接，但是实际上master还运行着</p>
<p>此时哨兵可能就会认为master宕机了，然后开启选举，将其他slave切换成了master</p>
<p>这个时候，集群里就会有两个master，也就是所谓的脑裂</p>
<p>此时虽然某个slave被切换成了master，但是可能client还没来得及切换到新的master，还继续写向旧master的数据可能也丢失了</p>
<p>因此旧master再次恢复的时候，会被作为一个slave挂到新的master上去，自己的数据会清空，重新从新的master复制数据</p>
<hr>
<p>2、解决异步复制和脑裂导致的数据丢失</p>
<p>min-slaves-to-write 1<br>min-slaves-max-lag 10</p>
<p>要求至少有1个slave，数据复制和同步的延迟不能超过10秒</p>
<p>如果说一旦所有的slave，数据复制和同步的延迟都超过了10秒钟，那么这个时候，master就不会再接收任何请求了</p>
<p>上面两个配置可以减少异步复制和脑裂导致的数据丢失</p>
<p>（1）减少异步复制的数据丢失</p>
<p>有了min-slaves-max-lag这个配置，就可以确保说，一旦slave复制数据和ack延时太长，就认为可能master宕机后损失的数据太多了，那么就拒绝写请求，这样可以把master宕机时由于部分数据未同步到slave导致的数据丢失降低的可控范围内</p>
<p>（2）减少脑裂的数据丢失</p>
<p>如果一个master出现了脑裂，跟其他slave丢了连接，那么上面两个配置可以确保说，如果不能继续给指定数量的slave发送数据，而且slave超过10秒没有给自己ack消息，那么就直接拒绝客户端的写请求</p>
<p>这样脑裂后的旧master就不会接受client的新数据，也就避免了数据丢失</p>
<p>上面的配置就确保了，如果跟任何一个slave丢了连接，在10秒后发现没有slave给自己ack，那么就拒绝新的写请求</p>
<p>因此在脑裂场景下，最多就丢失10秒的数据</p>
<h3 id="redis哨兵的多个核心底层原理的深入解析"><a href="#redis哨兵的多个核心底层原理的深入解析" class="headerlink" title="redis哨兵的多个核心底层原理的深入解析"></a>redis哨兵的多个核心底层原理的深入解析</h3><p>1、sdown和odown转换机制</p>
<p>sdown和odown两种失败状态</p>
<p>sdown是主观宕机，就一个哨兵如果自己觉得一个master宕机了，那么就是主观宕机</p>
<p>odown是客观宕机，如果quorum数量的哨兵都觉得一个master宕机了，那么就是客观宕机</p>
<p>sdown达成的条件很简单，如果一个哨兵ping一个master，超过了is-master-down-after-milliseconds指定的毫秒数之后，就主观认为master宕机</p>
<p>sdown到odown转换的条件很简单，如果一个哨兵在指定时间内，收到了quorum指定数量的其他哨兵也认为那个master是sdown了，那么就认为是odown了，客观认为master宕机</p>
<p>2、哨兵集群的自动发现机制</p>
<p>哨兵互相之间的发现，是通过redis的pub/sub系统实现的，每个哨兵都会往<strong>sentinel</strong>:hello这个channel里发送一个消息，这时候所有其他哨兵都可以消费到这个消息，并感知到其他的哨兵的存在</p>
<p>每隔两秒钟，每个哨兵都会往自己监控的某个master+slaves对应的<strong>sentinel</strong>:hello channel里发送一个消息，内容是自己的host、ip和runid还有对这个master的监控配置</p>
<p>每个哨兵也会去监听自己监控的每个master+slaves对应的<strong>sentinel</strong>:hello channel，然后去感知到同样在监听这个master+slaves的其他哨兵的存在</p>
<p>每个哨兵还会跟其他哨兵交换对master的监控配置，互相进行监控配置的同步</p>
<p>3、slave配置的自动纠正</p>
<p>哨兵会负责自动纠正slave的一些配置，比如slave如果要成为潜在的master候选人，哨兵会确保slave在复制现有master的数据; 如果slave连接到了一个错误的master上，比如故障转移之后，那么哨兵会确保它们连接到正确的master上</p>
<p>4、slave-&gt;master选举算法</p>
<p>如果一个master被认为odown了，而且majority哨兵都允许了主备切换，那么某个哨兵就会执行主备切换操作，此时首先要选举一个slave来</p>
<p>会考虑slave的一些信息</p>
<p>（1）跟master断开连接的时长<br>（2）slave优先级<br>（3）复制offset<br>（4）run id</p>
<p>如果一个slave跟master断开连接已经超过了down-after-milliseconds的10倍，外加master宕机的时长，那么slave就被认为不适合选举为master</p>
<p>(down-after-milliseconds * 10) + milliseconds_since_master_is_in_SDOWN_state</p>
<p>接下来会对slave进行排序</p>
<p>（1）按照slave优先级进行排序，slave priority越低，优先级就越高(slave priority是在redis.conf文件中自己设置的)<br>（2）如果slave priority相同，那么看replica offset，哪个slave复制了越多的数据，offset越靠后，优先级就越高<br>（3）如果上面两个条件都相同，那么选择一个run id比较小的那个slave</p>
<p>5、quorum和majority</p>
<p>每次一个哨兵要做主备切换，首先需要quorum数量的哨兵认为odown，然后选举出一个哨兵来做切换，这个哨兵还得得到majority哨兵的授权，才能正式执行切换</p>
<p>如果quorum &lt; majority，比如5个哨兵，majority就是3，quorum设置为2，那么就3个哨兵授权就可以执行切换</p>
<p>但是如果quorum &gt;= majority，那么必须quorum数量的哨兵都授权，比如5个哨兵，quorum是5，那么必须5个哨兵都同意授权，才能执行切换</p>
<p>6、configuration epoch</p>
<p>哨兵会对一套redis master+slave进行监控，有相应的监控的配置</p>
<p>执行切换的那个哨兵，会从要切换到的新master（salve-&gt;master）那里得到一个configuration epoch，这就是一个version号，每次切换的version号都必须是唯一的</p>
<p>如果第一个选举出的哨兵切换失败了，那么其他哨兵，会等待failover-timeout时间，然后接替继续执行切换，此时会重新获取一个新的configuration epoch，作为新的version号</p>
<p>7、configuraiton传播</p>
<p>哨兵完成切换之后，会在自己本地更新生成最新的master配置，然后同步给其他的哨兵，就是通过之前说的pub/sub消息机制</p>
<p>这里之前的version号就很重要了，因为各种消息都是通过一个channel去发布和监听的，所以一个哨兵完成一次新的切换之后，新的master配置是跟着新的version号的</p>
<p>其他的哨兵都是根据版本号的大小来更新自己的master配置的</p>
<h3 id="redis哨兵集群的实战配置"><a href="#redis哨兵集群的实战配置" class="headerlink" title="redis哨兵集群的实战配置"></a>redis哨兵集群的实战配置</h3><p>quorum的解释如下：</p>
<p>（1）至少多少个哨兵要一致同意，master进程挂掉了，或者slave进程挂掉了，或者要启动一个故障转移操作<br>（2）quorum是用来识别故障的，真正执行故障转移的时候，还是要在哨兵集群执行选举，选举一个哨兵进程出来执行故障转移操作<br>（3）假设有5个哨兵，quorum设置了2，那么如果5个哨兵中的2个都认为master挂掉了; 2个哨兵中的一个就会做一个选举，选举一个哨兵出来，执行故障转移; 如果5个哨兵中有3个哨兵都是运行的，那么故障转移就会被允许执行</p>
<p>动手实操，练习如何操作部署哨兵集群，如何基于哨兵进行故障转移，还有一些企业级的配置方案</p>
<p>1、哨兵的配置文件<br>(存放在redis安装目录下)<br>sentinel.conf</p>
<p>最小的配置</p>
<p>每一个哨兵都可以去监控多个maser-slaves的主从架构</p>
<p>因为可能你的公司里，为不同的项目，部署了多个master-slaves的redis主从集群</p>
<p>相同的一套哨兵集群，就可以去监控不同的多个redis主从集群</p>
<p>你自己给每个redis主从集群分配一个逻辑的名称</p>
<p>sentinel monitor mymaster 127.0.0.1 6379 2<br>sentinel down-after-milliseconds mymaster 60000<br>sentinel failover-timeout mymaster 180000<br>sentinel parallel-syncs mymaster 1</p>
<p>sentinel monitor resque 192.168.1.3 6380 4<br>sentinel down-after-milliseconds resque 10000<br>sentinel failover-timeout resque 180000<br>sentinel parallel-syncs resque 5</p>
<p>sentinel monitor mymaster 127.0.0.1 6379 </p>
<p>类似这种配置，来指定对一个master的监控，给监控的master指定的一个名称，因为后面分布式集群架构里会讲解，可以配置多个master做数据拆分</p>
<p>sentinel down-after-milliseconds mymaster 60000<br>sentinel failover-timeout mymaster 180000<br>sentinel parallel-syncs mymaster 1</p>
<p>上面的三个配置，都是针对某个监控的master配置的，给其指定上面分配的名称即可</p>
<p>上面这段配置，就监控了两个master node</p>
<p>这是最小的哨兵配置，如果发生了master-slave故障转移，或者新的哨兵进程加入哨兵集群，那么哨兵会自动更新自己的配置文件</p>
<p>sentinel monitor master-group-name hostname port quorum</p>
<p>quorum的解释如下：</p>
<p>（1）至少多少个哨兵要一致同意，master进程挂掉了，或者slave进程挂掉了，或者要启动一个故障转移操作<br>（2）quorum是用来识别故障的，真正执行故障转移的时候，还是要在哨兵集群执行选举，选举一个哨兵进程出来执行故障转移操作<br>（3）假设有5个哨兵，quorum设置了2，那么如果5个哨兵中的2个都认为master挂掉了; 2个哨兵中的一个就会做一个选举，选举一个哨兵出来，执行故障转移; 如果5个哨兵中有3个哨兵都是运行的，那么故障转移就会被允许执行</p>
<p>down-after-milliseconds，超过多少毫秒跟一个redis实例断了连接，哨兵就可能认为这个redis实例挂了</p>
<p>parallel-syncs，新的master别切换之后，同时有多少个slave被切换到去连接新master，重新做同步，数字越低，花费的时间越多</p>
<p>假设你的redis是1个master，4个slave</p>
<p>然后master宕机了，4个slave中有1个切换成了master，剩下3个slave就要挂到新的master上面去</p>
<p>这个时候，如果parallel-syncs是1，那么3个slave，一个一个地挂接到新的master上面去，1个挂接完，而且从新的master sync完数据之后，再挂接下一个</p>
<p>如果parallel-syncs是3，那么一次性就会把所有slave挂接到新的master上去</p>
<p>failover-timeout，执行故障转移的timeout超时时长</p>
<p>2、在eshop-cache03上再部署一个redis</p>
<p>只要安装redis就可以了，不需要去部署redis实例的启动</p>
<p>wget <a href="http://downloads.sourceforge.net/tcl/tcl8.6.1-src.tar.gz" target="_blank" rel="noopener">http://downloads.sourceforge.net/tcl/tcl8.6.1-src.tar.gz</a><br>tar -xzvf tcl8.6.1-src.tar.gz<br>cd  /usr/local/tcl8.6.1/unix/<br>./configure<br>make &amp;&amp; make install</p>
<p>使用redis-3.2.8.tar.gz（截止2017年4月的最新稳定版）<br>tar -zxvf redis-3.2.8.tar.gz<br>cd redis-3.2.8<br>make &amp;&amp; make test<br>make install</p>
<p>2、正式的配置</p>
<p>哨兵默认用26379端口，默认不能跟其他机器在指定端口连通，只能在本地访问</p>
<p>mkdir /etc/sentinal<br>mkdir -p /var/sentinal/5000</p>
<p>/etc/sentinel/5000.conf</p>
<p>port 5000<br>bind 192.168.31.187<br>dir /var/sentinal/5000<br>sentinel monitor mymaster 192.168.31.187 6379 2<br>sentinel down-after-milliseconds mymaster 30000<br>sentinel failover-timeout mymaster 60000<br>sentinel parallel-syncs mymaster 1</p>
<p>port 5000<br>bind 192.168.31.19<br>dir /var/sentinal/5000<br>sentinel monitor mymaster 192.168.31.187 6379 2<br>sentinel down-after-milliseconds mymaster 30000<br>sentinel failover-timeout mymaster 60000<br>sentinel parallel-syncs mymaster 1</p>
<p>port 5000<br>bind 192.168.31.227<br>dir /var/sentinal/5000<br>sentinel monitor mymaster 192.168.31.187 6379 2<br>sentinel down-after-milliseconds mymaster 30000<br>sentinel failover-timeout mymaster 60000<br>sentinel parallel-syncs mymaster 1</p>
<p>3、启动哨兵进程</p>
<p>在eshop-cache01、eshop-cache02、eshop-cache03三台机器上，分别启动三个哨兵进程，组成一个集群，观察一下日志的输出</p>
<p>redis-sentinel /etc/sentinal/5000.conf<br>redis-server /etc/sentinal/5000.conf –sentinel</p>
<p>日志里会显示出来，每个哨兵都能去监控到对应的redis master，并能够自动发现对应的slave</p>
<p>哨兵之间，互相会自动进行发现，用的就是之前说的pub/sub，消息发布和订阅channel消息系统和机制</p>
<p>4、检查哨兵状态</p>
<p>redis-cli -h 192.168.31.187 -p 5000</p>
<p>sentinel master mymaster<br>SENTINEL slaves mymaster<br>SENTINEL sentinels mymaster</p>
<p>SENTINEL get-master-addr-by-name mymaster</p>
<h3 id="redis-cluster横向扩容master"><a href="#redis-cluster横向扩容master" class="headerlink" title="redis cluster横向扩容master"></a>redis cluster横向扩容master</h3><p>1、单机redis在海量数据面前的瓶颈</p>
<p>2、怎么才能够突破单机瓶颈，让redis支撑海量数据？</p>
<p>3、redis的集群架构</p>
<p>redis cluster</p>
<p>支撑N个redis master node，每个master node都可以挂载多个slave node</p>
<p>读写分离的架构，对于每个master来说，写就写到master，然后读就从mater对应的slave去读</p>
<p>高可用，因为每个master都有salve节点，那么如果mater挂掉，redis cluster这套机制，就会自动将某个slave切换成master</p>
<p>redis cluster（多master + 读写分离 + 高可用）</p>
<p>我们只要基于redis cluster去搭建redis集群即可，不需要手工去搭建replication复制+主从架构+读写分离+哨兵集群+高可用</p>
<p>4、redis cluster vs. replication + sentinal</p>
<p>如果你的数据量很少，主要是承载高并发高性能的场景，比如你的缓存一般就几个G，单机足够了</p>
<p>replication，一个mater，多个slave，要几个slave跟你的要求的读吞吐量有关系，然后自己搭建一个sentinal集群，去保证redis主从架构的高可用性，就可以了</p>
<p>redis cluster，主要是针对海量数据+高并发+高可用的场景，海量数据，如果你的数据量很大，那么建议就用redis cluster</p>
<h3 id="redis阶段性总结"><a href="#redis阶段性总结" class="headerlink" title="redis阶段性总结"></a>redis阶段性总结</h3><p>1、讲解redis是为了什么？</p>
<p>topic：高并发、亿级流量、高性能、海量数据的场景，电商网站的商品详情页系统的缓存架构</p>
<p>商品详情页系统，大型电商网站，会有很多部分组成，但是支撑高并发、亿级流量的，主要就是其中的大型的缓存架构</p>
<p>在这个大型的缓存架构中，redis是最最基础的一层</p>
<p>高并发，缓存架构中除了redis，还有其他的组成部分，但是redis至关重要</p>
<p>大量的离散请求，随机请求，各种你未知的用户过来的请求，上千万用户过来访问，每个用户访问10次; 集中式的请求，1个用户过来，一天访问1亿次</p>
<p>支撑商品展示的最重要的，就是redis cluster，去抗住每天上亿的请求流量，支撑高并发的访问</p>
<p>redis cluster在整个缓存架构中，如何跟其他几个部分搭配起来组成一个大型的缓存系统，后面再讲</p>
<p>2、讲解的redis可以实现什么效果？</p>
<p>我之前一直在redis的各个知识点的讲解之前都强调一下，我们要讲解的每个知识点，要解决的问题是什么？？？</p>
<p>redis：持久化、复制（主从架构）、哨兵（高可用，主备切换）、redis cluster（海量数据+横向扩容+高可用/主备切换）</p>
<p>持久化：高可用的一部分，在发生redis集群灾难的情况下（比如说部分master+slave全部死掉了），如何快速进行数据恢复，快速实现服务可用，才能实现整个系统的高可用</p>
<p>复制：主从架构，master -&gt; slave 复制，读写分离的架构，写master，读slave，横向扩容slave支撑更高的读吞吐，读高并发，10万，20万，30万，上百万，QPS，横向扩容</p>
<p>哨兵：高可用，主从架构，在master故障的时候，快速将slave切换成master，实现快速的灾难恢复，实现高可用性</p>
<p>redis cluster：多master读写，数据分布式的存储，横向扩容，水平扩容，快速支撑高达的数据量+更高的读写QPS，自动进行master -&gt; slave的主备切换，高可用</p>
<p>让底层的缓存系统，redis，实现能够任意水平扩容，支撑海量数据（1T+，几十T，10G * 600 redis = 6T），支撑很高的读写QPS（redis单机在几万QPS，10台，几十万QPS），高可用性（给我们每个redis实例都做好AOF+RDB的备份策略+容灾策略，slave -&gt; master主备切换）</p>
<p>1T+海量数据、10万+读写QPS、99.99%高可用性</p>
<p>3、redis的第一套企业级的架构</p>
<p>如果你的数据量不大，单master就可以容纳，一般来说你的缓存的总量在10G以内就可以，那么建议按照以下架构去部署redis</p>
<p>redis持久化+备份方案+容灾方案+replication（主从+读写分离）+sentinal（哨兵集群，3个节点，高可用性）</p>
<p>可以支撑的数据量在10G以内，可以支撑的写QPS在几万左右，可以支撑的读QPS可以上10万以上（随你的需求，水平扩容slave节点就可以），可用性在99.99%</p>
<p>4、redis的第二套企业级架构</p>
<p>如果你的数据量很大，比如我们课程的topic，大型电商网站的商品详情页的架构（对标那些国内排名前三的大电商网站，<em>宝，</em>东，*宁易购），数据量是很大的</p>
<p>海量数据</p>
<p>redis cluster</p>
<p>多master分布式存储数据，水平扩容</p>
<p>支撑更多的数据量，1T+以上没问题，只要扩容master即可</p>
<p>读写QPS分别都达到几十万都没问题，只要扩容master即可，redis cluster，读写分离，支持不太好，readonly才能去slave上读</p>
<p>支撑99.99%可用性，也没问题，slave -&gt; master的主备切换，冗余slave去进一步提升可用性的方案（每个master挂一个slave，但是整个集群再加个3个slave冗余一下）</p>
<p>我们课程里，两套架构都讲解了，后续的业务系统的开发，主要是基于redis cluster去做</p>
<p>5、我们现在课程讲解的项目进展到哪里了？</p>
<p>我们要做后续的业务系统的开发，redis的架构部署好，是第一件事情，也是非常重要的，也是你作为一个架构师而言，在对系统进行设计的时候，你必须要考虑到底层的redis的并发、性能、能支撑的数据量、可用性</p>
<p>redis：水平扩容，海量数据，上10万的读写QPS，99.99%高可用性</p>
<p>从架构的角度，我们的redis是可以做到的，水平扩容，只要机器足够，到1T数据量，50万读写QPS，99.99%</p>
<p>正式开始做大型电商网站的商品详情页系统，大规模的缓存架构设计</p>

      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/redis/" rel="tag"># redis</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2019/10/01/SQL注入/" rel="next" title="SQL注入">
                <i class="fa fa-chevron-left"></i> SQL注入
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2019/10/02/模拟第一天/" rel="prev" title="模拟第一天">
                模拟第一天 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image" src="/images/weixin.jpg" alt="Chen ZeTao">
            
              <p class="site-author-name" itemprop="name">Chen ZeTao</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">44</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">15</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">27</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          

          

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-3"><a class="nav-link" href="#要掌握的很好的，就是redis架构"><span class="nav-number">1.</span> <span class="nav-text">要掌握的很好的，就是redis架构</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#redis-持久化RDB-AOF利弊比较"><span class="nav-number">2.</span> <span class="nav-text">redis 持久化RDB,AOF利弊比较</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#RDB持久化详解"><span class="nav-number">3.</span> <span class="nav-text">RDB持久化详解</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#AOF持久化详解"><span class="nav-number">4.</span> <span class="nav-text">AOF持久化详解</span></a></li></ol><li class="nav-item nav-level-1"><a class="nav-link" href="#9-29"><span class="nav-number"></span> <span class="nav-text">9.29</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#redis在企业级数据备份方案以及数据恢复负灾演练"><span class="nav-number">1.</span> <span class="nav-text">redis在企业级数据备份方案以及数据恢复负灾演练</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#redis通过主从架构实现读写分离，完成10万-QPS"><span class="nav-number">2.</span> <span class="nav-text">redis通过主从架构实现读写分离，完成10万+QPS</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#redis-replication（主从架构）基本原理"><span class="nav-number">3.</span> <span class="nav-text">redis replication（主从架构）基本原理</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#9-30"><span class="nav-number"></span> <span class="nav-text">9.30</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#redis主从复制原理细讲"><span class="nav-number">1.</span> <span class="nav-text">redis主从复制原理细讲</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#搭建redis主从节点"><span class="nav-number">2.</span> <span class="nav-text">搭建redis主从节点</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#chkconfig-2345-90-10"><span class="nav-number"></span> <span class="nav-text">chkconfig:   2345 90 10</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#description-Redis-is-a-persistent-key-value-database"><span class="nav-number"></span> <span class="nav-text">description:  Redis is a persistent key-value database</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#哨兵架构基础知识讲解"><span class="nav-number">1.</span> <span class="nav-text">哨兵架构基础知识讲解</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#redis哨兵主备切换的数据丢失问题：异步复制，集群脑裂"><span class="nav-number">2.</span> <span class="nav-text">redis哨兵主备切换的数据丢失问题：异步复制，集群脑裂</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#redis哨兵的多个核心底层原理的深入解析"><span class="nav-number">3.</span> <span class="nav-text">redis哨兵的多个核心底层原理的深入解析</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#redis哨兵集群的实战配置"><span class="nav-number">4.</span> <span class="nav-text">redis哨兵集群的实战配置</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#redis-cluster横向扩容master"><span class="nav-number">5.</span> <span class="nav-text">redis cluster横向扩容master</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#redis阶段性总结"><span class="nav-number">6.</span> <span class="nav-text">redis阶段性总结</span></a></li></ol></li></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      
        <div class="back-to-top">
          <i class="fa fa-arrow-up"></i>
          
            <span id="scrollpercent"><span>0</span>%</span>
          
        </div>
      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
<div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Chen ZeTao</span>

  
</div>


  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Muse</a> v5.1.4</div>



<div class="powered-by">
<i class="fa fa-user-md"></i><span id="busuanzi_container_site_uv">
  本站访客数:<span id="busuanzi_value_site_uv"></span>
</span>
</div>
<div class="theme-info">
  <div class="powered-by"></div>
  <span class="post-count">博客全站共83.6k字</span>
</div>

        
<div class="busuanzi-count">
  <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  
    <span class="site-uv">
      
      <span class="busuanzi-value" id="busuanzi_value_site_uv"></span>
      
    </span>
  

  
    <span class="site-pv">
      <i class="fa fa-eye"></i> 总访问量
      <span class="busuanzi-value" id="busuanzi_value_site_pv"></span>
      
    </span>
  
</div>








        
      </div>
    </footer>

    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  

  

  
  

  

  

  

  
<script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"debug":false,"model":{"jsonPath":"/live2dw/assets/tororo.model.json"},"display":{"position":"right","width":150,"height":300},"mobile":{"show":true},"react":{"opacity":0.7},"log":false});</script></body>
</html>
