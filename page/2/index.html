<!DOCTYPE html>



  


<html class="theme-next muse use-motion" lang="zh-Hans">
<head><meta name="generator" content="Hexo 3.9.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/favicon.ico?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon.ico?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon.ico?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hexo, NexT">










<meta property="og:type" content="website">
<meta property="og:title" content="ddd `Blog">
<meta property="og:url" content="http://yoursite.com/page/2/index.html">
<meta property="og:site_name" content="ddd `Blog">
<meta property="og:locale" content="zh-Hans">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="ddd `Blog">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":true,"scrollpercent":true,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/page/2/">





  <title>ddd `Blog</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">ddd `Blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">czt的博客</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br>
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br>
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            归档
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br>
            
            搜索
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off" placeholder="搜索..." spellcheck="false" type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/10/03/缓存雪崩解决方案/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Chen ZeTao">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/weixin.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="ddd `Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/10/03/缓存雪崩解决方案/" itemprop="url">缓存雪崩解决方案</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-10-03T11:36:38+08:00">
                2019-10-03
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  681
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  2
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p> 相对来说，考虑的比较完善的一套方案，分为事前，事中，事后三个层次去思考怎么来应对缓存雪崩的场景</p>
<p>1、事前解决方案</p>
<p>发生缓存雪崩之前，事情之前，怎么去避免redis彻底挂掉</p>
<p>redis本身的高可用性，复制，主从架构，操作主节点，读写，数据同步到从节点，一旦主节点挂掉，从节点跟上</p>
<p>双机房部署，一套redis cluster，部分机器在一个机房，另一部分机器在另外一个机房</p>
<p>还有一种部署方式，两套redis cluster，两套redis cluster之间做一个数据的同步，redis集群是可以搭建成树状的结构的</p>
<p>一旦说单个机房出了故障，至少说另外一个机房还能有些redis实例提供服务</p>
<p>2、事中解决方案</p>
<p>redis cluster已经彻底崩溃了，已经开始大量的访问无法访问到redis了</p>
<p>（1）ehcache本地缓存</p>
<p>所做的多级缓存架构的作用上了，ehcache的缓存，应对零散的redis中数据被清除掉的现象，另外一个主要是预防redis彻底崩溃</p>
<p>多台机器上部署的缓存服务实例的内存中，还有一套ehcache的缓存</p>
<p>ehcache的缓存还能支撑一阵</p>
<p>（2）对redis访问的资源隔离</p>
<p>（3）对源服务访问的限流以及资源隔离</p>
<p>3、事后解决方案</p>
<p>（1）redis数据可以恢复，做了备份，redis数据备份和恢复，redis重新启动起来</p>
<p>（2）redis数据彻底丢失了，或者数据过旧，快速缓存预热，redis重新启动起来</p>
<p>redis对外提供服务</p>
<p>缓存服务里，熔断策略，自动可以恢复，half-open，发现redis可以访问了，自动恢复了，自动就继续去访问redis了</p>
<p>基于hystrix的高可用服务这块技术之后，先讲解缓存服务如何设计成高可用的架构</p>
<p>缓存架构应对高并发下的缓存雪崩的解决方案，基于hystrix去做缓存服务的保护</p>
<p>要带着大家去实现的有什么东西？事前和事后不用了吧</p>
<p>事中，ehcache本身也做好了</p>
<p>基于hystrix对redis的访问进行保护，对源服务的访问进行保护，讲解hystrix的时候，也说过对源服务的访问怎么怎么进行这种高可用的保护</p>
<p>但是站的角度不同，源服务如果自己本身不知道什么原因出了故障，我们怎么去保护，调用商品服务的接口大量的报错、超时</p>
<p>限流，资源隔离，降级</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/10/03/线程池学习及优化/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Chen ZeTao">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/weixin.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="ddd `Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/10/03/线程池学习及优化/" itemprop="url">线程池学习及优化</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-10-03T10:51:47+08:00">
                2019-10-03
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  2.2k
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  7
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h3 id="多线程并发"><a href="#多线程并发" class="headerlink" title="多线程并发"></a>多线程并发</h3><p>生产环境里面，一个是线程池的大小怎么设置，timeout时长怎么</p>
<p>不合理的话，问题还是很大的</p>
<p>在生产环境中部署一个短路器，一开始需要将一些关键配置设置的大一些，比如timeout超时时长，线程池大小，或信号量容量</p>
<p>然后逐渐优化这些配置，直到在一个生产系统中运作良好</p>
<p>（1）一开始先不要设置timeout超时时长，默认就是1000ms，也就是1s<br>（2）一开始也不要设置线程池大小，默认就是10<br>（3）直接部署hystrix到生产环境，如果运行的很良好，那么就让它这样运行好了<br>（4）让hystrix应用，24小时运行在生产环境中<br>（5）依赖标准的监控和报警机制来捕获到系统的异常运行情况<br>（6）在24小时之后，看一下调用延迟的占比，以及流量，来计算出让短路器生效的最小的配置数字<br>（7）直接对hystrix配置进行热修改，然后继续在hystrix dashboard上监控<br>（8）看看修改配置后的系统表现有没有改善</p>
<p>下面是根据系统表现优化和调整线程池大小，队列大小，信号量容量，以及timeout超时时间的经验</p>
<p>假设对一个依赖服务的高峰调用QPS是每秒30次</p>
<p>一开始如果默认的线程池大小是10</p>
<p>我们想的是，理想情况下，每秒的高峰访问次数 <em> 99%的访问延时 + buffer = 30 </em> 0.2 + 4 = 10线程，10个线程每秒处理30次访问应该足够了，每个线程处理3次访问</p>
<p>此时，我们合理的timeout设置应该为300ms，也就是99.5%的访问延时，计算方法是，因为判断每次访问延时最多在250ms（TP99如果是200ms的话），再加一次重试时间50ms，就是300ms，感觉也应该足够了</p>
<p>因为如果timeout设置的太多了，比如400ms，比如如果实际上，在高峰期，还有网络情况较差的时候，可能每次调用要耗费350ms，也就是达到了最长的访问时长</p>
<p>那么每个线程处理2个请求，就会执行700ms，然后处理第三个请求的时候，就超过1秒钟了，此时会导致线程池全部被占满，都在处理请求</p>
<p>这个时候下一秒的30个请求再进来了，那么就会导致线程池已满，拒绝请求的情况，就会调用fallback降级机制</p>
<p>因此对于短路器来说，timeout超时一般应该设置成TP99.5，比如设置成300ms，那么可以确保说，10个线程，每个线程处理3个访问，每个访问最多就允许执行300ms，过时就timeout了</p>
<p>这样才能保证说每个线程都在1s内执行完，才不会导致线程池被占满，然后后续的请求过来大量的reject</p>
<p>对于线程池大小来说，一般应该控制在10个左右，20个以内，最少5个，不要太多，也不要太少</p>
<p>大家可能会想，每秒的高峰访问次数是30次，如果是300次，甚至是3000次，30000次呢？？？</p>
<p>30000 * 0.2 = 6000 + buffer = 6100，一个服务器内一个线程池给6000个线程把</p>
<p>如果你一个依赖服务占据的线程数量太多的话，会导致其他的依赖服务对应的线程池里没有资源可以用了</p>
<p>6000 / 20 = 300台虚拟机也是ok的</p>
<p>虚拟机，4个cpu core，4G内存，虚拟机，300台</p>
<p>物理机，十几个cpu core，几十个G的内存，5~8个虚拟机，300个虚拟机 = 50台物理机</p>
<p>你要真的说是，你的公司服务的用户量，或者数据量，或者请求量，真要是到了每秒几万的QPS，</p>
<p>3万QPS，60 * 3 = 180万访问量，1800，1亿8千，1亿，10个小时，10亿的访问量，app，系统</p>
<p>几十台服务器去支撑，我觉得很正常</p>
<p>QPS每秒在几千都算多的了</p>
<h3 id="为什么要用线程池"><a href="#为什么要用线程池" class="headerlink" title="为什么要用线程池?"></a>为什么要用线程池?</h3><p>线程池提供了一种限制和管理资源（包括执行一个任务）。 每个线程池还维护一些基本统计信息，例如已完成任务 </p>
<p>的数量。 </p>
<p>这里借用《Java并发编程的艺术》提到的来说一下使用线程池的好处： </p>
<ul>
<li><p><strong>降低资源消耗。</strong> 通过重复利用已创建的线程降低线程创建和销毁造成的消耗。 </p>
</li>
<li><p><strong>提高响应速度。</strong> 当任务到达时，任务可以不需要的等到线程创建就能立即执行。 </p>
</li>
<li><p><strong>提高线程的可管理性。</strong> 线程是稀缺资源，如果无限制的创建，不仅会消耗系统资源，还会降低系统的稳定性， </p>
</li>
</ul>
<p>使用线程池可以进行统一的分配，调优和监控。 </p>
<h2 id="线程池的核心原理和实现方法，7大参数讲一下"><a href="#线程池的核心原理和实现方法，7大参数讲一下" class="headerlink" title="线程池的核心原理和实现方法，7大参数讲一下"></a>线程池的核心原理和实现方法，7大参数讲一下</h2><ol>
<li>corePoolSize：表示核心线程池的大小。当提交一个任务时，如果当前核心线程池的线程个数没有达到corePoolSize，则会创建新的线程来执行所提交的任务，<strong>即使当前核心线程池有空闲的线程</strong>。如果当前核心线程池的线程个数已经达到了corePoolSize，则不再重新创建线程。如果调用了prestartCoreThread()或者 prestartAllCoreThreads()，线程池创建的时候所有的核心线程都会被创建并且启动。</li>
<li>maximumPoolSize：表示线程池能创建线程的最大个数。如果当阻塞队列已满时，并且当前线程池线程个数没有超过maximumPoolSize的话，就会创建新的线程来执行任务。</li>
<li>keepAliveTime：空闲线程存活时间。如果当前线程池的线程个数已经超过了corePoolSize，并且线程空闲时间超过了keepAliveTime的话，就会将这些空闲线程销毁，这样可以尽可能降低系统资源消耗。</li>
<li>unit：时间单位。为keepAliveTime指定时间单位。</li>
<li>workQueue：阻塞队列。用于保存任务的阻塞队列，关于阻塞队列可以看这篇文章。可以使用ArrayBlockingQueue, LinkedBlockingQueue, SynchronousQueue, PriorityBlockingQueue。</li>
<li>threadFactory：创建线程的工程类。可以通过指定线程工厂为每个创建出来的线程设置更有意义的名字，如果出现并发问题，也方便查找问题原因。</li>
<li>handler：饱和策略。当线程池的阻塞队列已满和指定的线程都已经开启，说明当前线程池已经处于饱和状态了，那么就需要采用一种策略来处理这种情况。采用的策略有这几种：</li>
</ol>
<p>AbortPolicy： 直接拒绝所提交的任务，并抛出RejectedExecutionException异常；<br>CallerRunsPolicy：只用调用者所在的线程来执行任务；<br>DiscardPolicy：不处理直接丢弃掉任务；<br>DiscardOldestPolicy：丢弃掉阻塞队列中存放时间最久的任务，执行当前任务</p>
<h1 id="4-线程池的关闭"><a href="#4-线程池的关闭" class="headerlink" title="4. 线程池的关闭"></a>4. 线程池的关闭</h1><p>关闭线程池，可以通过<code>shutdown</code>和<code>shutdownNow</code>这两个方法。它们的原理都是遍历线程池中所有的线程，然后依次中断线程。<code>shutdown</code>和<code>shutdownNow</code>还是有不一样的地方：</p>
<ol>
<li><code>shutdownNow</code>首先将线程池的状态设置为<strong>STOP</strong>,然后尝试<strong>停止所有的正在执行和未执行任务</strong>的线程，并返回等待执行任务的列表；</li>
<li><code>shutdown</code>只是将线程池的状态设置为<strong>SHUTDOWN</strong>状态，然后中断所有没有正在执行任务的线程</li>
</ol>
<p>可以看出shutdown方法会将正在执行的任务继续执行完，而shutdownNow会直接中断正在执行的任务。调用了这两个方法的任意一个，<code>isShutdown</code>方法都会返回true，当所有的线程都关闭成功，才表示线程池成功关闭，这时调用<code>isTerminated</code>方法才会返回true。</p>
<p>作者：你听___<br>链接：<a href="https://juejin.im/post/5aeec0106fb9a07ab379574f" target="_blank" rel="noopener">https://juejin.im/post/5aeec0106fb9a07ab379574f</a><br>来源：掘金<br>著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。</p>
<h4 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h4><ol>
<li><p>线程池判断核心线程池是否都在执行任务。如果不是，则创建一个新的工作线程执行任务，如果都在执行任务，则进入下一个流程</p>
</li>
<li><p>线程池判断工作队列是否已经满了，如果不是，则将新提交的任务存储在这个工作队列中。如果工作队列满了，则进入下一个流程。</p>
</li>
<li><p>线程池判断线程池中的线程是否都处于工作状态，如果没有，则创建一个新的工作线程来执行任务，如果满了，则交给饱和策略来处理这个任务。</p>
</li>
</ol>
<p>提交线程有execute和submit方法，execute方法用于没有返回值的任务，submit处理有返回的callable</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/10/03/zookeeper分布式锁/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Chen ZeTao">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/weixin.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="ddd `Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/10/03/zookeeper分布式锁/" itemprop="url">zookeeper分布式锁</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-10-03T00:56:25+08:00">
                2019-10-03
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  3.1k
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  11
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="一、什么是分布式锁？"><a href="#一、什么是分布式锁？" class="headerlink" title="一、什么是分布式锁？"></a>一、什么是分布式锁？</h2><p>要介绍分布式锁，首先要提到与分布式锁相对应的是线程锁、进程锁。</p>
<p>线程锁：主要用来给方法、代码块加锁。当某个方法或代码使用锁，在同一时刻仅有一个线程执行该方法或该代码段。线程锁只在同一JVM中有效果，因为线程锁的实现在根本上是依靠线程之间共享内存实现的，比如synchronized是共享对象头，显示锁Lock是共享某个变量（state）。</p>
<p>进程锁：为了控制同一操作系统中多个进程访问某个共享资源，因为进程具有独立性，各个进程无法访问其他进程的资源，因此无法通过synchronized等线程锁实现进程锁。</p>
<p>分布式锁：当多个进程不在同一个系统中，用分布式锁控制多个进程对资源的访问。</p>
<h2 id="二、分布式锁的使用场景。"><a href="#二、分布式锁的使用场景。" class="headerlink" title="二、分布式锁的使用场景。"></a>二、分布式锁的使用场景。</h2><p>线程间并发问题和进程间并发问题都是可以通过分布式锁解决的，但是强烈不建议这样做！因为采用分布式锁解决这些小问题是非常消耗资源的！分布式锁应该用来解决分布式情况下的多进程并发问题才是最合适的。</p>
<p>有这样一个情境，线程A和线程B都共享某个变量X。</p>
<p>如果是单机情况下（单JVM），线程之间共享内存，只要使用线程锁就可以解决并发问题。</p>
<p>如果是分布式情况下（多JVM），线程A和线程B很可能不是在同一JVM中，这样线程锁就无法起到作用了，这时候就要用到分布式锁来解决。</p>
<h3 id="缓存重建问题及解决"><a href="#缓存重建问题及解决" class="headerlink" title="缓存重建问题及解决"></a>缓存重建问题及解决</h3><p>整个三级缓存的架构已经走通了</p>
<p>我们还遇到一个问题，就是说，如果缓存服务在本地的ehcache中都读取不到数据，那就恩坑爹了</p>
<p>这个时候就意味着，需要重新到源头的服务中去拉去数据，拉取到数据之后，赶紧先给nginx的请求返回，同时将数据写入ehcache和redis中</p>
<p>分布式重建缓存的并发冲突问题</p>
<p><strong>重建缓存：比如我们这里，数据在所有的缓存中都不存在了（LRU算法弄掉了），就需要重新查询数据写入缓存，重建缓存分布式的重建缓存，在不同的机器上，不同的服务实例中，去做上面的事情，就会出现多个机器分布式重建去读取相同的数据，然后写入缓存中</strong></p>
<p>分布式重建缓存的并发冲突问题。。。。。。</p>
<p>1、流量均匀分布到所有缓存服务实例上</p>
<p>应用层nginx，是将请求流量均匀地打到各个缓存服务实例中的，可能咱们的eshop-cache那个服务，可能会部署多实例在不同的机器上</p>
<p>2、应用层nginx的hash，固定商品id，走固定的缓存服务实例</p>
<p>分发层的nginx的lua脚本，是怎么写的，怎么玩儿的，搞一堆应用层nginx的地址列表，对每个商品id做一个hash，然后对应用nginx数量取模</p>
<p>将每个商品的请求固定分发到同一个应用层nginx上面去</p>
<p>在应用层nginx里，发现自己本地lua shared dict缓存中没有数据的时候，就采取一样的方式，对product id取模，然后将请求固定分发到同一个缓存服务实例中去</p>
<p>这样的话，就不会出现说多个缓存服务实例分布式的去更新那个缓存了</p>
<p>留个作业，大家去做吧，这个东西，之前已经讲解果了，lua脚本几乎都是一模一样的，我们就不去做了，节省点时间</p>
<p>3、源信息服务发送的变更消息，需要按照商品id去分区，固定的商品变更走固定的kafka分区，也就是固定的一个缓存服务实例获取到</p>
<p>缓存服务，是监听kafka topic的，一个缓存服务实例，作为一个kafka consumer，就消费topic中的一个partition</p>
<p>所以你有多个缓存服务实例的话，每个缓存服务实例就消费一个kafka partition</p>
<p>所以这里，一般来说，你的源头信息服务，在发送消息到kafka topic的时候，都需要按照product id去分区</p>
<p>也就时说，同一个product id变更的消息一定是到同一个kafka partition中去的，也就是说同一个product id的变更消息，一定是同一个缓存服务实例消费到的</p>
<p>我们也不去做了，其实很简单，kafka producer api，里面send message的时候，多加一个参数就可以了，product id传递进去，就可以了</p>
<p>4、问题是，自己写的简易的hash分发，与kafka的分区，可能并不一致！！！</p>
<p>我们自己写的简易的hash分发策略，是按照crc32去取hash值，然后再取模的</p>
<p>关键你又不知道你的kafka producer的hash策略是什么，很可能说跟我们的策略是不一样的</p>
<p>拿就可能导致说，数据变更的消息所到的缓存服务实例，跟我们的应用层nginx分发到的那个缓存服务实例也许就不在一台机器上了</p>
<p>这样的话，在高并发，极端的情况下，可能就会出现冲突</p>
<p>5、分布式的缓存重建并发冲突问题发生了。。。</p>
<p>6、基于zookeeper分布式锁的解决方案</p>
<p><strong>分布式锁，如果你有多个机器在访问同一个共享资源，那么这个时候，如果你需要加个锁，让多个分布式的机器在访问共享资源的时候串行起来</strong></p>
<p>那么这个时候，那个锁，多个不同机器上的服务共享的锁，就是分布式锁</p>
<p>分布式锁当然有很多种不同的实现方案，redis分布式锁，zookeeper分布式锁</p>
<p>zk，做分布式协调这一块，还是很流行的，大数据应用里面，hadoop，storm，都是基于zk去做分布式协调</p>
<p>zk分布式锁的解决并发冲突的方案</p>
<p>（1）变更缓存重建以及空缓存请求重建，更新redis之前，都需要先获取对应商品id的分布式锁<br>（2）拿到分布式锁之后，需要根据时间版本去比较一下，如果自己的版本新于redis中的版本，那么就更新，否则就不更新<br>（3）如果拿不到分布式锁，那么就等待，不断轮询等待，直到自己获取到分布式的锁</p>
<h3 id="分布锁实现一"><a href="#分布锁实现一" class="headerlink" title="分布锁实现一"></a>分布锁实现一</h3><p>zk分布式锁的代码封装</p>
<p>zookeeper java client api去封装连接zk，以及获取分布式锁，还有释放分布式锁的代码</p>
<p>先简单介绍一下zk分布式锁的原理</p>
<p>我们通过去创建zk的一个临时node，来模拟给摸一个商品id加锁</p>
<p>zk会给你保证说，只会创建一个临时node，其他请求过来如果再要创建临时node，就会报错，NodeExistsException</p>
<p>那么所以说，我们的所谓上锁，其实就是去创建某个product id对应的一个临时node</p>
<p>如果临时node创建成功了，那么说明我们成功加锁了，此时就可以去执行对redis立面数据的操作</p>
<p>如果临时node创建失败了，说明有人已经在拿到锁了，在操作reids中的数据，那么就不断的等待，直到自己可以获取到锁为止</p>
<p>基于zk client api，去封装上面的这个代码逻辑</p>
<p>释放一个分布式锁，去删除掉那个临时node就可以了，就代表释放了一个锁，那么此时其他的机器就可以成功创建临时node，获取到锁</p>
<p>即使是用zk去实现一个分布式锁，也有很多种做法，有复杂的，也有简单的</p>
<p>应该说，我演示的这种分布式锁的做法，是非常简单的一种，但是很实用，大部分情况下，用这种简单的分布式锁都能搞定</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">连接zookeeper客户端实例代码逻辑：</span><br><span class="line">使用countdownlauch来控制多线程的并发。</span><br><span class="line">CountDownLatch connectedSemaphore = new CountDownLatch(1);</span><br><span class="line">zookeeper在连接客户端的时候，是一个异步的过程，在连接的下一步中通过connectedSemaphore.await()阻塞线程。封装一个监听器，监听zookeeper连接，当连接成功的时候，connectedSemaphore.countdown(),释放线程。</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">分布式加锁封装逻辑：</span><br><span class="line">通过商品id创建一个zookeeper临时节点，如果创建失败，说明此时有人已经创建了。会抛出异常，那么在catch中进入死循环，不断的尝试创建临时节点，直到创建成功，跳出死循环。</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">分布式释放锁的逻辑：</span><br><span class="line">释放一个分布式锁，只要删除这个商品id创建的临时节点就可以。</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">&lt;dependency&gt;</span><br><span class="line">    &lt;groupId&gt;org.apache.zookeeper&lt;/groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;zookeeper&lt;/artifactId&gt;</span><br><span class="line">    &lt;version&gt;3.4.5&lt;/version&gt;</span><br><span class="line">&lt;/dependency&gt;</span><br><span class="line"></span><br><span class="line">/**</span><br><span class="line"> * ZooKeeperSession</span><br><span class="line"> * @author Administrator</span><br><span class="line"> *</span><br><span class="line"> */</span><br><span class="line">public class ZooKeeperSession &#123;</span><br><span class="line">	</span><br><span class="line">	private static CountDownLatch connectedSemaphore = new CountDownLatch(1);</span><br><span class="line">	</span><br><span class="line">	private ZooKeeper zookeeper;</span><br><span class="line"></span><br><span class="line">	public ZooKeeperSession() &#123;</span><br><span class="line">		// 去连接zookeeper server，创建会话的时候，是异步去进行的</span><br><span class="line">		// 所以要给一个监听器，说告诉我们什么时候才是真正完成了跟zk server的连接</span><br><span class="line">		try &#123;</span><br><span class="line">			this.zookeeper = new ZooKeeper(</span><br><span class="line">					&quot;192.168.31.187:2181,192.168.31.19:2181,192.168.31.227:2181&quot;, </span><br><span class="line">					50000, </span><br><span class="line">					new ZooKeeperWatcher());</span><br><span class="line">			// 给一个状态CONNECTING，连接中</span><br><span class="line">			System.out.println(zookeeper.getState());</span><br><span class="line">			</span><br><span class="line">			try &#123;</span><br><span class="line">				// CountDownLatch</span><br><span class="line">				// java多线程并发同步的一个工具类</span><br><span class="line">				// 会传递进去一些数字，比如说1,2 ，3 都可以</span><br><span class="line">				// 然后await()，如果数字不是0，那么久卡住，等待</span><br><span class="line">				</span><br><span class="line">				// 其他的线程可以调用coutnDown()，减1</span><br><span class="line">				// 如果数字减到0，那么之前所有在await的线程，都会逃出阻塞的状态</span><br><span class="line">				// 继续向下运行</span><br><span class="line">				</span><br><span class="line">				connectedSemaphore.await();</span><br><span class="line">			&#125; catch(InterruptedException e) &#123;</span><br><span class="line">				e.printStackTrace();</span><br><span class="line">			&#125;</span><br><span class="line">	</span><br><span class="line">			System.out.println(&quot;ZooKeeper session established......&quot;);</span><br><span class="line">		&#125; catch (Exception e) &#123;</span><br><span class="line">			e.printStackTrace();</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	</span><br><span class="line">	/**</span><br><span class="line">	 * 获取分布式锁</span><br><span class="line">	 * @param productId</span><br><span class="line">	 */</span><br><span class="line">	public void acquireDistributedLock(Long productId) &#123;</span><br><span class="line">		String path = &quot;/product-lock-&quot; + productId;</span><br><span class="line">	</span><br><span class="line">		try &#123;</span><br><span class="line">			zookeeper.create(path, &quot;&quot;.getBytes(), </span><br><span class="line">					Ids.OPEN_ACL_UNSAFE, CreateMode.EPHEMERAL);</span><br><span class="line">			System.out.println(&quot;success to acquire lock for product[id=&quot; + productId + &quot;]&quot;);  </span><br><span class="line">		&#125; catch (Exception e) &#123;</span><br><span class="line">			// 如果那个商品对应的锁的node，已经存在了，就是已经被别人加锁了，那么就这里就会报错</span><br><span class="line">			// NodeExistsException</span><br><span class="line">			int count = 0;</span><br><span class="line">			while(true) &#123;</span><br><span class="line">				try &#123;</span><br><span class="line">					Thread.sleep(20); </span><br><span class="line">					zookeeper.create(path, &quot;&quot;.getBytes(), </span><br><span class="line">							Ids.OPEN_ACL_UNSAFE, CreateMode.EPHEMERAL);</span><br><span class="line">				&#125; catch (Exception e2) &#123;</span><br><span class="line">					e2.printStackTrace();</span><br><span class="line">					count++;</span><br><span class="line">					continue;</span><br><span class="line">				&#125;</span><br><span class="line">				System.out.println(&quot;success to acquire lock for product[id=&quot; + productId + &quot;] after &quot; + count + &quot; times try......&quot;);</span><br><span class="line">				break;</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	</span><br><span class="line">	/**</span><br><span class="line">	 * 释放掉一个分布式锁</span><br><span class="line">	 * @param productId</span><br><span class="line">	 */</span><br><span class="line">	public void releaseDistributedLock(Long productId) &#123;</span><br><span class="line">		String path = &quot;/product-lock-&quot; + productId;</span><br><span class="line">		try &#123;</span><br><span class="line">			zookeeper.delete(path, -1); </span><br><span class="line">		&#125; catch (Exception e) &#123;</span><br><span class="line">			e.printStackTrace();</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	</span><br><span class="line">	/**</span><br><span class="line">	 * 建立zk session的watcher</span><br><span class="line">	 * @author Administrator</span><br><span class="line">	 *</span><br><span class="line">	 */</span><br><span class="line">	private class ZooKeeperWatcher implements Watcher &#123;</span><br><span class="line"></span><br><span class="line">		public void process(WatchedEvent event) &#123;</span><br><span class="line">			System.out.println(&quot;Receive watched event: &quot; + event.getState());</span><br><span class="line">			if(KeeperState.SyncConnected == event.getState()) &#123;</span><br><span class="line">				connectedSemaphore.countDown();</span><br><span class="line">			&#125; </span><br><span class="line">		&#125;</span><br><span class="line">		</span><br><span class="line">	</span><br><span class="line">	&#125;</span><br><span class="line">	</span><br><span class="line">	/**</span><br><span class="line">	 * 封装单例的静态内部类</span><br><span class="line">	 * @author Administrator</span><br><span class="line">	 *</span><br><span class="line">	 */</span><br><span class="line">	private static class Singleton &#123;</span><br><span class="line">		</span><br><span class="line">		private static ZooKeeperSession instance;</span><br><span class="line">		</span><br><span class="line">		static &#123;</span><br><span class="line">			instance = new ZooKeeperSession();</span><br><span class="line">		&#125;</span><br><span class="line">		</span><br><span class="line">		public static ZooKeeperSession getInstance() &#123;</span><br><span class="line">			return instance;</span><br><span class="line">		&#125;</span><br><span class="line">		</span><br><span class="line">	</span><br><span class="line">	&#125;</span><br><span class="line">	</span><br><span class="line">	/**</span><br><span class="line">	 * 获取单例</span><br><span class="line">	 * @return</span><br><span class="line">	 */</span><br><span class="line">	public static ZooKeeperSession getInstance() &#123;</span><br><span class="line">		return Singleton.getInstance();</span><br><span class="line">	&#125;</span><br><span class="line">	</span><br><span class="line">	/**</span><br><span class="line">	 * 初始化单例的便捷方法</span><br><span class="line">	 */</span><br><span class="line">	public static void init() &#123;</span><br><span class="line">		getInstance();</span><br><span class="line">	&#125;</span><br><span class="line">	</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="获取分布式锁写缓存的业务逻辑"><a href="#获取分布式锁写缓存的业务逻辑" class="headerlink" title="获取分布式锁写缓存的业务逻辑"></a>获取分布式锁写缓存的业务逻辑</h3><p>业务代码</p>
<p>1、主动更新</p>
<p>监听kafka消息队列，获取到一个商品变更的消息之后，去哪个源服务中调用接口拉取数据，更新到ehcache和redis中</p>
<p>先获取分布式锁，然后才能更新redis，同时更新时要比较时间版本</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">先获取分布式锁，从redis中拿取相同key的商品id的缓存数据，比较时间版本，如果时间更新，则覆盖缓存，反之，不更新缓存。</span><br></pre></td></tr></table></figure>
<p>2、被动重建 </p>
<p>直接读取源头数据，直接返回给nginx，同时推送一条消息到一个队列，后台线程异步消费</p>
<p>后台现成负责先获取分布式锁，然后才能更新redis，同时要比较时间版本</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/10/02/模拟第二天/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Chen ZeTao">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/weixin.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="ddd `Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/10/02/模拟第二天/" itemprop="url">模拟第二天</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-10-02T22:41:46+08:00">
                2019-10-02
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  2k
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  7
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h3 id="HTTPS的工作原理"><a href="#HTTPS的工作原理" class="headerlink" title="HTTPS的工作原理"></a>HTTPS的工作原理</h3><p>（1）客户使用https的URL访问Web服务器，要求与Web服务器建立SSL连接。</p>
<p>　　（2）Web服务器收到客户端请求后，会将网站的证书信息（证书中包含公钥）传送一份给客户端。</p>
<p>　　（3）客户端的浏览器与Web服务器开始协商SSL连接的安全等级，也就是信息加密的等级。</p>
<p>　　（4）客户端的浏览器根据双方同意的安全等级，建立会话密钥，然后利用网站的公钥将会话密钥加密，并传送给网站。</p>
<p>　　（5）Web服务器利用自己的私钥解密出会话密钥。</p>
<p>　　（6）Web服务器利用会话密钥加密与客户端之间的通信。</p>
<p>  <img src="https://pic002.cnblogs.com/images/2012/339704/2012071410212142.gif" alt="img"></p>
<h3 id="Synchronized和ReentrantLock的区别"><a href="#Synchronized和ReentrantLock的区别" class="headerlink" title="Synchronized和ReentrantLock的区别"></a>Synchronized和ReentrantLock的区别</h3><h4 id="①-两者都是可重入锁"><a href="#①-两者都是可重入锁" class="headerlink" title="① 两者都是可重入锁"></a>① 两者都是可重入锁</h4><p>两者都是可重入锁。“可重入锁”概念是：自己可以再次获取自己的内部锁。比如一个线程获得了某个对象的锁，此时这个对象锁还没有释放，当其再次想要获取这个对象的锁的时候还是可以获取的，如果不可锁重入的话，就会造成死锁。同一个线程每次获取锁，锁的计数器都自增1，所以要等到锁的计数器下降为0时才能释放锁。 </p>
<h4 id="②synchronized依赖于JVM而ReenTrantLock依赖于API"><a href="#②synchronized依赖于JVM而ReenTrantLock依赖于API" class="headerlink" title="②synchronized依赖于JVM而ReenTrantLock依赖于API"></a>②synchronized依赖于JVM而ReenTrantLock依赖于API</h4><p>synchronized 是依赖于 JVM 实现的，前面我们也讲到了 虚拟机团队在 JDK1.6 为 synchronized 关键字进行了很多优化，但是这些优化都是在虚拟机层面实现的，并没有直接暴露给我们。ReenTrantLock 是 JDK 层面实现的（也就是 API 层面，需要 lock() 和 unlock 方法配合 try/fifinally 语句块来完成），所以我们可以通过查看它的源代码，来看它是如何实现的。 </p>
<h4 id="③ReenTrantLock比synchronized增加了一些高级功能"><a href="#③ReenTrantLock比synchronized增加了一些高级功能" class="headerlink" title="③ReenTrantLock比synchronized增加了一些高级功能"></a>③ReenTrantLock比synchronized增加了一些高级功能</h4><p>相比synchronized，ReenTrantLock增加了一些高级功能。主要来说主要有三点：</p>
<ul>
<li><p>①等待可中断<br>ReenTrantLock提供了一种能够中断等待锁的线程的机制，通过lock.lockInterruptibly()来实现这个机制。也就是说正在等待的线程可以选择放弃等待，改为处理其他事情。 </p>
</li>
<li><p>②可实现公平锁<br>ReenTrantLock可以指定是公平锁还是非公平锁。而synchronized只能是非公平锁。所谓的公平锁就是先等待的线程先获得锁。ReenTrantLock默认情况是非公平的，可以通过 ReenTrantLock类的<br>ReentrantLock(boolean fair) 构造方法来制定是否是公平的。 </p>
</li>
<li><p>③可实现选择性通知（锁可以绑定多个条件）<br>synchronized关键字与wait()和notify/notifyAll()方法相结合可以实现等待/通知机制，ReentrantLock类当然也 可以实现，但是需要借助于Condition接口与newCondition() 方法。</p>
<p>Condition是JDK1.5之后才有的，它具有很好的灵活性，比如可以实现多路通知功能也就是在一个Lock对象中可以创建多个Condition实例（即对象监视器），线程对象可以注册在指定的Condition中，从而可以有选择性的进行线程通知，在调度线程上更加灵活。 在使用notify/notifyAll()方法进行通知时，被通知的线程是由JVM选择的，用ReentrantLock类结合Condition实例可以实现”选择性通知”，这个功能非常重要，而且是Condition接口默认提供的。而 synchronized关键字就相当于整个Lock对象中只有一个Condition实例，所有的线程都注册在它一个身上。如果执行notifyAll()方法的话就会通知所有处于等待状态的线程这样会造成很大的效率问题，而Condition实例的 signalAll()方法 只会唤醒注册在该Condition实例中的所有等待线程。 </p>
</li>
</ul>
<h3 id="聚簇索引和非聚簇索引（二级索引）"><a href="#聚簇索引和非聚簇索引（二级索引）" class="headerlink" title="聚簇索引和非聚簇索引（二级索引）"></a>聚簇索引和非聚簇索引（二级索引）</h3><p><strong>myisam索引：因为myisam的索引和数据是分开存储存储的，myisam通过key_buffer把索引先缓存到内存中，当需要访问数据时（通过索引访问数据），在内存中直接搜索索引，然后通过索引找到磁盘相应数据，这也就是为什么索引不在key buffer命中时，速度慢的原因  </strong></p>
<p><strong>innodb索引：innodb的数据和索引放在一起，当找到索引也就找到了数据</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">MySQL的BTree索引使用的是B树中的B+Tree，但对于主要的两种存储引擎的实现方式是不同的。</span><br><span class="line"></span><br><span class="line">MyISAM: B+Tree叶节点的data域存放的是数据记录的地址。在索引检索的时候，首先按照B+Tree搜索算法搜索索引，如果指定的Key存在，则取出其 data 域的值，然后以 data 域的值为地址读取相应的数据记录。这被称为“非聚簇索引”。</span><br><span class="line">InnoDB: 其数据文件本身就是索引文件。相比MyISAM，索引文件和数据文件是分离的，其表数据文件本身就是按B+Tree组织的一个索引结构，树的叶节点data域保存了完整的数据记录。这个索引的key是数据表的主键，因此InnoDB表数据文件本身就是主索引。这被称为“聚簇索引（或聚集索引）”。而其余的索引都作为辅助索引，辅助索引的data域存储相应记录主键的值而不是地址，这也是和MyISAM不同的地方。在根据主索引搜索时，直接找到key所在的节点即可取出数据；在根据辅助索引查找时，则需要先取出主键的值，再走一遍主索引。 因此，在设计表的时候，不建议使用过长的字段作为主键，也不建议使用非单调的字段作为主键，这样会造成主索引频繁分裂。 PS：整理自《Java工程师修炼之道》</span><br></pre></td></tr></table></figure>
<p>mysql的聚簇索引是指innodb引擎的特性，mysiam并没有，如果需要该索引，只要将索引指定为主键（primary key）就可以了。</p>
<p>比如：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> blog_user</span><br><span class="line">(</span><br><span class="line">  user_Name <span class="built_in">char</span>(<span class="number">15</span>) <span class="keyword">not</span> <span class="literal">null</span> <span class="keyword">check</span>(user_Name !=<span class="string">''</span>),</span><br><span class="line">  user_Password <span class="built_in">char</span>(<span class="number">15</span>) <span class="keyword">not</span> <span class="literal">null</span>,</span><br><span class="line">  user_emial <span class="built_in">varchar</span>(<span class="number">20</span>) <span class="keyword">not</span> <span class="literal">null</span> <span class="keyword">unique</span>,</span><br><span class="line">  primary <span class="keyword">key</span>(user_Name)          </span><br><span class="line"></span><br><span class="line">)<span class="keyword">engine</span>=<span class="keyword">innodb</span> <span class="keyword">default</span> <span class="keyword">charset</span>=utf8 auto_increment=<span class="number">1</span>;</span><br></pre></td></tr></table></figure>
<p>其中的 primary key(user_Name) 这个就是聚簇索引索引了；<br>聚簇索引的叶节点就是数据节点，而非聚簇索引的叶节点仍然是索引节点，并保留一个链接指向对应数据块。</p>
<p>聚簇索引主键的插入速度要比非聚簇索引主键的插入速度慢很多。相比之下，聚簇索引适合排序，非聚簇索引（也叫二级索引）不适合用在排序的场合。<br>因为聚簇索引本身已经是按照物理顺序放置的，排序很快。非聚簇索引则没有按序存放，需要额外消耗资源来排序。<br>当你需要取出一定范围内的数据时，用聚簇索引也比用非聚簇索引好。<br>另外，二级索引需要两次索引查找，而不是一次才能取到数据，因为存储引擎第一次需要通过二级索引找到索引的叶子节点，从而找到数据的主键，然后在聚簇索引中用主键再次查找索引，再找到数据。</p>
<p>innodb索引分类：<br>聚簇索引(clustered index)<br>    1)  有主键时，根据主键创建聚簇索引<br>    2)  没有主键时，会用一个唯一且不为空的索引列做为主键，成为此表的聚簇索引<br>    3) 如果以上两个都不满足那innodb自己创建一个虚拟的聚集索引<br>辅助索引(secondary index)<br>   非聚簇索引都是辅助索引，像复合索引、前缀索引、唯一索引<br>————————————————<br>版权声明：本文为CSDN博主「大树叶」的原创文章，遵循 CC 4.0 BY-SA 版权协议，转载请附上原文出处链接及本声明。<br>原文链接：<a href="https://blog.csdn.net/bigtree_3721/article/details/51335479" target="_blank" rel="noopener">https://blog.csdn.net/bigtree_3721/article/details/51335479</a></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/10/02/zookeeper-kafka/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Chen ZeTao">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/weixin.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="ddd `Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/10/02/zookeeper-kafka/" itemprop="url">zookeeper+kafka+nginx</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-10-02T19:37:21+08:00">
                2019-10-02
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  1.9k
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  7
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h3 id="zookeeper-与-kafka集群的搭建"><a href="#zookeeper-与-kafka集群的搭建" class="headerlink" title="zookeeper 与 kafka集群的搭建"></a>zookeeper 与 kafka集群的搭建</h3><p>多级缓存的架构</p>
<p>主要是用来解决什么样的数据的缓存的更新的啊？？？</p>
<p>时效性不高的数据，比如一些商品的基本信息，如果发生了变更，假设在5分钟之后再更新到页面中，供用户观察到，也是ok的</p>
<p>时效性要求不高的数据，那么我们采取的是异步更新缓存的策略</p>
<p>时效性要求很高的数据，库存，采取的是数据库+缓存双写的技术方案，也解决了双写的一致性的问题</p>
<p>缓存数据生产服务，监听一个消息队列，然后数据源服务（商品信息管理服务）发生了数据变更之后，就将数据变更的消息推送到消息队列中</p>
<p>缓存数据生产服务可以去消费到这个数据变更的消息，然后根据消息的指示提取一些参数，然后调用对应的数据源服务的接口，拉去数据，这个时候一般是从mysql库中拉去的</p>
<p>消息队列是什么东西？采取打的就是kafka</p>
<p>我工作的时候，很多项目是跟大数据相关的，当然也有很多是纯java系统的架构，最近用kafka用得比较多</p>
<p>kafka比较简单易用，讲课来说，很方便</p>
<p>解释一下，我们当然是不可能对课程中涉及的各种技术都深入浅出的讲解的了，kafka，花上20个小时给你讲解一下，不可能的</p>
<p>所以说呢，在这里，一些技术的组合，用什么都ok</p>
<p>笑傲江湖中的风清扬，手中无剑胜有剑，还有任何东西都可以当做兵器，哪怕是一根草也可以</p>
<p>搞技术，kafka和activemq肯定有区别，但是说，在有些场景下，其实可能没有那么大的区分度，kafka和activemq其实是一样的</p>
<p>生产者+消费者的场景，kafka+activemq都ok</p>
<p>涉及的这种架构，对时效性要求高和时效性要求低的数据，分别采取什么技术方案？数据库+缓存双写一致性？异步+多级缓存架构？大缓存的维度化拆分？</p>
<p>你要关注的，是一些架构上的东西和思想，而不是具体的什么mq的使用</p>
<p>activemq的课程，书籍，资料</p>
<p>kafka集群，zookeeper集群，先搭建zookeeper集群，再搭建kafka集群</p>
<p>kafka另外一个原因：kafka，本来就要搭建zookeeper，zookeeper这个东西，后面我们还要用呢，缓存的分布式并发更新的问题，分布式锁解决</p>
<p>zookeeper + kafka的集群，都是三节点</p>
<p>java高级工程师的思想，在干活儿，在思考，jvm，宏观的思考，通盘去考虑整个架构，还有未来的技术规划，业务的发展方向，架构的演进方向和路线</p>
<p>把课程里讲解的各种技术方案组合成、修改成你需要的适合你的业务的缓存架构</p>
<p>1、zookeeper集群搭建</p>
<p>将课程提供的zookeeper-3.4.5.tar.gz使用WinSCP拷贝到/usr/local目录下。<br>对zookeeper-3.4.5.tar.gz进行解压缩：tar -zxvf zookeeper-3.4.5.tar.gz。<br>对zookeeper目录进行重命名：mv zookeeper-3.4.5 zk</p>
<p>配置zookeeper相关的环境变量<br>vi ~/.bashrc<br>export ZOOKEEPER_HOME=/usr/local/zk<br>export PATH=$PATH:$ZOOKEEPER_HOME/bin</p>
<p>source ~/.bashrc</p>
<p>cd zk/conf<br>cp zoo_sample.cfg zoo.cfg</p>
<p>vi zoo.cfg<br>修改：dataDir=/usr/local/zk/data<br>新增：<br>server.0=eshop-cache01:2888:3888<br>server.1=eshop-cache02:2888:3888<br>server.2=eshop-cache03:2888:3888</p>
<p>cd zk<br>mkdir data<br>cd data</p>
<p>vi myid<br>0</p>
<p>在另外两个节点上按照上述步骤配置ZooKeeper，使用scp将zk和.bashrc拷贝到eshop-cache02和eshop-cache03上即可。唯一的区别是标识号分别设置为1和2。</p>
<p>分别在三台机器上执行：zkServer.sh start。<br>检查ZooKeeper状态：zkServer.sh status，应该是一个leader，两个follower<br>jps：检查三个节点是否都有QuromPeerMain进程</p>
<p>2、kafka集群搭建</p>
<p>scala，我就不想多说了，就是一门编程语言，现在比较火，很多比如大数据领域里面的spark（计算引擎）就是用scala编写的</p>
<p>将课程提供的scala-2.11.4.tgz使用WinSCP拷贝到/usr/local目录下。<br>对scala-2.11.4.tgz进行解压缩：tar -zxvf scala-2.11.4.tgz。<br>对scala目录进行重命名：mv scala-2.11.4 scala</p>
<p>配置scala相关的环境变量<br>vi ~/.bashrc<br>export SCALA_HOME=/usr/local/scala<br>export PATH=$SCALA_HOME/bin<br>source ~/.bashrc</p>
<p>查看scala是否安装成功：scala -version</p>
<p>按照上述步骤在其他机器上都安装好scala。使用scp将scala和.bashrc拷贝到另外两台机器上即可。</p>
<p>将课程提供的kafka_2.9.2-0.8.1.tgz使用WinSCP拷贝到/usr/local目录下。<br>对kafka_2.9.2-0.8.1.tgz进行解压缩：tar -zxvf kafka_2.9.2-0.8.1.tgz。<br>对kafka目录进行改名：mv kafka_2.9.2-0.8.1 kafka</p>
<p>配置kafka<br>vi /usr/local/kafka/config/server.properties<br>broker.id：依次增长的整数，0、1、2，集群中Broker的唯一id<br>zookeeper.connect=192.168.31.187:2181,192.168.31.19:2181,192.168.31.227:2181</p>
<p>安装slf4j<br>将课程提供的slf4j-1.7.6.zip上传到/usr/local目录下<br>unzip slf4j-1.7.6.zip<br>把slf4j中的slf4j-nop-1.7.6.jar复制到kafka的libs目录下面</p>
<p>解决kafka Unrecognized VM option ‘UseCompressedOops’问题</p>
<p>vi /usr/local/kafka/bin/kafka-run-class.sh </p>
<p>if [ -z “$KAFKA_JVM_PERFORMANCE_OPTS” ]; then<br>  KAFKA_JVM_PERFORMANCE_OPTS=”-server  -XX:+UseCompressedOops -XX:+UseParNewGC -XX:+UseConcMarkSweepGC -XX:+CMSClassUnloadingEnabled -XX:+CMSScavengeBeforeRemark -XX:+DisableExplicitGC -Djava.awt.headless=true”<br>fi</p>
<p>去掉-XX:+UseCompressedOops即可</p>
<p>按照上述步骤在另外两台机器分别安装kafka。用scp把kafka拷贝到其他机器即可。<br>唯一区别的，就是server.properties中的broker.id，要设置为1和2</p>
<p>在三台机器上的kafka目录下，分别执行以下命令：nohup bin/kafka-server-start.sh config/server.properties &amp;</p>
<p>使用jps检查启动是否成功</p>
<p>使用基本命令检查kafka是否搭建成功</p>
<p>bin/kafka-topics.sh –zookeeper 192.168.229.7:2181,192.168.229.8:2181,192.168.229.9:2181 –topic test –replication-factor 1 –partitions 1 –create</p>
<p>bin/kafka-console-producer.sh –broker-list 192.168.229.7:9092,192.168.229.8:9092,192.168.229.9:9092 –topic test</p>
<p>bin/kafka-console-consumer.sh –bootstrap-server 192.168.229.7:9092,192.168.229.8:9092,192.168.229.9:9092 –topic test –from-beginning</p>
<h3 id="基于“分发层-应用层”双层nginx架构提升缓存命中率"><a href="#基于“分发层-应用层”双层nginx架构提升缓存命中率" class="headerlink" title="基于“分发层+应用层”双层nginx架构提升缓存命中率"></a>基于“分发层+应用层”双层nginx架构提升缓存命中率</h3><p>1、缓存命中率低</p>
<p>缓存数据生产服务那一层已经搞定了，相当于三层缓存架构中的本地堆缓存+redis分布式缓存都搞定了</p>
<p>就要来做三级缓存中的nginx那一层的缓存了</p>
<p>如果一般来说，你默认会部署多个nginx，在里面都会放一些缓存，就默认情况下，此时缓存命中率是比较低的</p>
<p>2、如何提升缓存命中率</p>
<p>分发层+应用层，双层nginx</p>
<p>分发层nginx，负责流量分发的逻辑和策略，这个里面它可以根据你自己定义的一些规则，比如根据productId去进行hash，然后对后端的nginx数量取模</p>
<p>将某一个商品的访问的请求，就固定路由到一个nginx后端服务器上去，保证说只会从redis中获取一次缓存数据，后面全都是走nginx本地缓存了</p>
<p>后端的nginx服务器，就称之为应用服务器; 最前端的nginx服务器，被称之为分发服务器</p>
<p>看似很简单，其实很有用，在实际的生产环境中，可以大幅度提升你的nginx本地缓存这一层的命中率，大幅度减少redis后端的压力，提升性能</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/10/02/模拟第一天/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Chen ZeTao">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/weixin.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="ddd `Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/10/02/模拟第一天/" itemprop="url">模拟第一天</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-10-02T11:06:55+08:00">
                2019-10-02
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  1.5k
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  5
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="java创建对象有几种方式"><a href="#java创建对象有几种方式" class="headerlink" title="java创建对象有几种方式"></a>java创建对象有几种方式</h2><ol>
<li>使用new关键字：这是我们最常见的也是最简单的创建对象的方式，通过这种方式我们还可以调用任意的够赞函数（无参的和有参的）。比如：Student student = new Student();</li>
<li>使用Class类的newInstance方法：我们也可以使用Class类的newInstance方法创建对象，这个newInstance方法调用无参的构造器创建对象，如：Student student2 = (Student)Class.forName(“根路径.Student”).newInstance();　或者：Student stu = Student.class.newInstance();</li>
<li>使用Constructor类的newInstance方法：本方法和Class类的newInstance方法很像，java.lang.relect.Constructor类里也有一个newInstance方法可以创建对象。我们可以通过这个newInstance方法调用有参数的和私有的构造函数。如： Constructor<student> constructor = Student.class.getInstance(); Student stu = constructor.newInstance();　这两种newInstance的方法就是大家所说的反射，事实上Class的newInstance方法内部调用Constructor的newInstance方法。这也是众多框架Spring、Hibernate、Struts等使用后者的原因。</student></li>
<li>使用Clone的方法：无论何时我们调用一个对象的clone方法，JVM就会创建一个新的对象，将前面的对象的内容全部拷贝进去，用clone方法创建对象并不会调用任何构造函数。要使用clone方法，我们必须先实现Cloneable接口并实现其定义的clone方法。如：Student stu2 = <student>stu.clone();这也是原型模式的应用。</student></li>
<li>使用反序列化：当我们序列化和反序列化一个对象，JVM会给我们创建一个单独的对象，在反序列化时，JVM创建对象并不会调用任何构造函数。为了反序列化一个对象，我们需要让我们的类实现Serializable接口。如：ObjectInputStream in = new ObjectInputStream (new FileInputStream(“data.obj”)); Student stu3 = (Student)in.readObject();</li>
</ol>
<h2 id="浅拷贝与深拷贝的区别？怎么实现深拷贝"><a href="#浅拷贝与深拷贝的区别？怎么实现深拷贝" class="headerlink" title="浅拷贝与深拷贝的区别？怎么实现深拷贝"></a>浅拷贝与深拷贝的区别？怎么实现深拷贝</h2><p>浅拷贝：创建一个新对象，然后将当前对象的非静态字段复制到该新对象，如果字段是值类型的，那么对该字段执行复制；如果该字段是引用类型的话，则复制引用但不复制引用的对象。因此，原始对象及其副本引用同一个对象。</p>
<p>深拷贝：创建一个新对象，然后将当前对象的非静态字段复制到该新对象，无论该字段是值类型的还是引用类型，都复制独立的一份。当你修改其中一个对象的任何内容时，都不会影响另一个对象的内容。</p>
<p>使用clone方法的对象需要是实现cloneable接口</p>
<p> ①、让每个引用类型属性内部都重写clone() 方法<br>②、利用序列化<br><a href="https://blog.csdn.net/baiye_xing/article/details/71788741" target="_blank" rel="noopener">https://blog.csdn.net/baiye_xing/article/details/71788741</a></p>
<h2 id="SQL注入原理，mybatis怎么实现sql注入"><a href="#SQL注入原理，mybatis怎么实现sql注入" class="headerlink" title="SQL注入原理，mybatis怎么实现sql注入"></a>SQL注入原理，mybatis怎么实现sql注入</h2><p><a href="https://czetao.github.io/2019/10/01/SQL注入/" target="_blank" rel="noopener">https://czetao.github.io/2019/10/01/SQL%E6%B3%A8%E5%85%A5/</a></p>
<h2 id="threadlocal使用需要注意什么问题？"><a href="#threadlocal使用需要注意什么问题？" class="headerlink" title="threadlocal使用需要注意什么问题？"></a>threadlocal使用需要注意什么问题？</h2><p>threadlocal–&gt;threadlocalmap —&gt;Entry&lt;threadlocal,value&gt;</p>
<p><a href="https://blog.csdn.net/LHQJ1992/article/details/52451136" target="_blank" rel="noopener">https://blog.csdn.net/LHQJ1992/article/details/52451136</a><br><a href="https://blog.csdn.net/qq_33404395/article/details/82356344" target="_blank" rel="noopener">https://blog.csdn.net/qq_33404395/article/details/82356344</a></p>
<p><img src="https://img-blog.csdn.net/20180903125233171?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzMzNDA0Mzk1/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt></p>
<p>ThreadLocal的实现是这样的：每个Thread 维护一个 ThreadLocalMap 映射表，这个映射表的 key 是 ThreadLocal实例本身，value 是真正需要存储的 Object。<br>也就是说 ThreadLocal 本身并不存储值，它只是作为一个 key 来让线程从 ThreadLocalMap 获取 value。<br>值得注意的是图中的虚线，表示 ThreadLocalMap 是使用 ThreadLocal 的弱引用作为 Key 的，弱引用的对象在 GC 时会被回收。</p>
<p>ThreadLocalMap使用ThreadLocal的弱引用作为key，如果一个ThreadLocal没有外部强引用来引用它，那么系统 GC 的时候，这个ThreadLocal势必会被回收，这样一来，ThreadLocalMap中就会出现key为null的Entry，就没有办法访问这些key为null的Entry的value，如果当前线程再迟迟不结束的话，这些key为null的Entry的value就会一直存在一条强引用链：Thread Ref -&gt; Thread -&gt; ThreaLocalMap -&gt; Entry -&gt; value永远无法回收，造成内存泄漏。<br>————————————————<br>版权声明：本文为CSDN博主「WangCw的夏天」的原创文章，遵循 CC 4.0 BY-SA 版权协议，转载请附上原文出处链接及本声明。<br>原文链接：<a href="https://blog.csdn.net/qq_33404395/article/details/82356344" target="_blank" rel="noopener">https://blog.csdn.net/qq_33404395/article/details/82356344</a></p>
<h3 id="为何HashMap的数组长度一定是2的次幂？"><a href="#为何HashMap的数组长度一定是2的次幂？" class="headerlink" title="为何HashMap的数组长度一定是2的次幂？"></a>为何HashMap的数组长度一定是2的次幂？</h3><p>hashMap的数组长度一定保持2的次幂，比如16的二进制表示为 10000，那么length-1就是15，二进制为01111，同理扩容后的数组长度为32，二进制表示为100000，length-1为31，二进制表示为011111。从下图可以我们也能看到这样会保证低位全为1，而扩容后只有一位差异，也就是多出了最左位的1，这样在通过 h&amp;(length-1)的时候，只要h对应的最左边的那一个差异位为0，就能保证得到的新的数组索引和老数组索引一致(大大减少了之前已经散列良好的老数组的数据位置重新调换)，个人理解。</p>
<p> 还有，数组长度保持2的次幂，length-1的低位都为1，会使得获得的数组索引index更加均匀，比如：</p>
<p>　　我们看到，上面的&amp;运算，高位是不会对结果产生影响的（hash函数采用各种位运算可能也是为了使得低位更加散列），我们只关注低位bit，如果低位全部为1，那么对于h低位部分来说，任何一位的变化都会对结果产生影响，也就是说，要得到index=21这个存储位置，h的低位只有这一种组合。这也是数组长度设计为必须为2的次幂的原因。</p>
<p><strong>当length-1时，低位都是111，可以保证key低位的唯一性</strong></p>
<p>　　如果不是2的次幂，也就是低位不是全为1此时，要使得index=21，h的低位部分不再具有唯一性了，哈希冲突的几率会变的更大，同时，index对应的这个bit位无论如何不会等于1了，而对应的那些数组位置也就被白白浪费了。</p>
<p><a href="https://www.cnblogs.com/chengxiao/p/6059914.html#t3" target="_blank" rel="noopener">https://www.cnblogs.com/chengxiao/p/6059914.html#t3</a></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/10/01/redis详解、/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Chen ZeTao">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/weixin.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="ddd `Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/10/01/redis详解、/" itemprop="url">redis详解、</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-10-01T17:52:57+08:00">
                2019-10-01
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  14.5k
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  53
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h3 id="要掌握的很好的，就是redis架构"><a href="#要掌握的很好的，就是redis架构" class="headerlink" title="要掌握的很好的，就是redis架构"></a>要掌握的很好的，就是redis架构</h3><ul>
<li>安装一个虚拟机集群</li>
<li>安装redis集群</li>
<li>配置持久化<ul>
<li>RDB 快照手动设置检查点（etc/redis/redis.conf 里面可以修改save）</li>
</ul>
</li>
</ul>
<p>高并发，高可用，海量数据，备份，随时可以恢复，</p>
<p>redis架构，每秒钟几十万的访问量QPS，99.99%的高可用性，TB级的海量数据，备份和恢复，缓存架构就成功了一半。最最简单的模式，无非就是存取redis，存数据，取数据。解决各种各样的高并发下缓存面临的难题，缓存架构中不断引入各种解决方案和技术，解决高并发的问题。</p>
<ol>
<li>搭建redis集群，从0开始，一步一步搭建一个4个结点的Centos集群。安装4台虚拟机<ul>
<li>在hosts文件下,配置好所有的机器的ip地址到hostname的映射关系</li>
<li>使用ssh配置每台机器之间免密登录</li>
</ul>
</li>
<li>make install </li>
<li>要把redis作为一个系统的daemon进程去运行，每次系统启动，redis进程一起启动</li>
</ol>
<p>如果没有持久化的话，redis遇到灾难性故障的时候，就会丢失所有的数据</p>
<p>如果通过持久化将数据搞一份儿在磁盘上去，然后定期比如说同步和备份到一些云存储服务上去，那么就可以保证数据不丢失全部，还是可以恢复一部分数据回来的。redis如果单单把数据放在内存中，是没有任何方法应对一些灾难性的工作的，redis 在启动会自动从磁盘中恢复数据到内存中。</p>
<h3 id="redis-持久化RDB-AOF利弊比较"><a href="#redis-持久化RDB-AOF利弊比较" class="headerlink" title="redis 持久化RDB,AOF利弊比较"></a>redis 持久化RDB,AOF利弊比较</h3><p>比如你redis整个挂了，然后redis就不可用了，你要做的事情是让redis变得可用，尽快变得可用</p>
<p>重启redis，尽快让它对外提供服务，但是就像上一讲说，如果你没做数据备份，这个时候redis启动了，也不可用啊，数据都没了</p>
<p>很可能说，大量的请求过来，缓存全部无法命中，在redis里根本找不到数据，这个时候就死定了，缓存雪崩问题，所有请求，没有在redis命中，就会去mysql数据库这种数据源头中去找，一下子mysql承接高并发，然后就挂了</p>
<p>mysql挂掉，你都没法去找数据恢复到redis里面去，redis的数据从哪儿来？从mysql来。。。</p>
<p>具体的完整的缓存雪崩的场景，还有企业级的解决方案，到后面讲</p>
<p>如果你把redis的持久化做好，备份和恢复方案做到企业级的程度，那么即使你的redis故障了，也可以通过备份数据，快速恢复，一旦恢复立即对外提供服务</p>
<p>redis的持久化，跟高可用，是有关系的，企业级redis架构中去讲解</p>
<p>redis持久化：RDB，AOF</p>
<hr>
<p>1、RDB和AOF两种持久化机制的介绍</p>
<p>RDB持久化机制，对redis中的数据执行周期性的持久化</p>
<p>AOF机制对每条写入命令作为日志，以append-only的模式写入一个日志文件中，在redis重启的时候，可以通过回放AOF日志中的写入指令来重新构建整个数据集</p>
<p>如果我们想要redis仅仅作为纯内存的缓存来用，那么可以禁止RDB和AOF所有的持久化机制</p>
<p>通过RDB或AOF，都可以将redis内存中的数据给持久化到磁盘上面来，然后可以将这些数据备份到别的地方去，比如说阿里云，云服务</p>
<p>如果redis挂了，服务器上的内存和磁盘上的数据都丢了，可以从云服务上拷贝回来之前的数据，放到指定的目录中，然后重新启动redis，redis就会自动根据持久化数据文件中的数据，去恢复内存中的数据，继续对外提供服务</p>
<p>如果同时使用RDB和AOF两种持久化机制，那么在redis重启的时候，会使用AOF来重新构建数据，因为AOF中的数据更加完整</p>
<hr>
<p>2、RDB持久化机制的优点</p>
<p>（1）RDB会生成多个数据文件，每个数据文件都代表了某一个时刻中redis的数据，这种多个数据文件的方式，非常适合做冷备，可以将这种完整的数据文件发送到一些远程的安全存储上去，比如说Amazon的S3云服务上去，在国内可以是阿里云的ODPS分布式存储上，以预定好的备份策略来定期备份redis中的数据</p>
<p>（2）RDB对redis对外提供的读写服务，影响非常小，可以让redis保持高性能，因为redis主进程只需要fork一个子进程，让子进程执行磁盘IO操作来进行RDB持久化即可</p>
<p>（3）相对于AOF持久化机制来说，直接基于RDB数据文件来重启和恢复redis进程，更加快速</p>
<hr>
<p>3、RDB持久化机制的缺点</p>
<p>（1）如果想要在redis故障时，尽可能少的丢失数据，那么RDB没有AOF好。一般来说，RDB数据快照文件，都是每隔5分钟，或者更长时间生成一次，这个时候就得接受一旦redis进程宕机，那么会丢失最近5分钟的数据</p>
<p>（2）RDB每次在fork子进程来执行RDB快照数据文件生成的时候，如果数据文件特别大，可能会导致对客户端提供的服务暂停数毫秒，或者甚至数秒</p>
<hr>
<p>4、AOF持久化机制的优点</p>
<p>（1）AOF可以更好的保护数据不丢失，一般AOF会每隔1秒，通过一个后台线程执行一次fsync操作，最多丢失1秒钟的数据</p>
<p>（2）AOF日志文件以append-only模式写入，所以没有任何磁盘寻址的开销，写入性能非常高，而且文件不容易破损，即使文件尾部破损，也很容易修复</p>
<p>（3）AOF日志文件即使过大的时候，出现后台重写操作，也不会影响客户端的读写。因为在rewrite log的时候，会对其中的指导进行压缩，创建出一份需要恢复数据的最小日志出来。再创建新日志文件的时候，老的日志文件还是照常写入。当新的merge后的日志文件ready的时候，再交换新老日志文件即可。</p>
<p>（4）AOF日志文件的命令通过非常可读的方式进行记录，这个特性非常适合做灾难性的误删除的紧急恢复。比如某人不小心用flushall命令清空了所有数据，只要这个时候后台rewrite还没有发生，那么就可以立即拷贝AOF文件，将最后一条flushall命令给删了，然后再将该AOF文件放回去，就可以通过恢复机制，自动恢复所有数据</p>
<hr>
<p>5、AOF持久化机制的缺点</p>
<p>（1）对于同一份数据来说，AOF日志文件通常比RDB数据快照文件更大</p>
<p>（2）AOF开启后，支持的写QPS会比RDB支持的写QPS低，因为AOF一般会配置成每秒fsync一次日志文件，当然，每秒一次fsync，性能也还是很高的</p>
<p>（3）以前AOF发生过bug，就是通过AOF记录的日志，进行数据恢复的时候，没有恢复一模一样的数据出来。所以说，类似AOF这种较为复杂的基于命令日志/merge/回放的方式，比基于RDB每次持久化一份完整的数据快照文件的方式，更加脆弱一些，容易有bug。不过AOF就是为了避免rewrite过程导致的bug，因此每次rewrite并不是基于旧的指令日志进行merge的，而是基于当时内存中的数据进行指令的重新构建，这样健壮性会好很多。</p>
<hr>
<p>6、RDB和AOF到底该如何选择</p>
<p>（1）不要仅仅使用RDB，因为那样会导致你丢失很多数据</p>
<p>（2）也不要仅仅使用AOF，因为那样有两个问题，第一，你通过AOF做冷备，没有RDB做冷备，来的恢复速度更快; 第二，RDB每次简单粗暴生成数据快照，更加健壮，可以避免AOF这种复杂的备份和恢复机制的bug</p>
<p>（3）综合使用AOF和RDB两种持久化机制，用AOF来保证数据不丢失，作为数据恢复的第一选择; 用RDB来做不同程度的冷备，在AOF文件都丢失或损坏不可用的时候，还可以使用RDB来进行快速的数据恢复</p>
<h3 id="RDB持久化详解"><a href="#RDB持久化详解" class="headerlink" title="RDB持久化详解"></a>RDB持久化详解</h3><p>1、如何配置RDB持久化机制<br>2、RDB持久化机制的工作流程<br>3、基于RDB持久化机制的数据恢复实验</p>
<hr>
<p>1、如何配置RDB持久化机制</p>
<p>redis.conf文件，也就是/etc/redis/6379.conf，去配置持久化</p>
<p>save 60 1000</p>
<p>每隔60s，如果有超过1000个key发生了变更，那么就生成一个新的dump.rdb文件，就是当前redis内存中完整的数据快照，这个操作也被称之为snapshotting，快照</p>
<p>也可以手动调用save或者bgsave命令，同步或异步执行rdb快照生成</p>
<p>save可以设置多个，就是多个snapshotting检查点，每到一个检查点，就会去check一下，是否有指定的key数量发生了变更，如果有，就生成一个新的dump.rdb文件</p>
<hr>
<p>2、RDB持久化机制的工作流程</p>
<p>（1）redis根据配置自己尝试去生成rdb快照文件<br>（2）fork一个子进程出来<br>（3）子进程尝试将数据dump到临时的rdb快照文件中<br>（4）完成rdb快照文件的生成之后，就替换之前的旧的快照文件</p>
<p>dump.rdb，每次生成一个新的快照，都会覆盖之前的老快照</p>
<hr>
<p>3、基于RDB持久化机制的数据恢复实验</p>
<p>（1）在redis中保存几条数据，立即停掉redis进程，然后重启redis，看看刚才插入的数据还在不在</p>
<p>数据还在，为什么？</p>
<p>带出来一个知识点，通过redis-cli SHUTDOWN这种方式去停掉redis，其实是一种安全退出的模式，redis在退出的时候会将内存中的数据立即生成一份完整的rdb快照</p>
<p>/var/redis/6379/dump.rdb</p>
<p>（2）在redis中再保存几条新的数据，用kill -9粗暴杀死redis进程，模拟redis故障异常退出，导致内存数据丢失的场景</p>
<p>这次就发现，redis进程异常被杀掉，数据没有进dump文件，几条最新的数据就丢失了</p>
<p>（2）手动设置一个save检查点，save 5 1<br>（3）写入几条数据，等待5秒钟，会发现自动进行了一次dump rdb快照，在dump.rdb中发现了数据<br>（4）异常停掉redis进程，再重新启动redis，看刚才插入的数据还在</p>
<p>rdb的手动配置检查点，以及rdb快照的生成，包括数据的丢失和恢复，全都演示过了</p>
<h3 id="AOF持久化详解"><a href="#AOF持久化详解" class="headerlink" title="AOF持久化详解"></a>AOF持久化详解</h3><p>1、AOF持久化的配置<br>2、AOF持久化的数据恢复实验<br>3、AOF rewrite<br>4、AOF破损文件的修复<br>5、AOF和RDB同时工作</p>
<hr>
<p>1、AOF持久化的配置</p>
<p>AOF持久化，默认是关闭的，默认是打开RDB持久化</p>
<p>appendonly yes，可以打开AOF持久化机制，在生产环境里面，一般来说AOF都是要打开的，除非你说随便丢个几分钟的数据也无所谓。<br>如果开启AOF，就算没有AOF文件，redis在重启时，也会创建一个新的空的AOF文件恢复数据，在这个时候就需要先关闭AOF，拷贝dump.rdb恢复redis先，接着应该直接在命令行热修改redis配置，打开AOF。此时磁盘上的配置文件还是no（关闭）的，还需要在磁盘上将AOF打开。</p>
<p>AOF append-only ，顺序写入，如果AOF文件破损，那么用redis-check-aof fix修复文件<br>打开AOF持久化机制之后，redis每次接收到一条写命令，就会写入日志文件中，当然是先写入os cache的，然后每隔一定时间再fsync一下</p>
<p>而且即使AOF和RDB都开启了，redis重启的时候，也是优先通过AOF进行数据恢复的，因为aof数据比较完整</p>
<p>可以配置AOF的fsync策略，有三种策略可以选择，一种是每次写入一条数据就执行一次fsync; 一种是每隔一秒执行一次fsync; 一种是不主动执行fsync</p>
<p>always: 每次写入一条数据，立即将这个数据对应的写日志fsync到磁盘上去，性能非常非常差，吞吐量很低; 确保说redis里的数据一条都不丢，那就只能这样了</p>
<p>mysql -&gt; 内存策略，大量磁盘，QPS到多少，一两k。QPS，每秒钟的请求数量<br>redis -&gt; 内存，磁盘持久化，QPS到多少，单机，一般来说，上万QPS没问题</p>
<p>everysec: 每秒将os cache中的数据fsync到磁盘，这个最常用的，生产环境一般都这么配置，性能很高，QPS还是可以上万的</p>
<p>no: 仅仅redis负责将数据写入os cache就撒手不管了，然后后面os自己会时不时有自己的策略将数据刷入磁盘，不可控了</p>
<hr>
<p>2、AOF持久化的数据恢复实验</p>
<p>（1）先仅仅打开RDB，写入一些数据，然后kill -9杀掉redis进程，接着重启redis，发现数据没了，因为RDB快照还没生成<br>（2）打开AOF的开关，启用AOF持久化<br>（3）写入一些数据，观察AOF文件中的日志内容</p>
<p>其实你在appendonly.aof文件中，可以看到刚写的日志，它们其实就是先写入os cache的，然后1秒后才fsync到磁盘中，只有fsync到磁盘中了，才是安全的，要不然光是在os cache中，机器只要重启，就什么都没了</p>
<p>（4）kill -9杀掉redis进程，重新启动redis进程，发现数据被恢复回来了，就是从AOF文件中恢复回来的</p>
<p>redis进程启动的时候，直接就会从appendonly.aof中加载所有的日志，把内存中的数据恢复回来</p>
<hr>
<p>3、AOF rewrite</p>
<p>redis中的数据其实有限的，很多数据可能会自动过期，可能会被用户删除，可能会被redis用缓存清除的算法清理掉</p>
<p>redis中的数据会不断淘汰掉旧的，就一部分常用的数据会被自动保留在redis内存中</p>
<p>所以可能很多之前的已经被清理掉的数据，对应的写日志还停留在AOF中，AOF日志文件就一个，会不断的膨胀，到很大很大</p>
<p>所以AOF会自动在后台每隔一定时间做rewrite操作，比如日志里已经存放了针对100w数据的写日志了; redis内存只剩下10万; 基于内存中当前的10万数据构建一套最新的日志，到AOF中; 覆盖之前的老日志; 确保AOF日志文件不会过大，保持跟redis内存数据量一致</p>
<p>redis 2.4之前，还需要手动，开发一些脚本，crontab，通过BGREWRITEAOF命令去执行AOF rewrite，但是redis 2.4之后，会自动进行rewrite操作</p>
<p>在redis.conf中，可以配置rewrite策略</p>
<p>auto-aof-rewrite-percentage 100<br>auto-aof-rewrite-min-size 64mb</p>
<p>比如说上一次AOF rewrite之后，是128mb</p>
<p>然后就会接着128mb继续写AOF的日志，如果发现增长的比例，超过了之前的100%，256mb，就可能会去触发一次rewrite</p>
<p>但是此时还要去跟min-size，64mb去比较，256mb &gt; 64mb，才会去触发rewrite</p>
<p>（1）redis fork一个子进程<br>（2）子进程基于当前内存中的数据，构建日志，开始往一个新的临时的AOF文件中写入日志<br>（3）redis主进程，接收到client新的写操作之后，在内存中写入日志，同时新的日志也继续写入旧的AOF文件<br>（4）子进程写完新的日志文件之后，redis主进程将内存中的新日志再次追加到新的AOF文件中<br>（5）用新的日志文件替换掉旧的日志文件</p>
<hr>
<p>4、AOF破损文件的修复</p>
<p>如果redis在append数据到AOF文件时，机器宕机了，可能会导致AOF文件破损</p>
<p>用redis-check-aof –fix命令来修复破损的AOF文件</p>
<hr>
<p>5、AOF和RDB同时工作</p>
<p>（1）如果RDB在执行snapshotting操作，那么redis不会执行AOF rewrite; 如果redis再执行AOF rewrite，那么就不会执行RDB snapshotting<br>（2）如果RDB在执行snapshotting，此时用户执行BGREWRITEAOF命令，那么等RDB快照生成之后，才会去执行AOF rewrite<br>（3）同时有RDB snapshot文件和AOF日志文件，那么redis重启的时候，会优先使用AOF进行数据恢复，因为其中的日志更完整</p>
<hr>
<p>6、最后一个小实验，让大家对redis的数据恢复有更加深刻的体会</p>
<p>（1）在有rdb的dump和aof的appendonly的同时，rdb里也有部分数据，aof里也有部分数据，这个时候其实会发现，rdb的数据不会恢复到内存中<br>（2）我们模拟让aof破损，然后fix，有一条数据会被fix删除<br>（3）再次用fix得aof文件去重启redis，发现数据只剩下一条了</p>
<p>数据恢复完全是依赖于底层的磁盘的持久化的，主要rdb和aof上都没有数据，那就没了</p>
<h1 id="9-29"><a href="#9-29" class="headerlink" title="9.29"></a>9.29</h1><h3 id="redis在企业级数据备份方案以及数据恢复负灾演练"><a href="#redis在企业级数据备份方案以及数据恢复负灾演练" class="headerlink" title="redis在企业级数据备份方案以及数据恢复负灾演练"></a>redis在企业级数据备份方案以及数据恢复负灾演练</h3><p>到这里为止，其实还是停留在简单学习知识的程度，学会了redis的持久化的原理和操作，但是在企业中，持久化到底是怎么去用得呢？</p>
<p>企业级的数据备份和各种灾难下的数据恢复，是怎么做得呢？</p>
<p>1、企业级的持久化的配置策略</p>
<p>在企业中，RDB的生成策略，用默认的也差不多</p>
<p>save 60 10000：如果你希望尽可能确保说，RDB最多丢1分钟的数据，那么尽量就是每隔1分钟都生成一个快照，低峰期，数据量很少，也没必要</p>
<p>10000-&gt;生成RDB，1000-&gt;RDB，这个根据你自己的应用和业务的数据量，你自己去决定</p>
<p>AOF一定要打开，fsync，everysec</p>
<p>auto-aof-rewrite-percentage 100: 就是当前AOF大小膨胀到超过上次100%，上次的两倍<br>auto-aof-rewrite-min-size 64mb: 根据你的数据量来定，16mb，32mb</p>
<p>2、企业级的数据备份方案</p>
<p>RDB非常适合做冷备，每次生成之后，就不会再有修改了</p>
<p>数据备份方案</p>
<p>（1）写crontab定时调度脚本去做数据备份<br>（2）每小时都copy一份rdb的备份，到一个目录中去，仅仅保留最近48小时的备份<br>（3）每天都保留一份当日的rdb的备份，到一个目录中去，仅仅保留最近1个月的备份<br>（4）每次copy备份的时候，都把太旧的备份给删了<br>（5）每天晚上将当前服务器上所有的数据备份，发送一份到远程的云服务上去</p>
<p>/usr/local/redis</p>
<p>每小时copy一次备份，删除48小时前的数据</p>
<p>crontab -e</p>
<p>0 <em> </em> <em> </em> sh /usr/local/redis/copy/redis_rdb_copy_hourly.sh</p>
<p>redis_rdb_copy_hourly.sh</p>
<p>#!/bin/sh </p>
<p>cur_date=<code>date +%Y%m%d%k</code><br>rm -rf /usr/local/redis/snapshotting/$cur_date<br>mkdir /usr/local/redis/snapshotting/$cur_date<br>cp /var/redis/6379/dump.rdb /usr/local/redis/snapshotting/$cur_date</p>
<p>del_date=<code>date -d -48hour +%Y%m%d%k</code><br>rm -rf /usr/local/redis/snapshotting/$del_date</p>
<p>每天copy一次备份</p>
<p>crontab -e</p>
<p>0 0 <em> </em> * sh /usr/local/redis/copy/redis_rdb_copy_daily.sh</p>
<p>redis_rdb_copy_daily.sh</p>
<p>#!/bin/sh </p>
<p>cur_date=<code>date +%Y%m%d</code><br>rm -rf /usr/local/redis/snapshotting/$cur_date<br>mkdir /usr/local/redis/snapshotting/$cur_date<br>cp /var/redis/6379/dump.rdb /usr/local/redis/snapshotting/$cur_date</p>
<p>del_date=<code>date -d -1month +%Y%m%d</code><br>rm -rf /usr/local/redis/snapshotting/$del_date</p>
<p>每天一次将所有数据上传一次到远程的云服务器上去</p>
<p>3、数据恢复方案</p>
<p>（1）如果是redis进程挂掉，那么重启redis进程即可，直接基于AOF日志文件恢复数据</p>
<p>不演示了，在AOF数据恢复那一块，演示了，fsync everysec，最多就丢一秒的数</p>
<p>（2）如果是redis进程所在机器挂掉，那么重启机器后，尝试重启redis进程，尝试直接基于AOF日志文件进行数据恢复</p>
<p>AOF没有破损，也是可以直接基于AOF恢复的</p>
<p>AOF append-only，顺序写入，如果AOF文件破损，那么用redis-check-aof fix</p>
<p>（3）如果redis当前最新的AOF和RDB文件出现了丢失/损坏，那么可以尝试基于该机器上当前的某个最新的RDB数据副本进行数据恢复</p>
<p>当前最新的AOF和RDB文件都出现了丢失/损坏到无法恢复，一般不是机器的故障，人为</p>
<p>大数据系统，hadoop，有人不小心就把hadoop中存储的大量的数据文件对应的目录，rm -rf一下，我朋友的一个小公司，运维不太靠谱，权限也弄的不太好</p>
<p>/var/redis/6379下的文件给删除了</p>
<p>找到RDB最新的一份备份，小时级的备份可以了，小时级的肯定是最新的，copy到redis里面去，就可以恢复到某一个小时的数据</p>
<p>容灾演练</p>
<p>我跟大家解释一下，我其实上课，为什么大量的讲师可能讲课就是纯PPT，或者是各种复制粘贴，都不是现场讲解和写代码演示的</p>
<p>很容易出错，为了避免出错，一般就会那样玩儿</p>
<p>吐槽，念PPT，效果很差</p>
<p>真实的，备课，讲课不可避免，会出现一些问题，但是我觉得还好，真实</p>
<p>appendonly.aof + dump.rdb，优先用appendonly.aof去恢复数据，但是我们发现redis自动生成的appendonly.aof是没有数据的</p>
<p>然后我们自己的dump.rdb是有数据的，但是明显没用我们的数据</p>
<p>redis启动的时候，自动重新基于内存的数据，生成了一份最新的rdb快照，直接用空的数据，覆盖掉了我们有数据的，拷贝过去的那份dump.rdb</p>
<p>你停止redis之后，其实应该先删除appendonly.aof，然后将我们的dump.rdb拷贝过去，然后再重启redis</p>
<p>很简单，就是虽然你删除了appendonly.aof，但是因为打开了aof持久化，redis就一定会优先基于aof去恢复，即使文件不在，那就创建一个新的空的aof文件</p>
<p>停止redis，暂时在配置中关闭aof，然后拷贝一份rdb过来，再重启redis，数据能不能恢复过来，可以恢复过来</p>
<p>脑子一热，再关掉redis，手动修改配置文件，打开aof，再重启redis，数据又没了，空的aof文件，所有数据又没了</p>
<p>在数据安全丢失的情况下，基于rdb冷备，如何完美的恢复数据，同时还保持aof和rdb的双开</p>
<p>停止redis，关闭aof，拷贝rdb备份，重启redis，确认数据恢复，直接在命令行热修改redis配置，打开aof，这个redis就会将内存中的数据对应的日志，写入aof文件中</p>
<p>此时aof和rdb两份数据文件的数据就同步了</p>
<p>redis config set热修改配置参数，可能配置文件中的实际的参数没有被持久化的修改，再次停止redis，手动修改配置文件，打开aof的命令，再次重启redis</p>
<p>（4）如果当前机器上的所有RDB文件全部损坏，那么从远程的云服务上拉取最新的RDB快照回来恢复数据</p>
<p>（5）如果是发现有重大的数据错误，比如某个小时上线的程序一下子将数据全部污染了，数据全错了，那么可以选择某个更早的时间点，对数据进行恢复</p>
<p>举个例子，12点上线了代码，发现代码有bug，导致代码生成的所有的缓存数据，写入redis，全部错了</p>
<p>找到一份11点的rdb的冷备，然后按照上面的步骤，去恢复到11点的数据，不就可以了吗</p>
<h3 id="redis通过主从架构实现读写分离，完成10万-QPS"><a href="#redis通过主从架构实现读写分离，完成10万-QPS" class="headerlink" title="redis通过主从架构实现读写分离，完成10万+QPS"></a>redis通过主从架构实现读写分离，完成10万+QPS</h3><p>1、redis高并发跟整个系统的高并发之间的关系</p>
<p>redis，你要搞高并发的话，不可避免，要把底层的缓存搞得很好</p>
<p>mysql，高并发，做到了，那么也是通过一系列复杂的分库分表，订单系统，事务要求的，QPS到几万，比较高了</p>
<p>要做一些电商的商品详情页，真正的超高并发，QPS上十万，甚至是百万，一秒钟百万的请求量</p>
<p>光是redis是不够的，但是redis是整个大型的缓存架构中，支撑高并发的架构里面，非常重要的一个环节</p>
<p>首先，你的底层的缓存中间件，缓存系统，必须能够支撑的起我们说的那种高并发，其次，再经过良好的整体的缓存架构的设计（多级缓存架构、热点缓存），支撑真正的上十万，甚至上百万的高并发</p>
<p>2、redis不能支撑高并发的瓶颈在哪里？</p>
<p>单机</p>
<p>3、如果redis要支撑超过10万+的并发，那应该怎么做？</p>
<p>单机的redis几乎不太可能说QPS超过10万+，除非一些特殊情况，比如你的机器性能特别好，配置特别高，物理机，维护做的特别好，而且你的整体的操作不是太复杂</p>
<p>单机在几万</p>
<p>读写分离，一般来说，对缓存，一般都是用来支撑读高并发的，写的请求是比较少的，可能写请求也就一秒钟几千，一两千</p>
<p>大量的请求都是读，一秒钟二十万次读</p>
<p>读写分离</p>
<p>主从架构 -&gt; 读写分离 -&gt; 支撑10万+读QPS的架构</p>
<p>4、接下来要讲解的一个topic</p>
<p>redis replication</p>
<p>redis主从架构 -&gt; 读写分离架构 -&gt; 可支持水平扩展的读高并发架构</p>
<h3 id="redis-replication（主从架构）基本原理"><a href="#redis-replication（主从架构）基本原理" class="headerlink" title="redis replication（主从架构）基本原理"></a>redis replication（主从架构）基本原理</h3><p>课程大纲</p>
<p>1、图解redis replication基本原理<br>2、redis replication的核心机制<br>3、master持久化对于主从架构的安全保障的意义</p>
<p>redis replication -&gt; 主从架构 -&gt; 读写分离 -&gt; 水平扩容支撑读高并发</p>
<p>redis replication的最最基本的原理，铺垫</p>
<hr>
<p>1、图解redis replication基本原理</p>
<hr>
<p>2、redis replication的核心机制</p>
<p>（1）redis采用异步方式复制数据到slave节点，不过redis 2.8开始，slave node会周期性地确认自己每次复制的数据量<br>（2）一个master node是可以配置多个slave node的<br>（3）slave node也可以连接其他的slave node<br>（4）slave node做复制的时候，是不会block master node的正常工作的<br>（5）slave node在做复制的时候，也不会block对自己的查询操作，它会用旧的数据集来提供服务; 但是复制完成的时候，需要删除旧数据集，加载新数据集，这个时候就会暂停对外服务了<br>（6）slave node主要用来进行横向扩容，做读写分离，扩容的slave node可以提高读的吞吐量</p>
<p>slave，高可用性，有很大的关系</p>
<hr>
<p>3、master持久化对于主从架构的安全保障的意义</p>
<p>如果采用了主从架构，那么建议必须开启master node的持久化！</p>
<p>不建议用slave node作为master node的数据热备，因为那样的话，如果你关掉master的持久化，可能在master宕机重启的时候数据是空的，然后可能一经过复制，salve node数据也丢了</p>
<p>master -&gt; RDB和AOF都关闭了 -&gt; 全部在内存中</p>
<p>master宕机，重启，是没有本地数据可以恢复的，然后就会直接认为自己IDE数据是空的</p>
<p>master就会将空的数据集同步到slave上去，所有slave的数据全部清空</p>
<p>100%的数据丢失</p>
<p>master节点，必须要使用持久化机制</p>
<p>第二个，master的各种备份方案，要不要做，万一说本地的所有文件丢失了; 从备份中挑选一份rdb去恢复master; 这样才能确保master启动的时候，是有数据的</p>
<p>即使采用了后续讲解的高可用机制，slave node可以自动接管master node，但是也可能sentinal还没有检测到master failure，master node就自动重启了，还是可能导致上面的所有slave node数据清空故障</p>
<h1 id="9-30"><a href="#9-30" class="headerlink" title="9.30"></a>9.30</h1><h3 id="redis主从复制原理细讲"><a href="#redis主从复制原理细讲" class="headerlink" title="redis主从复制原理细讲"></a>redis主从复制原理细讲</h3><p>1、复制的完整流程</p>
<p>（1）slave node启动，仅仅保存master node的信息，包括master node的host和ip，但是复制流程没开始</p>
<p>master host和ip是从哪儿来的，redis.conf里面的slaveof配置的</p>
<p>（2）slave node内部有个定时任务，每秒检查是否有新的master node要连接和复制，如果发现，就跟master node建立socket网络连接<br>（3）slave node发送ping命令给master node<br>（4）口令认证，如果master设置了requirepass，那么salve node必须发送masterauth的口令过去进行认证<br>（5）master node第一次执行全量复制，将所有数据发给slave node<br>（6）master node后续持续将写命令，异步复制给slave node</p>
<p>2、数据同步相关的核心机制</p>
<p>指的就是第一次slave连接msater的时候，执行的全量复制，那个过程里面你的一些细节的机制</p>
<p>（1）master和slave都会维护一个offset</p>
<p>master会在自身不断累加offset，slave也会在自身不断累加offset<br>slave每秒都会上报自己的offset给master，同时master也会保存每个slave的offset</p>
<p>这个倒不是说特定就用在全量复制的，主要是master和slave都要知道各自的数据的offset，才能知道互相之间的数据不一致的情况</p>
<p>（2）backlog</p>
<p>master node有一个backlog，默认是1MB大小<br>master node给slave node复制数据时，也会将数据在backlog中同步写一份<br>backlog主要是用来做全量复制中断候的增量复制的</p>
<p>（3）master run id</p>
<p>info server，可以看到master run id<br>如果根据host+ip定位master node，是不靠谱的，如果master node重启或者数据出现了变化，那么slave node应该根据不同的run id区分，run id不同就做全量复制<br>如果需要不更改run id重启redis，可以使用redis-cli debug reload命令</p>
<p>（4）psync</p>
<p>从节点使用psync从master node进行复制，psync runid offset<br>master node会根据自身的情况返回响应信息，可能是FULLRESYNC runid offset触发全量复制，可能是CONTINUE触发增量复制</p>
<p>3、全量复制</p>
<p>（1）master执行bgsave，在本地生成一份rdb快照文件<br>（2）master node将rdb快照文件发送给salve node，如果rdb复制时间超过60秒（repl-timeout），那么slave node就会认为复制失败，可以适当调节大这个参数<br>（3）对于千兆网卡的机器，一般每秒传输100MB，6G文件，很可能超过60s<br>（4）master node在生成rdb时，会将所有新的写命令缓存在内存中，在salve node保存了rdb之后，再将新的写命令复制给salve node<br>（5）client-output-buffer-limit slave 256MB 64MB 60，如果在复制期间，内存缓冲区持续消耗超过64MB，或者一次性超过256MB，那么停止复制，复制失败<br>（6）slave node接收到rdb之后，清空自己的旧数据，然后重新加载rdb到自己的内存中，同时基于旧的数据版本对外提供服务<br>（7）如果slave node开启了AOF，那么会立即执行BGREWRITEAOF，重写AOF</p>
<p>rdb生成、rdb通过网络拷贝、slave旧数据的清理、slave aof rewrite，很耗费时间</p>
<p>如果复制的数据量在4G~6G之间，那么很可能全量复制时间消耗到1分半到2分钟</p>
<p>4、增量复制</p>
<p>（1）如果全量复制过程中，master-slave网络连接断掉，那么salve重新连接master时，会触发增量复制<br>（2）master直接从自己的backlog中获取部分丢失的数据，发送给slave node，默认backlog就是1MB<br>（3）msater就是根据slave发送的psync中的offset来从backlog中获取数据的</p>
<p>5、heartbeat</p>
<p>主从节点互相都会发送heartbeat信息</p>
<p>master默认每隔10秒发送一次heartbeat，salve node每隔1秒发送一个heartbeat</p>
<p>6、异步复制</p>
<p>master每次接收到写命令之后，现在内部写入数据，然后异步发送给slave node</p>
<h3 id="搭建redis主从节点"><a href="#搭建redis主从节点" class="headerlink" title="搭建redis主从节点"></a>搭建redis主从节点</h3><p>之前几讲都是在铺垫各种redis replication的原理，和知识，主从，读写分离，画图</p>
<p>知道了这些东西，关键是怎么搭建呢？？？</p>
<p>一主一从，往主节点去写，在从节点去读，可以读到，主从架构就搭建成功了</p>
<p>1、启用复制，部署slave node</p>
<p>wget <a href="http://downloads.sourceforge.net/tcl/tcl8.6.1-src.tar.gz" target="_blank" rel="noopener">http://downloads.sourceforge.net/tcl/tcl8.6.1-src.tar.gz</a><br>tar -xzvf tcl8.6.1-src.tar.gz<br>cd  /usr/local/tcl8.6.1/unix/<br>./configure<br>make &amp;&amp; make install</p>
<p>使用redis-3.2.8.tar.gz（截止2017年4月的最新稳定版）<br>tar -zxvf redis-3.2.8.tar.gz<br>cd redis-3.2.8<br>make &amp;&amp; make test &amp;&amp; make install</p>
<p>（1）redis utils目录下，有个redis_init_script脚本<br>（2）将redis_init_script脚本拷贝到linux的/etc/init.d目录中，将redis_init_script重命名为redis_6379，6379是我们希望这个redis实例监听的端口号<br>（3）修改redis_6379脚本的第6行的REDISPORT，设置为相同的端口号（默认就是6379）<br>（4）创建两个目录：/etc/redis（存放redis的配置文件），/var/redis/6379（存放redis的持久化文件）<br>（5）修改redis配置文件（默认在根目录下，redis.conf），拷贝到/etc/redis目录中，修改名称为6379.conf</p>
<p>（6）修改redis.conf中的部分配置为生产环境</p>
<p>daemonize    yes                            让redis以daemon进程运行<br>pidfile        /var/run/redis_6379.pid     设置redis的pid文件位置<br>port        6379                        设置redis的监听端口号<br>dir         /var/redis/6379                设置持久化文件的存储位置   (设置持久化文件的位置)</p>
<p>（7）让redis跟随系统启动自动启动</p>
<p>在redis_6379脚本中，最上面，加入两行注释</p>
<h1 id="chkconfig-2345-90-10"><a href="#chkconfig-2345-90-10" class="headerlink" title="chkconfig:   2345 90 10"></a>chkconfig:   2345 90 10</h1><h1 id="description-Redis-is-a-persistent-key-value-database"><a href="#description-Redis-is-a-persistent-key-value-database" class="headerlink" title="description:  Redis is a persistent key-value database"></a>description:  Redis is a persistent key-value database</h1><p>chkconfig redis_6379 on（随着系统启动+）</p>
<p>在slave node上配置（redis.conf文件中只要修改slaveof相关配置）：</p>
<p>slaveof 192.168.1.1（主节点） 6379（redis端口号），即可也可以使用slaveof命令</p>
<p>则配置成自己是从节点<br>2、强制读写分离</p>
<p>基于主从复制架构，实现读写分离</p>
<p>redis slave node只读，默认开启，slave-read-only</p>
<p>开启了只读的redis slave node，会拒绝所有的写操作，这样可以强制搭建成读写分离的架构</p>
<p>3、集群安全认证</p>
<p>master上启用安全认证，requirepass<br>master连接口令，masterauth</p>
<p>4、读写分离架构的测试</p>
<p>先启动主节点，eshop-cache01上的redis实例<br>再启动从节点，eshop-cache02上的redis实例</p>
<p>刚才我调试了一下，redis slave node一直说没法连接到主节点的6379的端口</p>
<p>在搭建生产环境的集群的时候，不要忘记修改一个配置，bind</p>
<p>bind 127.0.0.1 -&gt; 本地的开发调试的模式，就只能127.0.0.1本地才能访问到6379的端口</p>
<p>每个redis.conf中的bind 127.0.0.1 -&gt; bind自己的ip地址<br>在每个节点上都: iptables -A INPUT -ptcp –dport  6379 -j ACCEPT</p>
<p>redis-cli -h ipaddr<br>info replication</p>
<p>在主上写，在从上读<br>ps -ef | grep redis<br>查看redis进程是否已经启动</p>
<h3 id="哨兵架构基础知识讲解"><a href="#哨兵架构基础知识讲解" class="headerlink" title="哨兵架构基础知识讲解"></a>哨兵架构基础知识讲解</h3><p>1、哨兵的介绍</p>
<p>sentinal，中文名是哨兵</p>
<p>哨兵是redis集群架构中非常重要的一个组件，主要功能如下</p>
<p>（1）集群监控，负责监控redis master和slave进程是否正常工作<br>（2）消息通知，如果某个redis实例有故障，那么哨兵负责发送消息作为报警通知给管理员<br>（3）故障转移，如果master node挂掉了，会自动转移到slave node上<br>（4）配置中心，如果故障转移发生了，通知client客户端新的master地址</p>
<p>哨兵本身也是分布式的，作为一个哨兵集群去运行，互相协同工作</p>
<p>（1）故障转移时，判断一个master node是宕机了，需要大部分的哨兵都同意才行，涉及到了分布式选举的问题<br>（2）即使部分哨兵节点挂掉了，哨兵集群还是能正常工作的，因为如果一个作为高可用机制重要组成部分的故障转移系统本身是单点的，那就很坑爹了</p>
<p>目前采用的是sentinal 2版本，sentinal 2相对于sentinal 1来说，重写了很多代码，主要是让故障转移的机制和算法变得更加健壮和简单</p>
<p>2、哨兵的核心知识</p>
<p>（1）哨兵至少需要3个实例，来保证自己的健壮性<br>（2）哨兵 + redis主从的部署架构，是不会保证数据零丢失的，只能保证redis集群的高可用性<br>（3）对于哨兵 + redis主从这种复杂的部署架构，尽量在测试环境和生产环境，都进行充足的测试和演练</p>
<p>3、为什么redis哨兵集群只有2个节点无法正常工作？</p>
<p>哨兵集群必须部署2个以上节点</p>
<p>如果哨兵集群仅仅部署了个2个哨兵实例，quorum=1</p>
<p>+—-+         +—-+<br>| M1 |———| R1 |<br>| S1 |         | S2 |<br>+—-+         +—-+</p>
<p>Configuration: quorum = 1</p>
<p>master宕机，s1和s2中只要有1个哨兵认为master宕机就可以还行切换，同时s1和s2中会选举出一个哨兵来执行故障转移</p>
<p>同时这个时候，需要majority，也就是大多数哨兵都是运行的，2个哨兵的majority就是2（2的majority=2，3的majority=2，5的majority=3，4的majority=2），2个哨兵都运行着，就可以允许执行故障转移</p>
<p>但是如果整个M1和S1运行的机器宕机了，那么哨兵只有1个了，此时就没有majority来允许执行故障转移，虽然另外一台机器还有一个R1，但是故障转移不会执行</p>
<p>4、经典的3节点哨兵集群</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">+----+</span><br><span class="line">| M1 |</span><br><span class="line">| S1 |</span><br><span class="line">+----+</span><br><span class="line">   |</span><br></pre></td></tr></table></figure>
<p>+—-+    |    +—-+<br>| R2 |—-+—-| R3 |<br>| S2 |         | S3 |<br>+—-+         +—-+</p>
<p>Configuration: quorum = 2，majority = 2</p>
<p>如果M1所在机器宕机了，那么三个哨兵还剩下2个，S2和S3可以一致认为master宕机，然后选举出一个来执行故障转移</p>
<p>同时3个哨兵的majority是2，所以还剩下的2个哨兵运行着，就可以允许执行故障转移</p>
<h3 id="redis哨兵主备切换的数据丢失问题：异步复制，集群脑裂"><a href="#redis哨兵主备切换的数据丢失问题：异步复制，集群脑裂" class="headerlink" title="redis哨兵主备切换的数据丢失问题：异步复制，集群脑裂"></a>redis哨兵主备切换的数据丢失问题：异步复制，集群脑裂</h3><p>课程大纲</p>
<p>1、两种数据丢失的情况<br>2、解决异步复制和脑裂导致的数据丢失</p>
<hr>
<p>1、两种数据丢失的情况</p>
<p>主备切换的过程，可能会导致数据丢失</p>
<p>（1）异步复制导致的数据丢失</p>
<p>因为master -&gt; slave的复制是异步的，所以可能有部分数据还没复制到slave，master就宕机了，此时这些部分数据就丢失了</p>
<p>（2）脑裂导致的数据丢失</p>
<p>脑裂，也就是说，某个master所在机器突然脱离了正常的网络，跟其他slave机器不能连接，但是实际上master还运行着</p>
<p>此时哨兵可能就会认为master宕机了，然后开启选举，将其他slave切换成了master</p>
<p>这个时候，集群里就会有两个master，也就是所谓的脑裂</p>
<p>此时虽然某个slave被切换成了master，但是可能client还没来得及切换到新的master，还继续写向旧master的数据可能也丢失了</p>
<p>因此旧master再次恢复的时候，会被作为一个slave挂到新的master上去，自己的数据会清空，重新从新的master复制数据</p>
<hr>
<p>2、解决异步复制和脑裂导致的数据丢失</p>
<p>min-slaves-to-write 1<br>min-slaves-max-lag 10</p>
<p>要求至少有1个slave，数据复制和同步的延迟不能超过10秒</p>
<p>如果说一旦所有的slave，数据复制和同步的延迟都超过了10秒钟，那么这个时候，master就不会再接收任何请求了</p>
<p>上面两个配置可以减少异步复制和脑裂导致的数据丢失</p>
<p>（1）减少异步复制的数据丢失</p>
<p>有了min-slaves-max-lag这个配置，就可以确保说，一旦slave复制数据和ack延时太长，就认为可能master宕机后损失的数据太多了，那么就拒绝写请求，这样可以把master宕机时由于部分数据未同步到slave导致的数据丢失降低的可控范围内</p>
<p>（2）减少脑裂的数据丢失</p>
<p>如果一个master出现了脑裂，跟其他slave丢了连接，那么上面两个配置可以确保说，如果不能继续给指定数量的slave发送数据，而且slave超过10秒没有给自己ack消息，那么就直接拒绝客户端的写请求</p>
<p>这样脑裂后的旧master就不会接受client的新数据，也就避免了数据丢失</p>
<p>上面的配置就确保了，如果跟任何一个slave丢了连接，在10秒后发现没有slave给自己ack，那么就拒绝新的写请求</p>
<p>因此在脑裂场景下，最多就丢失10秒的数据</p>
<h3 id="redis哨兵的多个核心底层原理的深入解析"><a href="#redis哨兵的多个核心底层原理的深入解析" class="headerlink" title="redis哨兵的多个核心底层原理的深入解析"></a>redis哨兵的多个核心底层原理的深入解析</h3><p>1、sdown和odown转换机制</p>
<p>sdown和odown两种失败状态</p>
<p>sdown是主观宕机，就一个哨兵如果自己觉得一个master宕机了，那么就是主观宕机</p>
<p>odown是客观宕机，如果quorum数量的哨兵都觉得一个master宕机了，那么就是客观宕机</p>
<p>sdown达成的条件很简单，如果一个哨兵ping一个master，超过了is-master-down-after-milliseconds指定的毫秒数之后，就主观认为master宕机</p>
<p>sdown到odown转换的条件很简单，如果一个哨兵在指定时间内，收到了quorum指定数量的其他哨兵也认为那个master是sdown了，那么就认为是odown了，客观认为master宕机</p>
<p>2、哨兵集群的自动发现机制</p>
<p>哨兵互相之间的发现，是通过redis的pub/sub系统实现的，每个哨兵都会往<strong>sentinel</strong>:hello这个channel里发送一个消息，这时候所有其他哨兵都可以消费到这个消息，并感知到其他的哨兵的存在</p>
<p>每隔两秒钟，每个哨兵都会往自己监控的某个master+slaves对应的<strong>sentinel</strong>:hello channel里发送一个消息，内容是自己的host、ip和runid还有对这个master的监控配置</p>
<p>每个哨兵也会去监听自己监控的每个master+slaves对应的<strong>sentinel</strong>:hello channel，然后去感知到同样在监听这个master+slaves的其他哨兵的存在</p>
<p>每个哨兵还会跟其他哨兵交换对master的监控配置，互相进行监控配置的同步</p>
<p>3、slave配置的自动纠正</p>
<p>哨兵会负责自动纠正slave的一些配置，比如slave如果要成为潜在的master候选人，哨兵会确保slave在复制现有master的数据; 如果slave连接到了一个错误的master上，比如故障转移之后，那么哨兵会确保它们连接到正确的master上</p>
<p>4、slave-&gt;master选举算法</p>
<p>如果一个master被认为odown了，而且majority哨兵都允许了主备切换，那么某个哨兵就会执行主备切换操作，此时首先要选举一个slave来</p>
<p>会考虑slave的一些信息</p>
<p>（1）跟master断开连接的时长<br>（2）slave优先级<br>（3）复制offset<br>（4）run id</p>
<p>如果一个slave跟master断开连接已经超过了down-after-milliseconds的10倍，外加master宕机的时长，那么slave就被认为不适合选举为master</p>
<p>(down-after-milliseconds * 10) + milliseconds_since_master_is_in_SDOWN_state</p>
<p>接下来会对slave进行排序</p>
<p>（1）按照slave优先级进行排序，slave priority越低，优先级就越高(slave priority是在redis.conf文件中自己设置的)<br>（2）如果slave priority相同，那么看replica offset，哪个slave复制了越多的数据，offset越靠后，优先级就越高<br>（3）如果上面两个条件都相同，那么选择一个run id比较小的那个slave</p>
<p>5、quorum和majority</p>
<p>每次一个哨兵要做主备切换，首先需要quorum数量的哨兵认为odown，然后选举出一个哨兵来做切换，这个哨兵还得得到majority哨兵的授权，才能正式执行切换</p>
<p>如果quorum &lt; majority，比如5个哨兵，majority就是3，quorum设置为2，那么就3个哨兵授权就可以执行切换</p>
<p>但是如果quorum &gt;= majority，那么必须quorum数量的哨兵都授权，比如5个哨兵，quorum是5，那么必须5个哨兵都同意授权，才能执行切换</p>
<p>6、configuration epoch</p>
<p>哨兵会对一套redis master+slave进行监控，有相应的监控的配置</p>
<p>执行切换的那个哨兵，会从要切换到的新master（salve-&gt;master）那里得到一个configuration epoch，这就是一个version号，每次切换的version号都必须是唯一的</p>
<p>如果第一个选举出的哨兵切换失败了，那么其他哨兵，会等待failover-timeout时间，然后接替继续执行切换，此时会重新获取一个新的configuration epoch，作为新的version号</p>
<p>7、configuraiton传播</p>
<p>哨兵完成切换之后，会在自己本地更新生成最新的master配置，然后同步给其他的哨兵，就是通过之前说的pub/sub消息机制</p>
<p>这里之前的version号就很重要了，因为各种消息都是通过一个channel去发布和监听的，所以一个哨兵完成一次新的切换之后，新的master配置是跟着新的version号的</p>
<p>其他的哨兵都是根据版本号的大小来更新自己的master配置的</p>
<h3 id="redis哨兵集群的实战配置"><a href="#redis哨兵集群的实战配置" class="headerlink" title="redis哨兵集群的实战配置"></a>redis哨兵集群的实战配置</h3><p>quorum的解释如下：</p>
<p>（1）至少多少个哨兵要一致同意，master进程挂掉了，或者slave进程挂掉了，或者要启动一个故障转移操作<br>（2）quorum是用来识别故障的，真正执行故障转移的时候，还是要在哨兵集群执行选举，选举一个哨兵进程出来执行故障转移操作<br>（3）假设有5个哨兵，quorum设置了2，那么如果5个哨兵中的2个都认为master挂掉了; 2个哨兵中的一个就会做一个选举，选举一个哨兵出来，执行故障转移; 如果5个哨兵中有3个哨兵都是运行的，那么故障转移就会被允许执行</p>
<p>动手实操，练习如何操作部署哨兵集群，如何基于哨兵进行故障转移，还有一些企业级的配置方案</p>
<p>1、哨兵的配置文件<br>(存放在redis安装目录下)<br>sentinel.conf</p>
<p>最小的配置</p>
<p>每一个哨兵都可以去监控多个maser-slaves的主从架构</p>
<p>因为可能你的公司里，为不同的项目，部署了多个master-slaves的redis主从集群</p>
<p>相同的一套哨兵集群，就可以去监控不同的多个redis主从集群</p>
<p>你自己给每个redis主从集群分配一个逻辑的名称</p>
<p>sentinel monitor mymaster 127.0.0.1 6379 2<br>sentinel down-after-milliseconds mymaster 60000<br>sentinel failover-timeout mymaster 180000<br>sentinel parallel-syncs mymaster 1</p>
<p>sentinel monitor resque 192.168.1.3 6380 4<br>sentinel down-after-milliseconds resque 10000<br>sentinel failover-timeout resque 180000<br>sentinel parallel-syncs resque 5</p>
<p>sentinel monitor mymaster 127.0.0.1 6379 </p>
<p>类似这种配置，来指定对一个master的监控，给监控的master指定的一个名称，因为后面分布式集群架构里会讲解，可以配置多个master做数据拆分</p>
<p>sentinel down-after-milliseconds mymaster 60000<br>sentinel failover-timeout mymaster 180000<br>sentinel parallel-syncs mymaster 1</p>
<p>上面的三个配置，都是针对某个监控的master配置的，给其指定上面分配的名称即可</p>
<p>上面这段配置，就监控了两个master node</p>
<p>这是最小的哨兵配置，如果发生了master-slave故障转移，或者新的哨兵进程加入哨兵集群，那么哨兵会自动更新自己的配置文件</p>
<p>sentinel monitor master-group-name hostname port quorum</p>
<p>quorum的解释如下：</p>
<p>（1）至少多少个哨兵要一致同意，master进程挂掉了，或者slave进程挂掉了，或者要启动一个故障转移操作<br>（2）quorum是用来识别故障的，真正执行故障转移的时候，还是要在哨兵集群执行选举，选举一个哨兵进程出来执行故障转移操作<br>（3）假设有5个哨兵，quorum设置了2，那么如果5个哨兵中的2个都认为master挂掉了; 2个哨兵中的一个就会做一个选举，选举一个哨兵出来，执行故障转移; 如果5个哨兵中有3个哨兵都是运行的，那么故障转移就会被允许执行</p>
<p>down-after-milliseconds，超过多少毫秒跟一个redis实例断了连接，哨兵就可能认为这个redis实例挂了</p>
<p>parallel-syncs，新的master别切换之后，同时有多少个slave被切换到去连接新master，重新做同步，数字越低，花费的时间越多</p>
<p>假设你的redis是1个master，4个slave</p>
<p>然后master宕机了，4个slave中有1个切换成了master，剩下3个slave就要挂到新的master上面去</p>
<p>这个时候，如果parallel-syncs是1，那么3个slave，一个一个地挂接到新的master上面去，1个挂接完，而且从新的master sync完数据之后，再挂接下一个</p>
<p>如果parallel-syncs是3，那么一次性就会把所有slave挂接到新的master上去</p>
<p>failover-timeout，执行故障转移的timeout超时时长</p>
<p>2、在eshop-cache03上再部署一个redis</p>
<p>只要安装redis就可以了，不需要去部署redis实例的启动</p>
<p>wget <a href="http://downloads.sourceforge.net/tcl/tcl8.6.1-src.tar.gz" target="_blank" rel="noopener">http://downloads.sourceforge.net/tcl/tcl8.6.1-src.tar.gz</a><br>tar -xzvf tcl8.6.1-src.tar.gz<br>cd  /usr/local/tcl8.6.1/unix/<br>./configure<br>make &amp;&amp; make install</p>
<p>使用redis-3.2.8.tar.gz（截止2017年4月的最新稳定版）<br>tar -zxvf redis-3.2.8.tar.gz<br>cd redis-3.2.8<br>make &amp;&amp; make test<br>make install</p>
<p>2、正式的配置</p>
<p>哨兵默认用26379端口，默认不能跟其他机器在指定端口连通，只能在本地访问</p>
<p>mkdir /etc/sentinal<br>mkdir -p /var/sentinal/5000</p>
<p>/etc/sentinel/5000.conf</p>
<p>port 5000<br>bind 192.168.31.187<br>dir /var/sentinal/5000<br>sentinel monitor mymaster 192.168.31.187 6379 2<br>sentinel down-after-milliseconds mymaster 30000<br>sentinel failover-timeout mymaster 60000<br>sentinel parallel-syncs mymaster 1</p>
<p>port 5000<br>bind 192.168.31.19<br>dir /var/sentinal/5000<br>sentinel monitor mymaster 192.168.31.187 6379 2<br>sentinel down-after-milliseconds mymaster 30000<br>sentinel failover-timeout mymaster 60000<br>sentinel parallel-syncs mymaster 1</p>
<p>port 5000<br>bind 192.168.31.227<br>dir /var/sentinal/5000<br>sentinel monitor mymaster 192.168.31.187 6379 2<br>sentinel down-after-milliseconds mymaster 30000<br>sentinel failover-timeout mymaster 60000<br>sentinel parallel-syncs mymaster 1</p>
<p>3、启动哨兵进程</p>
<p>在eshop-cache01、eshop-cache02、eshop-cache03三台机器上，分别启动三个哨兵进程，组成一个集群，观察一下日志的输出</p>
<p>redis-sentinel /etc/sentinal/5000.conf<br>redis-server /etc/sentinal/5000.conf –sentinel</p>
<p>日志里会显示出来，每个哨兵都能去监控到对应的redis master，并能够自动发现对应的slave</p>
<p>哨兵之间，互相会自动进行发现，用的就是之前说的pub/sub，消息发布和订阅channel消息系统和机制</p>
<p>4、检查哨兵状态</p>
<p>redis-cli -h 192.168.31.187 -p 5000</p>
<p>sentinel master mymaster<br>SENTINEL slaves mymaster<br>SENTINEL sentinels mymaster</p>
<p>SENTINEL get-master-addr-by-name mymaster</p>
<h3 id="redis-cluster横向扩容master"><a href="#redis-cluster横向扩容master" class="headerlink" title="redis cluster横向扩容master"></a>redis cluster横向扩容master</h3><p>1、单机redis在海量数据面前的瓶颈</p>
<p>2、怎么才能够突破单机瓶颈，让redis支撑海量数据？</p>
<p>3、redis的集群架构</p>
<p>redis cluster</p>
<p>支撑N个redis master node，每个master node都可以挂载多个slave node</p>
<p>读写分离的架构，对于每个master来说，写就写到master，然后读就从mater对应的slave去读</p>
<p>高可用，因为每个master都有salve节点，那么如果mater挂掉，redis cluster这套机制，就会自动将某个slave切换成master</p>
<p>redis cluster（多master + 读写分离 + 高可用）</p>
<p>我们只要基于redis cluster去搭建redis集群即可，不需要手工去搭建replication复制+主从架构+读写分离+哨兵集群+高可用</p>
<p>4、redis cluster vs. replication + sentinal</p>
<p>如果你的数据量很少，主要是承载高并发高性能的场景，比如你的缓存一般就几个G，单机足够了</p>
<p>replication，一个mater，多个slave，要几个slave跟你的要求的读吞吐量有关系，然后自己搭建一个sentinal集群，去保证redis主从架构的高可用性，就可以了</p>
<p>redis cluster，主要是针对海量数据+高并发+高可用的场景，海量数据，如果你的数据量很大，那么建议就用redis cluster</p>
<h3 id="redis阶段性总结"><a href="#redis阶段性总结" class="headerlink" title="redis阶段性总结"></a>redis阶段性总结</h3><p>1、讲解redis是为了什么？</p>
<p>topic：高并发、亿级流量、高性能、海量数据的场景，电商网站的商品详情页系统的缓存架构</p>
<p>商品详情页系统，大型电商网站，会有很多部分组成，但是支撑高并发、亿级流量的，主要就是其中的大型的缓存架构</p>
<p>在这个大型的缓存架构中，redis是最最基础的一层</p>
<p>高并发，缓存架构中除了redis，还有其他的组成部分，但是redis至关重要</p>
<p>大量的离散请求，随机请求，各种你未知的用户过来的请求，上千万用户过来访问，每个用户访问10次; 集中式的请求，1个用户过来，一天访问1亿次</p>
<p>支撑商品展示的最重要的，就是redis cluster，去抗住每天上亿的请求流量，支撑高并发的访问</p>
<p>redis cluster在整个缓存架构中，如何跟其他几个部分搭配起来组成一个大型的缓存系统，后面再讲</p>
<p>2、讲解的redis可以实现什么效果？</p>
<p>我之前一直在redis的各个知识点的讲解之前都强调一下，我们要讲解的每个知识点，要解决的问题是什么？？？</p>
<p>redis：持久化、复制（主从架构）、哨兵（高可用，主备切换）、redis cluster（海量数据+横向扩容+高可用/主备切换）</p>
<p>持久化：高可用的一部分，在发生redis集群灾难的情况下（比如说部分master+slave全部死掉了），如何快速进行数据恢复，快速实现服务可用，才能实现整个系统的高可用</p>
<p>复制：主从架构，master -&gt; slave 复制，读写分离的架构，写master，读slave，横向扩容slave支撑更高的读吞吐，读高并发，10万，20万，30万，上百万，QPS，横向扩容</p>
<p>哨兵：高可用，主从架构，在master故障的时候，快速将slave切换成master，实现快速的灾难恢复，实现高可用性</p>
<p>redis cluster：多master读写，数据分布式的存储，横向扩容，水平扩容，快速支撑高达的数据量+更高的读写QPS，自动进行master -&gt; slave的主备切换，高可用</p>
<p>让底层的缓存系统，redis，实现能够任意水平扩容，支撑海量数据（1T+，几十T，10G * 600 redis = 6T），支撑很高的读写QPS（redis单机在几万QPS，10台，几十万QPS），高可用性（给我们每个redis实例都做好AOF+RDB的备份策略+容灾策略，slave -&gt; master主备切换）</p>
<p>1T+海量数据、10万+读写QPS、99.99%高可用性</p>
<p>3、redis的第一套企业级的架构</p>
<p>如果你的数据量不大，单master就可以容纳，一般来说你的缓存的总量在10G以内就可以，那么建议按照以下架构去部署redis</p>
<p>redis持久化+备份方案+容灾方案+replication（主从+读写分离）+sentinal（哨兵集群，3个节点，高可用性）</p>
<p>可以支撑的数据量在10G以内，可以支撑的写QPS在几万左右，可以支撑的读QPS可以上10万以上（随你的需求，水平扩容slave节点就可以），可用性在99.99%</p>
<p>4、redis的第二套企业级架构</p>
<p>如果你的数据量很大，比如我们课程的topic，大型电商网站的商品详情页的架构（对标那些国内排名前三的大电商网站，<em>宝，</em>东，*宁易购），数据量是很大的</p>
<p>海量数据</p>
<p>redis cluster</p>
<p>多master分布式存储数据，水平扩容</p>
<p>支撑更多的数据量，1T+以上没问题，只要扩容master即可</p>
<p>读写QPS分别都达到几十万都没问题，只要扩容master即可，redis cluster，读写分离，支持不太好，readonly才能去slave上读</p>
<p>支撑99.99%可用性，也没问题，slave -&gt; master的主备切换，冗余slave去进一步提升可用性的方案（每个master挂一个slave，但是整个集群再加个3个slave冗余一下）</p>
<p>我们课程里，两套架构都讲解了，后续的业务系统的开发，主要是基于redis cluster去做</p>
<p>5、我们现在课程讲解的项目进展到哪里了？</p>
<p>我们要做后续的业务系统的开发，redis的架构部署好，是第一件事情，也是非常重要的，也是你作为一个架构师而言，在对系统进行设计的时候，你必须要考虑到底层的redis的并发、性能、能支撑的数据量、可用性</p>
<p>redis：水平扩容，海量数据，上10万的读写QPS，99.99%高可用性</p>
<p>从架构的角度，我们的redis是可以做到的，水平扩容，只要机器足够，到1T数据量，50万读写QPS，99.99%</p>
<p>正式开始做大型电商网站的商品详情页系统，大规模的缓存架构设计</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/10/01/SQL注入/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Chen ZeTao">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/weixin.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="ddd `Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/10/01/SQL注入/" itemprop="url">SQL注入</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-10-01T17:50:41+08:00">
                2019-10-01
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  1.6k
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  6
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="SQL注入简介"><a href="#SQL注入简介" class="headerlink" title="SQL注入简介"></a>SQL注入简介</h2><p>SQL注入是网站存在最多也是最简单的漏洞，主要原因是程序员在开发用户和数据库交互的系统时，没有对用户输入的字符串进行过滤，转义，限制或处理不严谨，导致用户可以通过输入精心构造的字符串去非法获取到数据库中的数据。</p>
<h3 id="SQL注入原理"><a href="#SQL注入原理" class="headerlink" title="SQL注入原理"></a>SQL注入原理</h3><p>一般用户登录用的SQL语句为：SELECT <em> FROM user WHERE username=’admin’ AND password=’passwd’，此处admin和passwd分别为用户输入的用户名和密码，如果程序员没有对用户输入的用户名和密码做处理，就可以构造万能密码成功绕过登录验证，如用户输入<strong>‘or 1#</strong>,SQL语句将变为：SELECT </em> FROM user WHERE username=’’or 1#’ AND password=’’，‘’or 1为TRUE，#注释掉后面的内容，所以查询语句可以正确执行。</p>
<h3 id="mybatis是如何防止SQL注入的"><a href="#mybatis是如何防止SQL注入的" class="headerlink" title="mybatis是如何防止SQL注入的"></a>mybatis是如何防止SQL注入的</h3><h3 id="1、首先看一下下面两个sql语句的区别："><a href="#1、首先看一下下面两个sql语句的区别：" class="headerlink" title="1、首先看一下下面两个sql语句的区别："></a>1、首先看一下下面两个sql语句的区别：</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;select id="selectByNameAndPassword" parameterType="java.util.Map" resultMap="BaseResultMap"&gt;</span><br><span class="line"><span class="keyword">select</span> <span class="keyword">id</span>, username, <span class="keyword">password</span>, <span class="keyword">role</span></span><br><span class="line"><span class="keyword">from</span> <span class="keyword">user</span></span><br><span class="line"><span class="keyword">where</span> username = <span class="comment">#&#123;username,jdbcType=VARCHAR&#125;</span></span><br><span class="line"><span class="keyword">and</span> <span class="keyword">password</span> = <span class="comment">#&#123;password,jdbcType=VARCHAR&#125;</span></span><br><span class="line">&lt;/<span class="keyword">select</span>&gt;</span><br></pre></td></tr></table></figure>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;select id="selectByNameAndPassword" parameterType="java.util.Map" resultMap="BaseResultMap"&gt;</span><br><span class="line"><span class="keyword">select</span> <span class="keyword">id</span>, username, <span class="keyword">password</span>, <span class="keyword">role</span></span><br><span class="line"><span class="keyword">from</span> <span class="keyword">user</span></span><br><span class="line"><span class="keyword">where</span> username = $&#123;username,jdbcType=<span class="built_in">VARCHAR</span>&#125;</span><br><span class="line"><span class="keyword">and</span> <span class="keyword">password</span> = $&#123;<span class="keyword">password</span>,jdbcType=<span class="built_in">VARCHAR</span>&#125;</span><br><span class="line">&lt;/<span class="keyword">select</span>&gt;</span><br></pre></td></tr></table></figure>
<p><strong>mybatis中的#和$的区别：</strong></p>
<p>1、#将传入的数据都当成一个字符串，会对自动传入的数据加一个双引号。<br>如：where username=#{username}，如果传入的值是111,那么解析成sql时的值为where username=”111”, 如果传入的值是id，则解析成的sql为where username=”id”.　<br>2、$将传入的数据直接显示生成在sql中。<br>如：where username=${username}，如果传入的值是111,那么解析成sql时的值为where username=111；<br>如果传入的值是;drop table user;，则解析成的sql为：select id, username, password, role from user where username=;drop table user;<br>3、#方式能够很大程度防止sql注入，$方式无法防止Sql注入。<br>4、$方式一般用于传入数据库对象，例如传入表名.<br>5、一般能用#的就别用$，若不得不使用“${xxx}”这样的参数，要手工地做好过滤工作，来防止sql注入攻击。<br>6、在MyBatis中，“${xxx}”这样格式的参数会直接参与SQL编译，从而不能避免注入攻击。但涉及到动态表名和列名时，只能使用“${xxx}”这样的参数格式。所以，这样的参数需要我们在代码中手工进行处理来防止注入。<br>【结论】在编写MyBatis的映射语句时，尽量采用“#{xxx}”这样的格式。若不得不使用“${xxx}”这样的参数，要手工地做好过滤工作，来防止SQL注入攻击。</p>
<h3 id="2、什么是sql注入"><a href="#2、什么是sql注入" class="headerlink" title="2、什么是sql注入"></a>2、什么是sql注入</h3><p>　　<a href="https://en.wikipedia.org/wiki/SQL_injection" target="_blank" rel="noopener"> sql注入解释</a>：是一种代码注入技术，用于攻击数据驱动的应用，恶意的SQL语句被插入到执行的实体字段中（例如，为了转储数据库内容给攻击者）</p>
<p>　　<strong>SQL**</strong>注入<strong>，大家都不陌生，是一种常见的攻击方式。</strong>攻击者<strong>在界面的表单信息或URL上输入一些奇怪的SQL片段（例如“or ‘1’=’1’”这样的语句），有可能入侵</strong>参数检验不足<strong>的应用程序。所以，在我们的应用中需要做一些工作，来防备这样的攻击方式。在一些安全性要求很高的应用中（比如银行软件），经常使用将</strong>SQL<strong>**语句</strong>全部替换为<strong>存储过程</strong>这样的方式，来防止SQL注入。这当然是<strong>一种很安全的方式</strong>，但我们平时开发中，可能不需要这种死板的方式。</p>
<h3 id="3、mybatis是如何做到防止sql注入的"><a href="#3、mybatis是如何做到防止sql注入的" class="headerlink" title="3、mybatis是如何做到防止sql注入的"></a>3、mybatis是如何做到防止sql注入的</h3><p>　　<a href="https://mybatis.github.io/mybatis-3/" target="_blank" rel="noopener">MyBatis</a>框架作为一款半自动化的持久层框架，其SQL语句都要我们自己手动编写，这个时候当然需要防止SQL注入。其实，MyBatis的SQL是一个具有“<strong>输入+输出</strong>”的功能，类似于函数的结构，参考上面的两个例子。其中，parameterType表示了输入的参数类型，resultType表示了输出的参数类型。回应上文，如果我们想防止SQL注入，理所当然地要在输入参数上下功夫。上面代码中使用 <strong>#</strong> 的即输入参数在SQL中拼接的部分，传入参数后，打印出执行的SQL语句，会看到SQL是这样的：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select id, username, password, role from user where username=? and password=?</span><br></pre></td></tr></table></figure>
<p>　　不管输入什么参数，打印出的SQL都是这样的。这是因为MyBatis启用了预编译功能，在SQL执行前，会先将上面的SQL发送给数据库进行编译；执行时，直接使用编译好的SQL，替换占位符“?”就可以了。因为SQL注入只能对编译过程起作用，所以这样的方式就很好地避免了SQL注入的问题。</p>
<p>　　【底层实现原理】MyBatis是如何做到SQL预编译的呢？其实在框架底层，是JDBC中的PreparedStatement类在起作用，PreparedStatement是我们很熟悉的Statement的子类，它的对象包含了编译好的SQL语句。这种“准备好”的方式不仅能提高安全性，而且在多次执行同一个SQL时，能够提高效率。原因是SQL已编译好，再次执行时无需再编译。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">//安全的，预编译了的</span><br><span class="line">Connection conn = getConn();//获得连接</span><br><span class="line">String sql = &quot;select id, username, password, role from user where id=?&quot;; //执行sql前会预编译号该条语句</span><br><span class="line">PreparedStatement pstmt = conn.prepareStatement(sql); </span><br><span class="line">pstmt.setString(1, id); </span><br><span class="line">ResultSet rs=pstmt.executeUpdate(); </span><br><span class="line">......</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">//不安全的，没进行预编译</span><br><span class="line">private String getNameByUserId(String userId) &#123;</span><br><span class="line">    Connection conn = getConn();//获得连接</span><br><span class="line">    String sql = &quot;select id,username,password,role from user where id=&quot; + id;</span><br><span class="line">    //当id参数为&quot;3;drop table user;&quot;时，执行的sql语句如下:</span><br><span class="line">    //select id,username,password,role from user where id=3; drop table user;  </span><br><span class="line">    PreparedStatement pstmt =  conn.prepareStatement(sql);</span><br><span class="line">    ResultSet rs=pstmt.executeUpdate();</span><br><span class="line">    ......</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>【 <strong>结论</strong>：】</p>
<table>
<thead>
<tr>
<th>#{}：相当于JDBC中的PreparedStatement</th>
</tr>
</thead>
<tbody>
<tr>
<td>${}：是输出变量的值</td>
</tr>
</tbody>
</table>
<p>简单说，#{}是经过预编译的，是安全的；${}是未经过预编译的，仅仅是取变量的值，是非安全的，存在SQL注入。<br>如果我们order by语句后用了${}，那么不做任何处理的时候是存在SQL注入危险的。你说怎么防止，那我只能悲惨的告诉你，你得手动处理过滤一下输入的内容。如判断一下输入的参数的长度是否正常（注入语句一般很长），更精确的过滤则可以查询一下输入的参数是否在预期的参数集合中。</p>
<p>作者：<a href="http://www.cnblogs.com/mmzs/" target="_blank" rel="noopener">淼淼之森</a></p>
<p>### </p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/10/01/JAVA锁/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Chen ZeTao">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/weixin.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="ddd `Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/10/01/JAVA锁/" itemprop="url">JAVA锁</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-10-01T17:48:43+08:00">
                2019-10-01
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  4.1k
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  14
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="JAVA锁"><a href="#JAVA锁" class="headerlink" title="JAVA锁"></a>JAVA锁</h1><p>Java SE1.6为了减少获得锁和释放锁所带来的性能消耗，引入了“偏向锁”和“轻量级锁”，所以在Java SE1.6里锁一共有四种状态，无锁状态，偏向锁状态，轻量级锁状态和重量级锁状态，它会随着竞争情况逐渐升级。<strong>锁可以升级但不能降级，意味着偏向锁升级成轻量级锁后不能降级成偏向锁。这种锁升级却不能降级的策略，目的是为了提高获得锁和释放锁的效率。</strong></p>
<h3 id="悲观锁与乐观锁"><a href="#悲观锁与乐观锁" class="headerlink" title="悲观锁与乐观锁"></a>悲观锁与乐观锁</h3><h4 id="悲观锁"><a href="#悲观锁" class="headerlink" title="悲观锁"></a>悲观锁</h4><p>总是假设最坏的情况，每次去拿数据的时候都认为别人会修改，所以每次在拿数据的时候都会上锁。传统的关系型数据库里边就用到了很多这种锁机制，比如行锁，表锁，读锁，写锁等，都是在做操作之前先上锁。JAVA中synchronize和ReentrantLock等独占锁就是悲观锁思想的实现。</p>
<h4 id="乐观锁"><a href="#乐观锁" class="headerlink" title="乐观锁"></a>乐观锁</h4><p>总是假设最好的情况，每次拿数据都认为别人不会修改，所以不会上锁。<strong>但是在更新的时候会判断一下在此期间别人有没有去更新这个数据，可以使用版本号机制和CAS算法实现。</strong></p>
<p>乐观锁适用于多读的应用类型，这样可以提高吞吐量。</p>
<p><strong>java中的4种锁，分别是重量级锁，自旋锁，轻量级锁和偏向锁。重量级锁是悲观锁的一种，自旋锁，轻量级锁和偏向锁属于乐观锁。</strong></p>
<h5 id="乐观锁常见的两种实现方式"><a href="#乐观锁常见的两种实现方式" class="headerlink" title="乐观锁常见的两种实现方式"></a>乐观锁常见的两种实现方式</h5><blockquote>
<p><strong>乐观锁一般会使用版本号机制或CAS算法实现。</strong></p>
</blockquote>
<h4 id="1-版本号机制"><a href="#1-版本号机制" class="headerlink" title="1. 版本号机制"></a>1. 版本号机制</h4><p>一般是在数据表中加上一个数据版本号version字段，表示数据被修改的次数，当数据被修改时，version值会加一。当线程A要更新数据值时，在读取数据的同时也会读取version值，在提交更新时，若刚才读取到的version值为当前数据库中的version值相等时才更新，否则重试更新操作，直到更新成功。</p>
<p><strong>举一个简单的例子：</strong> 假设数据库中帐户信息表中有一个 version 字段，当前值为 1 ；而当前帐户余额字段（ balance ）为 $100 。</p>
<ol>
<li>操作员 A 此时将其读出（ version=1 ），并从其帐户余额中扣除 $50（ $100-$50 ）。</li>
<li>在操作员 A 操作的过程中，操作员B 也读入此用户信息（ version=1 ），并从其帐户余额中扣除 $20 （ $100-$20 ）。</li>
<li>操作员 A 完成了修改工作，将数据版本号加一（ version=2 ），连同帐户扣除后余额（ balance=$50 ），提交至数据库更新，此时由于提交数据版本大于数据库记录当前版本，数据被更新，数据库记录 version 更新为 2 。</li>
<li>操作员 B 完成了操作，也将版本号加一（ version=2 ）试图向数据库提交数据（ balance=$80 ），但此时比对数据库记录版本时发现，操作员 B 提交的数据版本号为 2 ，数据库记录当前版本也为 2 ，不满足 “ 提交版本必须大于记录当前版本才能执行更新 “ 的乐观锁策略，因此，操作员 B 的提交被驳回。</li>
</ol>
<p>这样，就避免了操作员 B 用基于 version=1 的旧数据修改的结果覆盖操作员A 的操作结果的可能。</p>
<h4 id="2-简单回顾一下CAS算法"><a href="#2-简单回顾一下CAS算法" class="headerlink" title="2.简单回顾一下CAS算法"></a>2.简单回顾一下CAS算法</h4><p><strong>CAS算法</strong> 即compare and swap（比较与交换），是一种有名的无锁算法。无锁编程，即不使用锁的情况下实现多线程之间的变量同步，也就是在没有线程被阻塞的情况下实现变量的同步，所以也叫非阻塞同步（Non-blocking Synchronization）。CAS算法涉及到三个操作数</p>
<ul>
<li>需要读写的内存值 V</li>
<li>进行比较的值 A</li>
<li>拟写入的新值 B</li>
</ul>
<p>当且仅当 V 的值等于 A时，CAS通过原子方式用新值B来更新V的值，否则不会执行任何操作（比较和替换是一个原子操作）。一般情况下是一个自旋操作，即不断的重试。</p>
<h3 id="乐观锁的缺点"><a href="#乐观锁的缺点" class="headerlink" title="乐观锁的缺点"></a>乐观锁的缺点</h3><blockquote>
<p>ABA 问题是乐观锁一个常见的问题</p>
</blockquote>
<h4 id="1-ABA-问题"><a href="#1-ABA-问题" class="headerlink" title="1 ABA 问题"></a>1 ABA 问题</h4><p>如果一个变量V初次读取的时候是A值，并且在准备赋值的时候检查到它仍然是A值，那我们就能说明它的值没有被其他线程修改过了吗？很明显是不能的，因为在这段时间它的值可能被改为其他值，然后又改回A，那CAS操作就会误认为它从来没有被修改过。这个问题被称为CAS操作的 <strong>“ABA”问题。</strong></p>
<p>JDK 1.5 以后的 <code>AtomicStampedReference 类</code>就提供了此种能力，其中的 <code>compareAndSet 方法</code>就是首先检查当前引用是否等于预期引用，并且当前标志是否等于预期标志，如果全部相等，则以原子方式将该引用和该标志的值设置为给定的更新值。</p>
<h4 id="2-循环时间长开销大"><a href="#2-循环时间长开销大" class="headerlink" title="2 循环时间长开销大"></a>2 循环时间长开销大</h4><p><strong>自旋CAS（也就是不成功就一直循环执行直到成功）如果长时间不成功，会给CPU带来非常大的执行开销。</strong> 如果JVM能支持处理器提供的pause指令那么效率会有一定的提升，pause指令有两个作用，第一它可以延迟流水线执行指令（de-pipeline）,使CPU不会消耗过多的执行资源，延迟的时间取决于具体实现的版本，在一些处理器上延迟时间是零。第二它可以避免在退出循环的时候因内存顺序冲突（memory order violation）而引起CPU流水线被清空（CPU pipeline flush），从而提高CPU的执行效率。</p>
<h4 id="3-只能保证一个共享变量的原子操作"><a href="#3-只能保证一个共享变量的原子操作" class="headerlink" title="3 只能保证一个共享变量的原子操作"></a>3 只能保证一个共享变量的原子操作</h4><p>CAS 只对单个共享变量有效，当操作涉及跨多个共享变量时 CAS 无效。但是从 JDK 1.5开始，提供了<code>AtomicReference类</code>来保证引用对象之间的原子性，你可以把多个变量放在一个对象里来进行 CAS 操作.所以我们可以使用锁或者利用<code>AtomicReference类</code>把多个共享变量合并成一个共享变量来操作。</p>
<h3 id="什么是自旋锁？"><a href="#什么是自旋锁？" class="headerlink" title="什么是自旋锁？"></a>什么是自旋锁？</h3><p>自旋锁（spinlock）：是指当一个线程在获取锁的时候，如果锁已经被其它线程获取，那么该线程将循环等待，然后不断的判断锁是否能够被成功获取，直到获取到锁才会退出循环。</p>
<p>获取锁的线程一直处于活跃状态，但是并没有执行任何有效的任务，使用这种锁会造成<a href="https://en.wikipedia.org/wiki/Busy_waiting" target="_blank" rel="noopener">busy-waiting</a>。</p>
<p>它是为实现保护共享资源而提出一种锁机制。其实，自旋锁与互斥锁比较类似，它们都是为了解决对某项资源的互斥使用。无论是互斥锁，还是自旋锁，在任何时刻，最多只能有一个保持者，也就说，在任何时刻最多只能有一个执行单元获得锁。但是两者在调度机制上略有不同。对于互斥锁，如果资源已经被占用，资源申请者只能进入睡眠状态。但是自旋锁不会引起调用者睡眠，如果自旋锁已经被别的执行单元保持，调用者就一直循环在那里看是否该自旋锁的保持者已经释放了锁，”自旋”一词就是因此而得名。</p>
<h3 id="Java如何实现自旋锁？"><a href="#Java如何实现自旋锁？" class="headerlink" title="Java如何实现自旋锁？"></a>Java如何实现自旋锁？</h3><p>下面是个简单的例子：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">SpinLock</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> AtomicReference&lt;Thread&gt; cas = <span class="keyword">new</span> AtomicReference&lt;Thread&gt;();</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">lock</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        Thread current = Thread.currentThread();</span><br><span class="line">        <span class="comment">// 利用CAS</span></span><br><span class="line">        <span class="keyword">while</span> (!cas.compareAndSet(<span class="keyword">null</span>, current)) &#123;</span><br><span class="line">            <span class="comment">// DO nothing</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">unlock</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        Thread current = Thread.currentThread();</span><br><span class="line">        cas.compareAndSet(current, <span class="keyword">null</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;<span class="number">1234567891011121314</span></span><br></pre></td></tr></table></figure>
<p>lock（)方法利用的CAS，当第一个线程A获取锁的时候，能够成功获取到，不会进入while循环，如果此时线程A没有释放锁，另一个线程B又来获取锁，此时由于不满足CAS，所以就会进入while循环，不断判断是否满足CAS，直到A线程调用unlock方法释放了该锁。</p>
<h3 id="自旋锁存在的问题"><a href="#自旋锁存在的问题" class="headerlink" title="自旋锁存在的问题"></a>自旋锁存在的问题</h3><ol>
<li>如果某个线程持有锁的时间过长，就会导致其它等待获取锁的线程进入循环等待，消耗CPU。使用不当会造成CPU使用率极高。</li>
<li>上面Java实现的自旋锁不是公平的，即无法满足等待时间最长的线程优先获取锁。不公平的锁就会存在“线程饥饿”问题。</li>
</ol>
<h3 id="自旋锁的优点"><a href="#自旋锁的优点" class="headerlink" title="自旋锁的优点"></a>自旋锁的优点</h3><ol>
<li>自旋锁不会使线程状态发生切换，一直处于用户态，即线程一直都是active的；不会使线程进入阻塞状态，减少了不必要的上下文切换，执行速度快</li>
<li>非自旋锁在获取不到锁的时候会进入阻塞状态，从而进入内核态，当获取到锁的时候需要从内核态恢复，需要线程上下文切换。 （线程被阻塞后便进入内核（Linux）调度状态，这个会导致系统在用户态与内核态之间来回切换，严重影响锁的性能）</li>
</ol>
<h3 id="TicketLock主要解决的是公平性的问题。"><a href="#TicketLock主要解决的是公平性的问题。" class="headerlink" title="TicketLock主要解决的是公平性的问题。"></a>TicketLock主要解决的是公平性的问题。</h3><p>思路：每当有线程获取锁的时候，就给该线程分配一个递增的id，我们称之为排队号，同时，锁对应一个服务号，每当有线程释放锁，服务号就会递增，此时如果服务号与某个线程排队号一致，那么该线程就获得锁，由于排队号是递增的，所以就保证了最先请求获取锁的线程可以最先获取到锁，就实现了公平性。</p>
<p>可以想象成银行办理业务排队，排队的每一个顾客都代表一个需要请求锁的线程，而银行服务窗口表示锁，每当有窗口服务完成就把自己的服务号加一，此时在排队的所有顾客中，只有自己的排队号与服务号一致的才可以得到服务。</p>
<h3 id="偏向锁"><a href="#偏向锁" class="headerlink" title="偏向锁"></a>偏向锁</h3><p>Java偏向锁(Biased Locking)是Java6引入的一项多线程优化。<br>偏向锁，顾名思义，它会偏向于第一个访问锁的线程，如果在运行过程中，同步锁只有一个线程访问，不存在多线程争用的情况，则线程是不需要触发同步的，这种情况下，就会给线程加一个偏向锁。<br><strong>如果在运行过程中，遇到了其他线程抢占锁，则持有偏向锁的线程会被挂起，JVM会消除它身上的偏向锁，将锁恢复到标准的轻量级锁。</strong></p>
<p>它通过消除资源无竞争情况下的同步原语，进一步提高了程序的运行性能。</p>
<h4 id="偏向锁的实现"><a href="#偏向锁的实现" class="headerlink" title="偏向锁的实现"></a>偏向锁的实现</h4><p>偏向锁获取过程：</p>
<ol>
<li>访问Mark Word中偏向锁的标识是否设置成1，锁标志位是否为01，确认为可偏向状态。</li>
<li>如果为可偏向状态，则测试线程ID是否指向当前线程，如果是，进入步骤5，否则进入步骤3。</li>
<li>如果线程ID并未指向当前线程，则通过CAS操作竞争锁。如果竞争成功，则将Mark Word中线程ID设置为当前线程ID，然后执行5；如果竞争失败，执行4。</li>
<li>如果CAS获取偏向锁失败，则表示有竞争。当到达全局安全点（safepoint）时获得偏向锁的线程被挂起，偏向锁升级为轻量级锁，然后被阻塞在安全点的线程继续往下执行同步代码。（撤销偏向锁的时候会导致stop the word）</li>
<li>执行同步代码。</li>
</ol>
<p>注意：第四步中到达安全点safepoint会导致stop the word，时间很短。</p>
<h4 id="偏向锁的释放："><a href="#偏向锁的释放：" class="headerlink" title="偏向锁的释放："></a>偏向锁的释放：</h4><p>偏向锁的撤销在上述第四步骤中有提到。偏向锁只有遇到其他线程尝试竞争偏向锁时，持有偏向锁的线程才会释放锁，<strong>线程不会主动去释放偏向锁。</strong>偏向锁的撤销，需要等待全局安全点（在这个时间点上没有字节码正在执行），它会首先暂停拥有偏向锁的线程，判断锁对象是否处于被锁定状态，撤销偏向锁后恢复到未锁定（标志位为“01”）或轻量级锁（标志位为“00”）的状态。</p>
<h4 id="偏向锁的适用场景"><a href="#偏向锁的适用场景" class="headerlink" title="偏向锁的适用场景"></a>偏向锁的适用场景</h4><p>始终只有一个线程在执行同步块，在它没有执行完释放锁之前，没有其它线程去执行同步块，在锁无竞争的情况下使用，一旦有了竞争就升级为轻量级锁，升级为轻量级锁的时候需要撤销偏向锁，撤销偏向锁的时候会导致stop the word操作；<br>在有锁的竞争时，偏向锁会多做很多额外操作，尤其是撤销偏向所的时候会导致进入安全点，安全点会导致stw，导致性能下降，这种情况下应当禁用； </p>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><h3 id="自旋锁"><a href="#自旋锁" class="headerlink" title="自旋锁"></a>自旋锁</h3><p>线程的阻塞和唤醒需要CPU从用户态转为核心态，频繁的阻塞和唤醒对CPU来说是一件负担很重的工作。同时我们可以发现，很多对象锁的锁定状态只会持续很短的一段时间，例如整数的自加操作，在很短的时间内阻塞并唤醒线程显然不值得，为此引入了自旋锁。</p>
<p>所谓“自旋”，就是让线程去执行一个无意义的循环，循环结束后再去重新竞争锁，如果竞争不到继续循环，循环过程中线程会一直处于running状态，但是基于JVM的线程调度，会出让时间片，所以其他线程依旧有申请锁和释放锁的机会。</p>
<p>自旋锁省去了阻塞锁的时间空间（队列的维护等）开销，但是长时间自旋就变成了“忙式等待”，忙式等待显然还不如阻塞锁。所以自旋的次数一般控制在一个范围内，例如10,100等，在超出这个范围后，自旋锁会升级为阻塞锁。（即从轻量级锁转变为重量级锁）</p>
<h3 id="轻量级锁"><a href="#轻量级锁" class="headerlink" title="轻量级锁"></a>轻量级锁</h3><p>加锁</p>
<p>线程在执行同步块之前，JVM会先在当前线程的栈桢中创建用于存储锁记录的空间，并将对象头中的Mark Word复制到锁记录中，官方称为Displaced Mark Word。<strong>然后线程尝试使用CAS将对象头中的Mark Word替换为指向锁记录的指针。如果成功，当前线程获得锁，如果失败，则自旋获取锁，当自旋获取锁仍然失败时，表示存在其他线程竞争锁(两条或两条以上的线程竞争同一个锁)，则轻量级锁会膨胀成重量级锁。</strong></p>
<p>解锁</p>
<p><strong>轻量级解锁时，会使用原子的CAS操作来将Displaced Mark Word替换回到对象头，如果成功，则表示同步过程已完成。</strong>如果失败，表示有其他线程尝试过获取该锁，则要在释放锁的同时唤醒被挂起的线程。</p>
<h3 id="重量级锁"><a href="#重量级锁" class="headerlink" title="重量级锁"></a>重量级锁</h3><p>重量锁在JVM中又叫对象监视器（Monitor），它很像C中的Mutex，除了具备Mutex(0|1)互斥的功能，它还负责实现了Semaphore(信号量)的功能，也就是说它至少包含一个竞争锁的队列，和一个信号阻塞队列（wait队列），前者负责做互斥，后一个用于做线程同步。</p>
<p><strong>如果说轻量级锁是在无竞争的情况下使用CAS操作去消除同步使用的互斥量，那偏向锁就是在无竞争的情况下把整个同步都消除掉，连CAS都不做了。</strong></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/10/01/解决缓存数据库双写不一致/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Chen ZeTao">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/weixin.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="ddd `Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/10/01/解决缓存数据库双写不一致/" itemprop="url">解决缓存数据库双写不一致</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-10-01T17:19:51+08:00">
                2019-10-01
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  4.8k
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  16
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>在讲双写不一致的时候，先将为什么会发生双写不一致。<br>数据发生了变更，先删除了缓存，然后要去修改数据库，此时还没修改</p>
<p>一个请求过来，去读缓存，发现缓存空了，去查询数据库，查到了修改前的旧数据，放到了缓存中</p>
<p>数据变更的程序完成了数据库的修改</p>
<p>完了，数据库和缓存中的数据不一样了。。。。</p>
<p><strong>hash路由的算法，跟HashMap中的hash算法是一样的。</strong>    </p>
<ul>
<li>直接调用hashcode函数，求得的hash值过大，不适合拿来直接做下标，所以要通过将hash做一次扰动再跟已有的队列-1再取模。</li>
</ul>
<p>通过线程池 +内存队列+通过同个商品的ID路由到同一个队列中，将写请求，和读请求做到一个串行化的效果。只有当写请求完成之后，工作线程才会进行读请求的进行。</p>
<p>更新请求：删除缓存，修改数据库</p>
<p>读请求：读缓存，发现空，进入队列中等待，排到了则读数据库，并将数据写入缓存，返回数据</p>
<p>问题1：当写请求不断积压，读请求等待的时间过长，超过最大等待时间，会直接读数据库，造成双写不一致。</p>
<p>所以在这时候需要添加机器，分散队列的写请求服务。</p>
<p>少量情况下，可能遇到读跟数据更新冲突的情况，如上所述，那么此时更新操作如果先入队列，之后可能会瞬间来了对这个数据大量的读请求，但是因为做了去重的优化，所以也就一个更新缓存的操作跟在它后面</p>
<p>等数据更新完了，读请求触发的缓存更新操作也完成，然后临时等待的读请求全部可以读到缓存中的数据</p>
<p>问题2：大量的读请求在服务上等待。</p>
<p>当有大量的读请求时，此时若缓存为空，那么会通过去重，只让一个读请求进入队列中等待操作。</p>
<p>但可能发生，队列中的读操作还没完成，大量的读请求在服务中等待，造成服务宕机。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">进入队列后，读请求会有一个等待的时间，等待同步更新操作完成，这样的话，一个数据变更的操作，先执行，删除缓存，然后再去更新数据库，但是还没完成更新</span><br><span class="line"></span><br><span class="line">此时如果一个读请求过来，读到了空的缓存，那么可以先将缓存更新的请求发送到队列中，此时会在队列中积压，然后同步等待缓存更新完成</span><br><span class="line">这里有一个优化点，一个队列中，其实多个更新缓存请求串在一起是没意义的，因此可以做过滤，如果发现队列中已经有一个更新缓存的请求了，那么就不用再放个更新请求操作进去了，直接等待前面的更新操作请求完成即可</span><br><span class="line"></span><br><span class="line">待那个队列对应的工作线程完成了上一个操作的数据库的修改之后，才会去执行下一个操作，也就是缓存更新的操作，此时会从数据库中读取最新的值，然后写入缓存中</span><br><span class="line"></span><br><span class="line">如果请求还在等待时间范围内，不断轮询发现可以取到值了，那么就直接返回; 如果请求等待的时间超过一定时长，那么这一次直接从数据库中读取当前的旧值</span><br></pre></td></tr></table></figure>
<h3 id="高并发下的缓存与-数据库双写不一致问题分析与设计"><a href="#高并发下的缓存与-数据库双写不一致问题分析与设计" class="headerlink" title="高并发下的缓存与+数据库双写不一致问题分析与设计"></a>高并发下的缓存与+数据库双写不一致问题分析与设计</h3><p>马上开始去开发业务系统</p>
<p>从哪一步开始做，从比较简单的那一块开始做，实时性要求比较高的那块数据的缓存去做</p>
<p>实时性比较高的数据缓存，选择的就是库存的服务</p>
<p>库存可能会修改，每次修改都要去更新这个缓存数据; 每次库存的数据，在缓存中一旦过期，或者是被清理掉了，前端的nginx服务都会发送请求给库存服务，去获取相应的数据</p>
<p>库存这一块，写数据库的时候，直接更新redis缓存</p>
<p>实际上没有这么的简单，这里，其实就涉及到了一个问题，<strong>数据库与缓存双写，数据不一致的问题</strong></p>
<p>围绕和结合实时性较高的库存服务，把数据库与缓存双写不一致问题以及其解决方案，给大家讲解一下</p>
<p>数据库与缓存双写不一致，很常见的问题，大型的缓存架构中，第一个解决方案</p>
<p>大型的缓存架构全部讲解完了以后，整套架构是非常复杂，架构可以应对各种各样奇葩和极端的情况</p>
<p>也有一种可能，不是说，来讲课的就是超人，万能的</p>
<p>讲课，就跟写书一样，很可能会写错，也可能有些方案里的一些地方，我没考虑到</p>
<p>也可能说，有些方案只是适合某些场景，在某些场景下，可能需要你进行方案的优化和调整才能适用于你自己的项目</p>
<p>大家觉得对这些方案有什么疑问或者见解，都可以找我，沟通一下</p>
<p>如果的确我觉得是我讲解的不对，或者有些地方考虑不周，那么我可以在视频里补录，更新到网站上面去</p>
<p>多多包涵</p>
<p>1、最初级的缓存不一致问题以及解决方案</p>
<p>问题：先修改数据库，再删除缓存，如果删除缓存失败了，那么会导致数据库中是新数据，缓存中是旧数据，数据出现不一致</p>
<p>解决思路</p>
<p>先删除缓存，再修改数据库，如果删除缓存成功了，如果修改数据库失败了，那么数据库中是旧数据，缓存中是空的，那么数据不会不一致</p>
<p>因为读的时候缓存没有，则读数据库中旧数据，然后更新到缓存中</p>
<p>2、比较复杂的数据不一致问题分析</p>
<p>数据发生了变更，先删除了缓存，然后要去修改数据库，此时还没修改</p>
<p>一个请求过来，去读缓存，发现缓存空了，去查询数据库，查到了修改前的旧数据，放到了缓存中</p>
<p>数据变更的程序完成了数据库的修改</p>
<p>完了，数据库和缓存中的数据不一样了。。。。</p>
<p>3、为什么上亿流量高并发场景下，缓存会出现这个问题？</p>
<p>只有在对一个数据在并发的进行读写的时候，才可能会出现这种问题</p>
<p>其实如果说你的并发量很低的话，特别是读并发很低，每天访问量就1万次，那么很少的情况下，会出现刚才描述的那种不一致的场景</p>
<p>但是问题是，如果每天的是上亿的流量，每秒并发读是几万，每秒只要有数据更新的请求，就可能会出现上述的数据库+缓存不一致的情况</p>
<p>高并发了以后，问题是很多的</p>
<p><strong>4、数据库与缓存更新与读取操作进行异步串行化</strong></p>
<p>更新数据的时候，根据数据的唯一标识，将操作路由之后，发送到一个jvm内部的队列中</p>
<p>读取数据的时候，如果发现数据不在缓存中，那么将重新读取数据+更新缓存的操作，根据唯一标识路由之后，也发送同一个jvm内部的队列中</p>
<p>一个队列对应一个工作线程</p>
<p>每个工作线程串行拿到对应的操作，然后一条一条的执行</p>
<p>这样的话，一个数据变更的操作，先执行，删除缓存，然后再去更新数据库，但是还没完成更新</p>
<p>此时如果一个读请求过来，读到了空的缓存，那么可以先将缓存更新的请求发送到队列中，此时会在队列中积压，然后同步等待缓存更新完成</p>
<p>这里有一个优化点，一个队列中，其实多个更新缓存请求串在一起是没意义的，因此可以做过滤，如果发现队列中已经有一个更新缓存的请求了，那么就不用再放个更新请求操作进去了，直接等待前面的更新操作请求完成即可</p>
<p>待那个队列对应的工作线程完成了上一个操作的数据库的修改之后，才会去执行下一个操作，也就是缓存更新的操作，此时会从数据库中读取最新的值，然后写入缓存中</p>
<p>如果请求还在等待时间范围内，不断轮询发现可以取到值了，那么就直接返回; 如果请求等待的时间超过一定时长，那么这一次直接从数据库中读取当前的旧值</p>
<p>5、高并发的场景下，该解决方案要注意的问题</p>
<p><strong>（1）读请求长时阻塞</strong></p>
<p>由于读请求进行了非常轻度的异步化，所以一定要注意读超时的问题，每个读请求必须在超时时间范围内返回</p>
<p>该解决方案，最大的风险点在于说，可能数据更新很频繁，导致队列中积压了大量更新操作在里面，然后读请求会发生大量的超时，最后导致大量的请求直接走数据库</p>
<p>务必通过一些模拟真实的测试，看看更新数据的频繁是怎样的</p>
<p>另外一点，因为一个队列中，可能会积压针对多个数据项的更新操作，因此需要根据自己的业务情况进行测试，可能需要部署多个服务，每个服务分摊一些数据的更新操作</p>
<p>如果一个内存队列里居然会挤压100个商品的库存修改操作，每隔库存修改操作要耗费10ms区完成，那么最后一个商品的读请求，可能等待10 * 100 = 1000ms = 1s后，才能得到数据</p>
<p>这个时候就导致读请求的长时阻塞</p>
<p>一定要做根据实际业务系统的运行情况，去进行一些压力测试，和模拟线上环境，去看看最繁忙的时候，内存队列可能会挤压多少更新操作，可能会导致最后一个更新操作对应的读请求，会hang多少时间，如果读请求在200ms返回，如果你计算过后，哪怕是最繁忙的时候，积压10个更新操作，最多等待200ms，那还可以的</p>
<p>如果一个内存队列可能积压的更新操作特别多，那么你就要加机器，让每个机器上部署的服务实例处理更少的数据，那么每个内存队列中积压的更新操作就会越少</p>
<p>其实根据之前的项目经验，一般来说数据的写频率是很低的，因此实际上正常来说，在队列中积压的更新操作应该是很少的</p>
<p>针对读高并发，读缓存架构的项目，一般写请求相对读来说，是非常非常少的，每秒的QPS能到几百就不错了</p>
<p>一秒，500的写操作，5份，每200ms，就100个写操作</p>
<p>单机器，20个内存队列，每个内存队列，可能就积压5个写操作，每个写操作性能测试后，一般在20ms左右就完成</p>
<p>那么针对每个内存队列中的数据的读请求，也就最多hang一会儿，200ms以内肯定能返回了</p>
<p>写QPS扩大10倍，但是经过刚才的测算，就知道，单机支撑写QPS几百没问题，那么就扩容机器，扩容10倍的机器，10台机器，每个机器20个队列，200个队列</p>
<p>大部分的情况下，应该是这样的，大量的读请求过来，都是直接走缓存取到数据的</p>
<p>少量情况下，可能遇到读跟数据更新冲突的情况，如上所述，那么此时更新操作如果先入队列，之后可能会瞬间来了对这个数据大量的读请求，但是因为做了去重的优化，所以也就一个更新缓存的操作跟在它后面</p>
<p>等数据更新完了，读请求触发的缓存更新操作也完成，然后临时等待的读请求全部可以读到缓存中的数据</p>
<p>（2）读请求并发量过高</p>
<p>这里还必须做好压力测试，确保恰巧碰上上述情况的时候，还有一个风险，就是突然间大量读请求会在几十毫秒的延时hang在服务上，看服务能不能抗的住，需要多少机器才能抗住最大的极限情况的峰值</p>
<p>但是因为并不是所有的数据都在同一时间更新，缓存也不会同一时间失效，所以每次可能也就是少数数据的缓存失效了，然后那些数据对应的读请求过来，并发量应该也不会特别大</p>
<p>按1:99的比例计算读和写的请求，每秒5万的读QPS，可能只有500次更新操作</p>
<p>如果一秒有500的写QPS，那么要测算好，可能写操作影响的数据有500条，这500条数据在缓存中失效后，可能导致多少读请求，发送读请求到库存服务来，要求更新缓存</p>
<p>一般来说，1:1，1:2，1:3，每秒钟有1000个读请求，会hang在库存服务上，每个读请求最多hang多少时间，200ms就会返回</p>
<p>在同一时间最多hang住的可能也就是单机200个读请求，同时hang住</p>
<p>单机hang200个读请求，还是ok的</p>
<p>1:20，每秒更新500条数据，这500秒数据对应的读请求，会有20 * 500 = 1万</p>
<p>1万个读请求全部hang在库存服务上，就死定了</p>
<p>（3）多服务实例部署的请求路由</p>
<p>可能这个服务部署了多个实例，那么必须保证说，执行数据更新操作，以及执行缓存更新操作的请求，都通过nginx服务器路由到相同的服务实例上</p>
<p>（4）热点商品的路由问题，导致请求的倾斜</p>
<p>万一某个商品的读写请求特别高，全部打到相同的机器的相同的队列里面去了，可能造成某台机器的压力过大</p>
<p>就是说，因为只有在商品数据更新的时候才会清空缓存，然后才会导致读写并发，所以更新频率不是太高的话，这个问题的影响并不是特别大</p>
<p>但是的确可能某些机器的负载会高一些</p>
<h3 id="在库存服务中实现缓存与数据库双写一致性保障方案"><a href="#在库存服务中实现缓存与数据库双写一致性保障方案" class="headerlink" title="在库存服务中实现缓存与数据库双写一致性保障方案"></a>在库存服务中实现缓存与数据库双写一致性保障方案</h3><p>更新数据的时候，根据数据的唯一标识，将操作路由之后，发送到一个jvm内部的队列中</p>
<p>读取数据的时候，如果发现数据 不在缓存中，那么将重新读取数据+更新缓存的操作，根据唯一标识路由之后，也发送同一个jvm内部的队列中</p>
<p>一个队列对应一个工作线程</p>
<p>每个工作线程串行拿到对应的操作，然后一条一条的执行</p>
<p>这样的话，一个数据变更的操作，先执行，删除缓存，然后再去更新数据库，但是还没完成更新</p>
<p>此时如果一个读请求过来，读到了空的缓存，那么可以先将缓存更新的请求发送到队列中，此时会在队列中积压，然后同步等待缓存更新完成</p>
<p>这里有一个优化点，一个队列中，其实多个更新缓存请求串在一起是没意义的，因此可以做过滤，如果发现队列中已经有一个更新缓存的请求了，那么就不用再放个更新请求操作进去了，直接等待前面的更新操作请求完成即可</p>
<p>待那个队列对应的工作线程完成了上一个操作的数据库的修改之后，才会去执行下一个操作，也就是缓存更新的操作，此时会从数据库中读取最新的值，然后写入缓存中</p>
<p>如果请求还在等待时间范围内，不断轮询发现可以取到值了，那么就直接返回; 如果请求等待的时间超过一定时长，那么这一次直接从数据库中读取当前的旧值</p>
<p>int h;<br>return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16);</p>
<p>(queueNum - 1) &amp; hash</p>
<p>1、线程池+内存队列 化</p>
<p>@Bean<br>public ServletListenerRegistrationBean servletListenerRegistrationBean(){<br>    ServletListenerRegistrationBean servletListenerRegistrationBean = new ServletListenerRegistrationBean();<br>    servletListenerRegistrationBean.setListener(new InitListener());<br>    return servletListenerRegistrationBean;<br>}</p>
<p>java web应用，做系统的初始化，一般在哪里做呢？</p>
<p>ServletContextListener里面做，listener，会跟着整个web应用的启动，就初始化，类似于线程池初始化的构建</p>
<p><strong>使用单例初始化线程池，基于静态内部类（静态代码块）初始化线程池的方式，</strong></p>
<p>spring boot应用，Application，搞一个listener的注册</p>
<p>2、两种请求对象封装</p>
<p>3、请求异步执行Service封装</p>
<p>4、两种请求Controller接口封装</p>
<p>5、读请求去重优化</p>
<p>6、空数据读请求过滤优化</p>
<p>队列</p>
<p>对一个商品的库存的数据库更新操作已经在内存队列中了</p>
<p>然后对这个商品的库存的读取操作，要求读取数据库的库存数据，然后更新到缓存中，多个读</p>
<p>这多个读，其实只要有一个读请求操作压到队列里就可以了</p>
<p>其他的读操作，全部都wait那个读请求的操作，刷新缓存，就可以读到缓存中的最新数据了</p>
<p>如果读请求发现redis缓存中没有数据，就会发送读请求给库存服务，但是此时缓存中为空，可能是因为写请求先删除了缓存，也可能是数据库里压根儿没这条数据</p>
<p>如果是数据库中压根儿没这条数据的场景，那么就不应该将读请求操作给压入队列中，而是直接返回空就可以了</p>
<p>都是为了减少内存队列中的请求积压，内存队列中积压的请求越多，就可能导致每个读请求hang住的时间越长，也可能导致多个读请求被hang住</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/">1</a><span class="page-number current">2</span><a class="page-number" href="/page/3/">3</a><span class="space">&hellip;</span><a class="page-number" href="/page/5/">5</a><a class="extend next" rel="next" href="/page/3/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image" src="/images/weixin.jpg" alt="Chen ZeTao">
            
              <p class="site-author-name" itemprop="name">Chen ZeTao</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">50</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">15</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">29</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          

          

          
          

          
          

          

        </div>
      </section>

      

      
        <div class="back-to-top">
          <i class="fa fa-arrow-up"></i>
          
            <span id="scrollpercent"><span>0</span>%</span>
          
        </div>
      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
<div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Chen ZeTao</span>

  
</div>


  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Muse</a> v5.1.4</div>



<div class="powered-by">
<i class="fa fa-user-md"></i><span id="busuanzi_container_site_uv">
  本站访客数:<span id="busuanzi_value_site_uv"></span>
</span>
</div>
<div class="theme-info">
  <div class="powered-by"></div>
  <span class="post-count">博客全站共98.2k字</span>
</div>

        
<div class="busuanzi-count">
  <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  
    <span class="site-uv">
      
      <span class="busuanzi-value" id="busuanzi_value_site_uv"></span>
      
    </span>
  

  
    <span class="site-pv">
      <i class="fa fa-eye"></i> 总访问量
      <span class="busuanzi-value" id="busuanzi_value_site_pv"></span>
      
    </span>
  
</div>








        
      </div>
    </footer>

    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  

  

  
  

  

  

  

  
<script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"debug":false,"model":{"jsonPath":"/live2dw/assets/tororo.model.json"},"display":{"position":"right","width":150,"height":300},"mobile":{"show":true},"react":{"opacity":0.7},"log":false});</script></body>
</html>
