<!DOCTYPE html>



  


<html class="theme-next muse use-motion" lang="zh-Hans">
<head><meta name="generator" content="Hexo 3.9.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/favicon.ico?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon.ico?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon.ico?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hexo, NexT">










<meta property="og:type" content="website">
<meta property="og:title" content="ddd `Blog">
<meta property="og:url" content="http://yoursite.com/page/3/index.html">
<meta property="og:site_name" content="ddd `Blog">
<meta property="og:locale" content="zh-Hans">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="ddd `Blog">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":true,"scrollpercent":true,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/page/3/">





  <title>ddd `Blog</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">ddd `Blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">czt的博客</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br>
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br>
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            归档
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br>
            
            搜索
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off" placeholder="搜索..." spellcheck="false" type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/10/02/zookeeper-kafka/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Chen ZeTao">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/weixin.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="ddd `Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/10/02/zookeeper-kafka/" itemprop="url">zookeeper+kafka+nginx</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-10-02T19:37:21+08:00">
                2019-10-02
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  1.9k
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  7
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h3 id="zookeeper-与-kafka集群的搭建"><a href="#zookeeper-与-kafka集群的搭建" class="headerlink" title="zookeeper 与 kafka集群的搭建"></a>zookeeper 与 kafka集群的搭建</h3><p>多级缓存的架构</p>
<p>主要是用来解决什么样的数据的缓存的更新的啊？？？</p>
<p>时效性不高的数据，比如一些商品的基本信息，如果发生了变更，假设在5分钟之后再更新到页面中，供用户观察到，也是ok的</p>
<p>时效性要求不高的数据，那么我们采取的是异步更新缓存的策略</p>
<p>时效性要求很高的数据，库存，采取的是数据库+缓存双写的技术方案，也解决了双写的一致性的问题</p>
<p>缓存数据生产服务，监听一个消息队列，然后数据源服务（商品信息管理服务）发生了数据变更之后，就将数据变更的消息推送到消息队列中</p>
<p>缓存数据生产服务可以去消费到这个数据变更的消息，然后根据消息的指示提取一些参数，然后调用对应的数据源服务的接口，拉去数据，这个时候一般是从mysql库中拉去的</p>
<p>消息队列是什么东西？采取打的就是kafka</p>
<p>我工作的时候，很多项目是跟大数据相关的，当然也有很多是纯java系统的架构，最近用kafka用得比较多</p>
<p>kafka比较简单易用，讲课来说，很方便</p>
<p>解释一下，我们当然是不可能对课程中涉及的各种技术都深入浅出的讲解的了，kafka，花上20个小时给你讲解一下，不可能的</p>
<p>所以说呢，在这里，一些技术的组合，用什么都ok</p>
<p>笑傲江湖中的风清扬，手中无剑胜有剑，还有任何东西都可以当做兵器，哪怕是一根草也可以</p>
<p>搞技术，kafka和activemq肯定有区别，但是说，在有些场景下，其实可能没有那么大的区分度，kafka和activemq其实是一样的</p>
<p>生产者+消费者的场景，kafka+activemq都ok</p>
<p>涉及的这种架构，对时效性要求高和时效性要求低的数据，分别采取什么技术方案？数据库+缓存双写一致性？异步+多级缓存架构？大缓存的维度化拆分？</p>
<p>你要关注的，是一些架构上的东西和思想，而不是具体的什么mq的使用</p>
<p>activemq的课程，书籍，资料</p>
<p>kafka集群，zookeeper集群，先搭建zookeeper集群，再搭建kafka集群</p>
<p>kafka另外一个原因：kafka，本来就要搭建zookeeper，zookeeper这个东西，后面我们还要用呢，缓存的分布式并发更新的问题，分布式锁解决</p>
<p>zookeeper + kafka的集群，都是三节点</p>
<p>java高级工程师的思想，在干活儿，在思考，jvm，宏观的思考，通盘去考虑整个架构，还有未来的技术规划，业务的发展方向，架构的演进方向和路线</p>
<p>把课程里讲解的各种技术方案组合成、修改成你需要的适合你的业务的缓存架构</p>
<p>1、zookeeper集群搭建</p>
<p>将课程提供的zookeeper-3.4.5.tar.gz使用WinSCP拷贝到/usr/local目录下。<br>对zookeeper-3.4.5.tar.gz进行解压缩：tar -zxvf zookeeper-3.4.5.tar.gz。<br>对zookeeper目录进行重命名：mv zookeeper-3.4.5 zk</p>
<p>配置zookeeper相关的环境变量<br>vi ~/.bashrc<br>export ZOOKEEPER_HOME=/usr/local/zk<br>export PATH=$PATH:$ZOOKEEPER_HOME/bin</p>
<p>source ~/.bashrc</p>
<p>cd zk/conf<br>cp zoo_sample.cfg zoo.cfg</p>
<p>vi zoo.cfg<br>修改：dataDir=/usr/local/zk/data<br>新增：<br>server.0=eshop-cache01:2888:3888<br>server.1=eshop-cache02:2888:3888<br>server.2=eshop-cache03:2888:3888</p>
<p>cd zk<br>mkdir data<br>cd data</p>
<p>vi myid<br>0</p>
<p>在另外两个节点上按照上述步骤配置ZooKeeper，使用scp将zk和.bashrc拷贝到eshop-cache02和eshop-cache03上即可。唯一的区别是标识号分别设置为1和2。</p>
<p>分别在三台机器上执行：zkServer.sh start。<br>检查ZooKeeper状态：zkServer.sh status，应该是一个leader，两个follower<br>jps：检查三个节点是否都有QuromPeerMain进程</p>
<p>2、kafka集群搭建</p>
<p>scala，我就不想多说了，就是一门编程语言，现在比较火，很多比如大数据领域里面的spark（计算引擎）就是用scala编写的</p>
<p>将课程提供的scala-2.11.4.tgz使用WinSCP拷贝到/usr/local目录下。<br>对scala-2.11.4.tgz进行解压缩：tar -zxvf scala-2.11.4.tgz。<br>对scala目录进行重命名：mv scala-2.11.4 scala</p>
<p>配置scala相关的环境变量<br>vi ~/.bashrc<br>export SCALA_HOME=/usr/local/scala<br>export PATH=$SCALA_HOME/bin<br>source ~/.bashrc</p>
<p>查看scala是否安装成功：scala -version</p>
<p>按照上述步骤在其他机器上都安装好scala。使用scp将scala和.bashrc拷贝到另外两台机器上即可。</p>
<p>将课程提供的kafka_2.9.2-0.8.1.tgz使用WinSCP拷贝到/usr/local目录下。<br>对kafka_2.9.2-0.8.1.tgz进行解压缩：tar -zxvf kafka_2.9.2-0.8.1.tgz。<br>对kafka目录进行改名：mv kafka_2.9.2-0.8.1 kafka</p>
<p>配置kafka<br>vi /usr/local/kafka/config/server.properties<br>broker.id：依次增长的整数，0、1、2，集群中Broker的唯一id<br>zookeeper.connect=192.168.31.187:2181,192.168.31.19:2181,192.168.31.227:2181</p>
<p>安装slf4j<br>将课程提供的slf4j-1.7.6.zip上传到/usr/local目录下<br>unzip slf4j-1.7.6.zip<br>把slf4j中的slf4j-nop-1.7.6.jar复制到kafka的libs目录下面</p>
<p>解决kafka Unrecognized VM option ‘UseCompressedOops’问题</p>
<p>vi /usr/local/kafka/bin/kafka-run-class.sh </p>
<p>if [ -z “$KAFKA_JVM_PERFORMANCE_OPTS” ]; then<br>  KAFKA_JVM_PERFORMANCE_OPTS=”-server  -XX:+UseCompressedOops -XX:+UseParNewGC -XX:+UseConcMarkSweepGC -XX:+CMSClassUnloadingEnabled -XX:+CMSScavengeBeforeRemark -XX:+DisableExplicitGC -Djava.awt.headless=true”<br>fi</p>
<p>去掉-XX:+UseCompressedOops即可</p>
<p>按照上述步骤在另外两台机器分别安装kafka。用scp把kafka拷贝到其他机器即可。<br>唯一区别的，就是server.properties中的broker.id，要设置为1和2</p>
<p>在三台机器上的kafka目录下，分别执行以下命令：nohup bin/kafka-server-start.sh config/server.properties &amp;</p>
<p>使用jps检查启动是否成功</p>
<p>使用基本命令检查kafka是否搭建成功</p>
<p>bin/kafka-topics.sh –zookeeper 192.168.229.7:2181,192.168.229.8:2181,192.168.229.9:2181 –topic test –replication-factor 1 –partitions 1 –create</p>
<p>bin/kafka-console-producer.sh –broker-list 192.168.229.7:9092,192.168.229.8:9092,192.168.229.9:9092 –topic test</p>
<p>bin/kafka-console-consumer.sh –bootstrap-server 192.168.229.7:9092,192.168.229.8:9092,192.168.229.9:9092 –topic test –from-beginning</p>
<h3 id="基于“分发层-应用层”双层nginx架构提升缓存命中率"><a href="#基于“分发层-应用层”双层nginx架构提升缓存命中率" class="headerlink" title="基于“分发层+应用层”双层nginx架构提升缓存命中率"></a>基于“分发层+应用层”双层nginx架构提升缓存命中率</h3><p>1、缓存命中率低</p>
<p>缓存数据生产服务那一层已经搞定了，相当于三层缓存架构中的本地堆缓存+redis分布式缓存都搞定了</p>
<p>就要来做三级缓存中的nginx那一层的缓存了</p>
<p>如果一般来说，你默认会部署多个nginx，在里面都会放一些缓存，就默认情况下，此时缓存命中率是比较低的</p>
<p>2、如何提升缓存命中率</p>
<p>分发层+应用层，双层nginx</p>
<p>分发层nginx，负责流量分发的逻辑和策略，这个里面它可以根据你自己定义的一些规则，比如根据productId去进行hash，然后对后端的nginx数量取模</p>
<p>将某一个商品的访问的请求，就固定路由到一个nginx后端服务器上去，保证说只会从redis中获取一次缓存数据，后面全都是走nginx本地缓存了</p>
<p>后端的nginx服务器，就称之为应用服务器; 最前端的nginx服务器，被称之为分发服务器</p>
<p>看似很简单，其实很有用，在实际的生产环境中，可以大幅度提升你的nginx本地缓存这一层的命中率，大幅度减少redis后端的压力，提升性能</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/10/02/模拟第一天/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Chen ZeTao">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/weixin.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="ddd `Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/10/02/模拟第一天/" itemprop="url">模拟第一天</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-10-02T11:06:55+08:00">
                2019-10-02
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  1.5k
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  5
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="java创建对象有几种方式"><a href="#java创建对象有几种方式" class="headerlink" title="java创建对象有几种方式"></a>java创建对象有几种方式</h2><ol>
<li>使用new关键字：这是我们最常见的也是最简单的创建对象的方式，通过这种方式我们还可以调用任意的够赞函数（无参的和有参的）。比如：Student student = new Student();</li>
<li>使用Class类的newInstance方法：我们也可以使用Class类的newInstance方法创建对象，这个newInstance方法调用无参的构造器创建对象，如：Student student2 = (Student)Class.forName(“根路径.Student”).newInstance();　或者：Student stu = Student.class.newInstance();</li>
<li>使用Constructor类的newInstance方法：本方法和Class类的newInstance方法很像，java.lang.relect.Constructor类里也有一个newInstance方法可以创建对象。我们可以通过这个newInstance方法调用有参数的和私有的构造函数。如： Constructor<student> constructor = Student.class.getInstance(); Student stu = constructor.newInstance();　这两种newInstance的方法就是大家所说的反射，事实上Class的newInstance方法内部调用Constructor的newInstance方法。这也是众多框架Spring、Hibernate、Struts等使用后者的原因。</student></li>
<li>使用Clone的方法：无论何时我们调用一个对象的clone方法，JVM就会创建一个新的对象，将前面的对象的内容全部拷贝进去，用clone方法创建对象并不会调用任何构造函数。要使用clone方法，我们必须先实现Cloneable接口并实现其定义的clone方法。如：Student stu2 = <student>stu.clone();这也是原型模式的应用。</student></li>
<li>使用反序列化：当我们序列化和反序列化一个对象，JVM会给我们创建一个单独的对象，在反序列化时，JVM创建对象并不会调用任何构造函数。为了反序列化一个对象，我们需要让我们的类实现Serializable接口。如：ObjectInputStream in = new ObjectInputStream (new FileInputStream(“data.obj”)); Student stu3 = (Student)in.readObject();</li>
</ol>
<h2 id="浅拷贝与深拷贝的区别？怎么实现深拷贝"><a href="#浅拷贝与深拷贝的区别？怎么实现深拷贝" class="headerlink" title="浅拷贝与深拷贝的区别？怎么实现深拷贝"></a>浅拷贝与深拷贝的区别？怎么实现深拷贝</h2><p>浅拷贝：创建一个新对象，然后将当前对象的非静态字段复制到该新对象，如果字段是值类型的，那么对该字段执行复制；如果该字段是引用类型的话，则复制引用但不复制引用的对象。因此，原始对象及其副本引用同一个对象。</p>
<p>深拷贝：创建一个新对象，然后将当前对象的非静态字段复制到该新对象，无论该字段是值类型的还是引用类型，都复制独立的一份。当你修改其中一个对象的任何内容时，都不会影响另一个对象的内容。</p>
<p>使用clone方法的对象需要是实现cloneable接口</p>
<p> ①、让每个引用类型属性内部都重写clone() 方法<br>②、利用序列化<br><a href="https://blog.csdn.net/baiye_xing/article/details/71788741" target="_blank" rel="noopener">https://blog.csdn.net/baiye_xing/article/details/71788741</a></p>
<h2 id="SQL注入原理，mybatis怎么实现sql注入"><a href="#SQL注入原理，mybatis怎么实现sql注入" class="headerlink" title="SQL注入原理，mybatis怎么实现sql注入"></a>SQL注入原理，mybatis怎么实现sql注入</h2><p><a href="https://czetao.github.io/2019/10/01/SQL注入/" target="_blank" rel="noopener">https://czetao.github.io/2019/10/01/SQL%E6%B3%A8%E5%85%A5/</a></p>
<h2 id="threadlocal使用需要注意什么问题？"><a href="#threadlocal使用需要注意什么问题？" class="headerlink" title="threadlocal使用需要注意什么问题？"></a>threadlocal使用需要注意什么问题？</h2><p>threadlocal–&gt;threadlocalmap —&gt;Entry&lt;threadlocal,value&gt;</p>
<p><a href="https://blog.csdn.net/LHQJ1992/article/details/52451136" target="_blank" rel="noopener">https://blog.csdn.net/LHQJ1992/article/details/52451136</a><br><a href="https://blog.csdn.net/qq_33404395/article/details/82356344" target="_blank" rel="noopener">https://blog.csdn.net/qq_33404395/article/details/82356344</a></p>
<p><img src="https://img-blog.csdn.net/20180903125233171?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzMzNDA0Mzk1/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt></p>
<p>ThreadLocal的实现是这样的：每个Thread 维护一个 ThreadLocalMap 映射表，这个映射表的 key 是 ThreadLocal实例本身，value 是真正需要存储的 Object。<br>也就是说 ThreadLocal 本身并不存储值，它只是作为一个 key 来让线程从 ThreadLocalMap 获取 value。<br>值得注意的是图中的虚线，表示 ThreadLocalMap 是使用 ThreadLocal 的弱引用作为 Key 的，弱引用的对象在 GC 时会被回收。</p>
<p>ThreadLocalMap使用ThreadLocal的弱引用作为key，如果一个ThreadLocal没有外部强引用来引用它，那么系统 GC 的时候，这个ThreadLocal势必会被回收，这样一来，ThreadLocalMap中就会出现key为null的Entry，就没有办法访问这些key为null的Entry的value，如果当前线程再迟迟不结束的话，这些key为null的Entry的value就会一直存在一条强引用链：Thread Ref -&gt; Thread -&gt; ThreaLocalMap -&gt; Entry -&gt; value永远无法回收，造成内存泄漏。<br>————————————————<br>版权声明：本文为CSDN博主「WangCw的夏天」的原创文章，遵循 CC 4.0 BY-SA 版权协议，转载请附上原文出处链接及本声明。<br>原文链接：<a href="https://blog.csdn.net/qq_33404395/article/details/82356344" target="_blank" rel="noopener">https://blog.csdn.net/qq_33404395/article/details/82356344</a></p>
<h3 id="为何HashMap的数组长度一定是2的次幂？"><a href="#为何HashMap的数组长度一定是2的次幂？" class="headerlink" title="为何HashMap的数组长度一定是2的次幂？"></a>为何HashMap的数组长度一定是2的次幂？</h3><p>hashMap的数组长度一定保持2的次幂，比如16的二进制表示为 10000，那么length-1就是15，二进制为01111，同理扩容后的数组长度为32，二进制表示为100000，length-1为31，二进制表示为011111。从下图可以我们也能看到这样会保证低位全为1，而扩容后只有一位差异，也就是多出了最左位的1，这样在通过 h&amp;(length-1)的时候，只要h对应的最左边的那一个差异位为0，就能保证得到的新的数组索引和老数组索引一致(大大减少了之前已经散列良好的老数组的数据位置重新调换)，个人理解。</p>
<p> 还有，数组长度保持2的次幂，length-1的低位都为1，会使得获得的数组索引index更加均匀，比如：</p>
<p>　　我们看到，上面的&amp;运算，高位是不会对结果产生影响的（hash函数采用各种位运算可能也是为了使得低位更加散列），我们只关注低位bit，如果低位全部为1，那么对于h低位部分来说，任何一位的变化都会对结果产生影响，也就是说，要得到index=21这个存储位置，h的低位只有这一种组合。这也是数组长度设计为必须为2的次幂的原因。</p>
<p><strong>当length-1时，低位都是111，可以保证key低位的唯一性</strong></p>
<p>　　如果不是2的次幂，也就是低位不是全为1此时，要使得index=21，h的低位部分不再具有唯一性了，哈希冲突的几率会变的更大，同时，index对应的这个bit位无论如何不会等于1了，而对应的那些数组位置也就被白白浪费了。</p>
<p><a href="https://www.cnblogs.com/chengxiao/p/6059914.html#t3" target="_blank" rel="noopener">https://www.cnblogs.com/chengxiao/p/6059914.html#t3</a></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/10/01/redis详解、/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Chen ZeTao">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/weixin.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="ddd `Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/10/01/redis详解、/" itemprop="url">redis详解、</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-10-01T17:52:57+08:00">
                2019-10-01
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  14.5k
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  53
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h3 id="要掌握的很好的，就是redis架构"><a href="#要掌握的很好的，就是redis架构" class="headerlink" title="要掌握的很好的，就是redis架构"></a>要掌握的很好的，就是redis架构</h3><ul>
<li>安装一个虚拟机集群</li>
<li>安装redis集群</li>
<li>配置持久化<ul>
<li>RDB 快照手动设置检查点（etc/redis/redis.conf 里面可以修改save）</li>
</ul>
</li>
</ul>
<p>高并发，高可用，海量数据，备份，随时可以恢复，</p>
<p>redis架构，每秒钟几十万的访问量QPS，99.99%的高可用性，TB级的海量数据，备份和恢复，缓存架构就成功了一半。最最简单的模式，无非就是存取redis，存数据，取数据。解决各种各样的高并发下缓存面临的难题，缓存架构中不断引入各种解决方案和技术，解决高并发的问题。</p>
<ol>
<li>搭建redis集群，从0开始，一步一步搭建一个4个结点的Centos集群。安装4台虚拟机<ul>
<li>在hosts文件下,配置好所有的机器的ip地址到hostname的映射关系</li>
<li>使用ssh配置每台机器之间免密登录</li>
</ul>
</li>
<li>make install </li>
<li>要把redis作为一个系统的daemon进程去运行，每次系统启动，redis进程一起启动</li>
</ol>
<p>如果没有持久化的话，redis遇到灾难性故障的时候，就会丢失所有的数据</p>
<p>如果通过持久化将数据搞一份儿在磁盘上去，然后定期比如说同步和备份到一些云存储服务上去，那么就可以保证数据不丢失全部，还是可以恢复一部分数据回来的。redis如果单单把数据放在内存中，是没有任何方法应对一些灾难性的工作的，redis 在启动会自动从磁盘中恢复数据到内存中。</p>
<h3 id="redis-持久化RDB-AOF利弊比较"><a href="#redis-持久化RDB-AOF利弊比较" class="headerlink" title="redis 持久化RDB,AOF利弊比较"></a>redis 持久化RDB,AOF利弊比较</h3><p>比如你redis整个挂了，然后redis就不可用了，你要做的事情是让redis变得可用，尽快变得可用</p>
<p>重启redis，尽快让它对外提供服务，但是就像上一讲说，如果你没做数据备份，这个时候redis启动了，也不可用啊，数据都没了</p>
<p>很可能说，大量的请求过来，缓存全部无法命中，在redis里根本找不到数据，这个时候就死定了，缓存雪崩问题，所有请求，没有在redis命中，就会去mysql数据库这种数据源头中去找，一下子mysql承接高并发，然后就挂了</p>
<p>mysql挂掉，你都没法去找数据恢复到redis里面去，redis的数据从哪儿来？从mysql来。。。</p>
<p>具体的完整的缓存雪崩的场景，还有企业级的解决方案，到后面讲</p>
<p>如果你把redis的持久化做好，备份和恢复方案做到企业级的程度，那么即使你的redis故障了，也可以通过备份数据，快速恢复，一旦恢复立即对外提供服务</p>
<p>redis的持久化，跟高可用，是有关系的，企业级redis架构中去讲解</p>
<p>redis持久化：RDB，AOF</p>
<hr>
<p>1、RDB和AOF两种持久化机制的介绍</p>
<p>RDB持久化机制，对redis中的数据执行周期性的持久化</p>
<p>AOF机制对每条写入命令作为日志，以append-only的模式写入一个日志文件中，在redis重启的时候，可以通过回放AOF日志中的写入指令来重新构建整个数据集</p>
<p>如果我们想要redis仅仅作为纯内存的缓存来用，那么可以禁止RDB和AOF所有的持久化机制</p>
<p>通过RDB或AOF，都可以将redis内存中的数据给持久化到磁盘上面来，然后可以将这些数据备份到别的地方去，比如说阿里云，云服务</p>
<p>如果redis挂了，服务器上的内存和磁盘上的数据都丢了，可以从云服务上拷贝回来之前的数据，放到指定的目录中，然后重新启动redis，redis就会自动根据持久化数据文件中的数据，去恢复内存中的数据，继续对外提供服务</p>
<p>如果同时使用RDB和AOF两种持久化机制，那么在redis重启的时候，会使用AOF来重新构建数据，因为AOF中的数据更加完整</p>
<hr>
<p>2、RDB持久化机制的优点</p>
<p>（1）RDB会生成多个数据文件，每个数据文件都代表了某一个时刻中redis的数据，这种多个数据文件的方式，非常适合做冷备，可以将这种完整的数据文件发送到一些远程的安全存储上去，比如说Amazon的S3云服务上去，在国内可以是阿里云的ODPS分布式存储上，以预定好的备份策略来定期备份redis中的数据</p>
<p>（2）RDB对redis对外提供的读写服务，影响非常小，可以让redis保持高性能，因为redis主进程只需要fork一个子进程，让子进程执行磁盘IO操作来进行RDB持久化即可</p>
<p>（3）相对于AOF持久化机制来说，直接基于RDB数据文件来重启和恢复redis进程，更加快速</p>
<hr>
<p>3、RDB持久化机制的缺点</p>
<p>（1）如果想要在redis故障时，尽可能少的丢失数据，那么RDB没有AOF好。一般来说，RDB数据快照文件，都是每隔5分钟，或者更长时间生成一次，这个时候就得接受一旦redis进程宕机，那么会丢失最近5分钟的数据</p>
<p>（2）RDB每次在fork子进程来执行RDB快照数据文件生成的时候，如果数据文件特别大，可能会导致对客户端提供的服务暂停数毫秒，或者甚至数秒</p>
<hr>
<p>4、AOF持久化机制的优点</p>
<p>（1）AOF可以更好的保护数据不丢失，一般AOF会每隔1秒，通过一个后台线程执行一次fsync操作，最多丢失1秒钟的数据</p>
<p>（2）AOF日志文件以append-only模式写入，所以没有任何磁盘寻址的开销，写入性能非常高，而且文件不容易破损，即使文件尾部破损，也很容易修复</p>
<p>（3）AOF日志文件即使过大的时候，出现后台重写操作，也不会影响客户端的读写。因为在rewrite log的时候，会对其中的指导进行压缩，创建出一份需要恢复数据的最小日志出来。再创建新日志文件的时候，老的日志文件还是照常写入。当新的merge后的日志文件ready的时候，再交换新老日志文件即可。</p>
<p>（4）AOF日志文件的命令通过非常可读的方式进行记录，这个特性非常适合做灾难性的误删除的紧急恢复。比如某人不小心用flushall命令清空了所有数据，只要这个时候后台rewrite还没有发生，那么就可以立即拷贝AOF文件，将最后一条flushall命令给删了，然后再将该AOF文件放回去，就可以通过恢复机制，自动恢复所有数据</p>
<hr>
<p>5、AOF持久化机制的缺点</p>
<p>（1）对于同一份数据来说，AOF日志文件通常比RDB数据快照文件更大</p>
<p>（2）AOF开启后，支持的写QPS会比RDB支持的写QPS低，因为AOF一般会配置成每秒fsync一次日志文件，当然，每秒一次fsync，性能也还是很高的</p>
<p>（3）以前AOF发生过bug，就是通过AOF记录的日志，进行数据恢复的时候，没有恢复一模一样的数据出来。所以说，类似AOF这种较为复杂的基于命令日志/merge/回放的方式，比基于RDB每次持久化一份完整的数据快照文件的方式，更加脆弱一些，容易有bug。不过AOF就是为了避免rewrite过程导致的bug，因此每次rewrite并不是基于旧的指令日志进行merge的，而是基于当时内存中的数据进行指令的重新构建，这样健壮性会好很多。</p>
<hr>
<p>6、RDB和AOF到底该如何选择</p>
<p>（1）不要仅仅使用RDB，因为那样会导致你丢失很多数据</p>
<p>（2）也不要仅仅使用AOF，因为那样有两个问题，第一，你通过AOF做冷备，没有RDB做冷备，来的恢复速度更快; 第二，RDB每次简单粗暴生成数据快照，更加健壮，可以避免AOF这种复杂的备份和恢复机制的bug</p>
<p>（3）综合使用AOF和RDB两种持久化机制，用AOF来保证数据不丢失，作为数据恢复的第一选择; 用RDB来做不同程度的冷备，在AOF文件都丢失或损坏不可用的时候，还可以使用RDB来进行快速的数据恢复</p>
<h3 id="RDB持久化详解"><a href="#RDB持久化详解" class="headerlink" title="RDB持久化详解"></a>RDB持久化详解</h3><p>1、如何配置RDB持久化机制<br>2、RDB持久化机制的工作流程<br>3、基于RDB持久化机制的数据恢复实验</p>
<hr>
<p>1、如何配置RDB持久化机制</p>
<p>redis.conf文件，也就是/etc/redis/6379.conf，去配置持久化</p>
<p>save 60 1000</p>
<p>每隔60s，如果有超过1000个key发生了变更，那么就生成一个新的dump.rdb文件，就是当前redis内存中完整的数据快照，这个操作也被称之为snapshotting，快照</p>
<p>也可以手动调用save或者bgsave命令，同步或异步执行rdb快照生成</p>
<p>save可以设置多个，就是多个snapshotting检查点，每到一个检查点，就会去check一下，是否有指定的key数量发生了变更，如果有，就生成一个新的dump.rdb文件</p>
<hr>
<p>2、RDB持久化机制的工作流程</p>
<p>（1）redis根据配置自己尝试去生成rdb快照文件<br>（2）fork一个子进程出来<br>（3）子进程尝试将数据dump到临时的rdb快照文件中<br>（4）完成rdb快照文件的生成之后，就替换之前的旧的快照文件</p>
<p>dump.rdb，每次生成一个新的快照，都会覆盖之前的老快照</p>
<hr>
<p>3、基于RDB持久化机制的数据恢复实验</p>
<p>（1）在redis中保存几条数据，立即停掉redis进程，然后重启redis，看看刚才插入的数据还在不在</p>
<p>数据还在，为什么？</p>
<p>带出来一个知识点，通过redis-cli SHUTDOWN这种方式去停掉redis，其实是一种安全退出的模式，redis在退出的时候会将内存中的数据立即生成一份完整的rdb快照</p>
<p>/var/redis/6379/dump.rdb</p>
<p>（2）在redis中再保存几条新的数据，用kill -9粗暴杀死redis进程，模拟redis故障异常退出，导致内存数据丢失的场景</p>
<p>这次就发现，redis进程异常被杀掉，数据没有进dump文件，几条最新的数据就丢失了</p>
<p>（2）手动设置一个save检查点，save 5 1<br>（3）写入几条数据，等待5秒钟，会发现自动进行了一次dump rdb快照，在dump.rdb中发现了数据<br>（4）异常停掉redis进程，再重新启动redis，看刚才插入的数据还在</p>
<p>rdb的手动配置检查点，以及rdb快照的生成，包括数据的丢失和恢复，全都演示过了</p>
<h3 id="AOF持久化详解"><a href="#AOF持久化详解" class="headerlink" title="AOF持久化详解"></a>AOF持久化详解</h3><p>1、AOF持久化的配置<br>2、AOF持久化的数据恢复实验<br>3、AOF rewrite<br>4、AOF破损文件的修复<br>5、AOF和RDB同时工作</p>
<hr>
<p>1、AOF持久化的配置</p>
<p>AOF持久化，默认是关闭的，默认是打开RDB持久化</p>
<p>appendonly yes，可以打开AOF持久化机制，在生产环境里面，一般来说AOF都是要打开的，除非你说随便丢个几分钟的数据也无所谓。<br>如果开启AOF，就算没有AOF文件，redis在重启时，也会创建一个新的空的AOF文件恢复数据，在这个时候就需要先关闭AOF，拷贝dump.rdb恢复redis先，接着应该直接在命令行热修改redis配置，打开AOF。此时磁盘上的配置文件还是no（关闭）的，还需要在磁盘上将AOF打开。</p>
<p>AOF append-only ，顺序写入，如果AOF文件破损，那么用redis-check-aof fix修复文件<br>打开AOF持久化机制之后，redis每次接收到一条写命令，就会写入日志文件中，当然是先写入os cache的，然后每隔一定时间再fsync一下</p>
<p>而且即使AOF和RDB都开启了，redis重启的时候，也是优先通过AOF进行数据恢复的，因为aof数据比较完整</p>
<p>可以配置AOF的fsync策略，有三种策略可以选择，一种是每次写入一条数据就执行一次fsync; 一种是每隔一秒执行一次fsync; 一种是不主动执行fsync</p>
<p>always: 每次写入一条数据，立即将这个数据对应的写日志fsync到磁盘上去，性能非常非常差，吞吐量很低; 确保说redis里的数据一条都不丢，那就只能这样了</p>
<p>mysql -&gt; 内存策略，大量磁盘，QPS到多少，一两k。QPS，每秒钟的请求数量<br>redis -&gt; 内存，磁盘持久化，QPS到多少，单机，一般来说，上万QPS没问题</p>
<p>everysec: 每秒将os cache中的数据fsync到磁盘，这个最常用的，生产环境一般都这么配置，性能很高，QPS还是可以上万的</p>
<p>no: 仅仅redis负责将数据写入os cache就撒手不管了，然后后面os自己会时不时有自己的策略将数据刷入磁盘，不可控了</p>
<hr>
<p>2、AOF持久化的数据恢复实验</p>
<p>（1）先仅仅打开RDB，写入一些数据，然后kill -9杀掉redis进程，接着重启redis，发现数据没了，因为RDB快照还没生成<br>（2）打开AOF的开关，启用AOF持久化<br>（3）写入一些数据，观察AOF文件中的日志内容</p>
<p>其实你在appendonly.aof文件中，可以看到刚写的日志，它们其实就是先写入os cache的，然后1秒后才fsync到磁盘中，只有fsync到磁盘中了，才是安全的，要不然光是在os cache中，机器只要重启，就什么都没了</p>
<p>（4）kill -9杀掉redis进程，重新启动redis进程，发现数据被恢复回来了，就是从AOF文件中恢复回来的</p>
<p>redis进程启动的时候，直接就会从appendonly.aof中加载所有的日志，把内存中的数据恢复回来</p>
<hr>
<p>3、AOF rewrite</p>
<p>redis中的数据其实有限的，很多数据可能会自动过期，可能会被用户删除，可能会被redis用缓存清除的算法清理掉</p>
<p>redis中的数据会不断淘汰掉旧的，就一部分常用的数据会被自动保留在redis内存中</p>
<p>所以可能很多之前的已经被清理掉的数据，对应的写日志还停留在AOF中，AOF日志文件就一个，会不断的膨胀，到很大很大</p>
<p>所以AOF会自动在后台每隔一定时间做rewrite操作，比如日志里已经存放了针对100w数据的写日志了; redis内存只剩下10万; 基于内存中当前的10万数据构建一套最新的日志，到AOF中; 覆盖之前的老日志; 确保AOF日志文件不会过大，保持跟redis内存数据量一致</p>
<p>redis 2.4之前，还需要手动，开发一些脚本，crontab，通过BGREWRITEAOF命令去执行AOF rewrite，但是redis 2.4之后，会自动进行rewrite操作</p>
<p>在redis.conf中，可以配置rewrite策略</p>
<p>auto-aof-rewrite-percentage 100<br>auto-aof-rewrite-min-size 64mb</p>
<p>比如说上一次AOF rewrite之后，是128mb</p>
<p>然后就会接着128mb继续写AOF的日志，如果发现增长的比例，超过了之前的100%，256mb，就可能会去触发一次rewrite</p>
<p>但是此时还要去跟min-size，64mb去比较，256mb &gt; 64mb，才会去触发rewrite</p>
<p>（1）redis fork一个子进程<br>（2）子进程基于当前内存中的数据，构建日志，开始往一个新的临时的AOF文件中写入日志<br>（3）redis主进程，接收到client新的写操作之后，在内存中写入日志，同时新的日志也继续写入旧的AOF文件<br>（4）子进程写完新的日志文件之后，redis主进程将内存中的新日志再次追加到新的AOF文件中<br>（5）用新的日志文件替换掉旧的日志文件</p>
<hr>
<p>4、AOF破损文件的修复</p>
<p>如果redis在append数据到AOF文件时，机器宕机了，可能会导致AOF文件破损</p>
<p>用redis-check-aof –fix命令来修复破损的AOF文件</p>
<hr>
<p>5、AOF和RDB同时工作</p>
<p>（1）如果RDB在执行snapshotting操作，那么redis不会执行AOF rewrite; 如果redis再执行AOF rewrite，那么就不会执行RDB snapshotting<br>（2）如果RDB在执行snapshotting，此时用户执行BGREWRITEAOF命令，那么等RDB快照生成之后，才会去执行AOF rewrite<br>（3）同时有RDB snapshot文件和AOF日志文件，那么redis重启的时候，会优先使用AOF进行数据恢复，因为其中的日志更完整</p>
<hr>
<p>6、最后一个小实验，让大家对redis的数据恢复有更加深刻的体会</p>
<p>（1）在有rdb的dump和aof的appendonly的同时，rdb里也有部分数据，aof里也有部分数据，这个时候其实会发现，rdb的数据不会恢复到内存中<br>（2）我们模拟让aof破损，然后fix，有一条数据会被fix删除<br>（3）再次用fix得aof文件去重启redis，发现数据只剩下一条了</p>
<p>数据恢复完全是依赖于底层的磁盘的持久化的，主要rdb和aof上都没有数据，那就没了</p>
<h1 id="9-29"><a href="#9-29" class="headerlink" title="9.29"></a>9.29</h1><h3 id="redis在企业级数据备份方案以及数据恢复负灾演练"><a href="#redis在企业级数据备份方案以及数据恢复负灾演练" class="headerlink" title="redis在企业级数据备份方案以及数据恢复负灾演练"></a>redis在企业级数据备份方案以及数据恢复负灾演练</h3><p>到这里为止，其实还是停留在简单学习知识的程度，学会了redis的持久化的原理和操作，但是在企业中，持久化到底是怎么去用得呢？</p>
<p>企业级的数据备份和各种灾难下的数据恢复，是怎么做得呢？</p>
<p>1、企业级的持久化的配置策略</p>
<p>在企业中，RDB的生成策略，用默认的也差不多</p>
<p>save 60 10000：如果你希望尽可能确保说，RDB最多丢1分钟的数据，那么尽量就是每隔1分钟都生成一个快照，低峰期，数据量很少，也没必要</p>
<p>10000-&gt;生成RDB，1000-&gt;RDB，这个根据你自己的应用和业务的数据量，你自己去决定</p>
<p>AOF一定要打开，fsync，everysec</p>
<p>auto-aof-rewrite-percentage 100: 就是当前AOF大小膨胀到超过上次100%，上次的两倍<br>auto-aof-rewrite-min-size 64mb: 根据你的数据量来定，16mb，32mb</p>
<p>2、企业级的数据备份方案</p>
<p>RDB非常适合做冷备，每次生成之后，就不会再有修改了</p>
<p>数据备份方案</p>
<p>（1）写crontab定时调度脚本去做数据备份<br>（2）每小时都copy一份rdb的备份，到一个目录中去，仅仅保留最近48小时的备份<br>（3）每天都保留一份当日的rdb的备份，到一个目录中去，仅仅保留最近1个月的备份<br>（4）每次copy备份的时候，都把太旧的备份给删了<br>（5）每天晚上将当前服务器上所有的数据备份，发送一份到远程的云服务上去</p>
<p>/usr/local/redis</p>
<p>每小时copy一次备份，删除48小时前的数据</p>
<p>crontab -e</p>
<p>0 <em> </em> <em> </em> sh /usr/local/redis/copy/redis_rdb_copy_hourly.sh</p>
<p>redis_rdb_copy_hourly.sh</p>
<p>#!/bin/sh </p>
<p>cur_date=<code>date +%Y%m%d%k</code><br>rm -rf /usr/local/redis/snapshotting/$cur_date<br>mkdir /usr/local/redis/snapshotting/$cur_date<br>cp /var/redis/6379/dump.rdb /usr/local/redis/snapshotting/$cur_date</p>
<p>del_date=<code>date -d -48hour +%Y%m%d%k</code><br>rm -rf /usr/local/redis/snapshotting/$del_date</p>
<p>每天copy一次备份</p>
<p>crontab -e</p>
<p>0 0 <em> </em> * sh /usr/local/redis/copy/redis_rdb_copy_daily.sh</p>
<p>redis_rdb_copy_daily.sh</p>
<p>#!/bin/sh </p>
<p>cur_date=<code>date +%Y%m%d</code><br>rm -rf /usr/local/redis/snapshotting/$cur_date<br>mkdir /usr/local/redis/snapshotting/$cur_date<br>cp /var/redis/6379/dump.rdb /usr/local/redis/snapshotting/$cur_date</p>
<p>del_date=<code>date -d -1month +%Y%m%d</code><br>rm -rf /usr/local/redis/snapshotting/$del_date</p>
<p>每天一次将所有数据上传一次到远程的云服务器上去</p>
<p>3、数据恢复方案</p>
<p>（1）如果是redis进程挂掉，那么重启redis进程即可，直接基于AOF日志文件恢复数据</p>
<p>不演示了，在AOF数据恢复那一块，演示了，fsync everysec，最多就丢一秒的数</p>
<p>（2）如果是redis进程所在机器挂掉，那么重启机器后，尝试重启redis进程，尝试直接基于AOF日志文件进行数据恢复</p>
<p>AOF没有破损，也是可以直接基于AOF恢复的</p>
<p>AOF append-only，顺序写入，如果AOF文件破损，那么用redis-check-aof fix</p>
<p>（3）如果redis当前最新的AOF和RDB文件出现了丢失/损坏，那么可以尝试基于该机器上当前的某个最新的RDB数据副本进行数据恢复</p>
<p>当前最新的AOF和RDB文件都出现了丢失/损坏到无法恢复，一般不是机器的故障，人为</p>
<p>大数据系统，hadoop，有人不小心就把hadoop中存储的大量的数据文件对应的目录，rm -rf一下，我朋友的一个小公司，运维不太靠谱，权限也弄的不太好</p>
<p>/var/redis/6379下的文件给删除了</p>
<p>找到RDB最新的一份备份，小时级的备份可以了，小时级的肯定是最新的，copy到redis里面去，就可以恢复到某一个小时的数据</p>
<p>容灾演练</p>
<p>我跟大家解释一下，我其实上课，为什么大量的讲师可能讲课就是纯PPT，或者是各种复制粘贴，都不是现场讲解和写代码演示的</p>
<p>很容易出错，为了避免出错，一般就会那样玩儿</p>
<p>吐槽，念PPT，效果很差</p>
<p>真实的，备课，讲课不可避免，会出现一些问题，但是我觉得还好，真实</p>
<p>appendonly.aof + dump.rdb，优先用appendonly.aof去恢复数据，但是我们发现redis自动生成的appendonly.aof是没有数据的</p>
<p>然后我们自己的dump.rdb是有数据的，但是明显没用我们的数据</p>
<p>redis启动的时候，自动重新基于内存的数据，生成了一份最新的rdb快照，直接用空的数据，覆盖掉了我们有数据的，拷贝过去的那份dump.rdb</p>
<p>你停止redis之后，其实应该先删除appendonly.aof，然后将我们的dump.rdb拷贝过去，然后再重启redis</p>
<p>很简单，就是虽然你删除了appendonly.aof，但是因为打开了aof持久化，redis就一定会优先基于aof去恢复，即使文件不在，那就创建一个新的空的aof文件</p>
<p>停止redis，暂时在配置中关闭aof，然后拷贝一份rdb过来，再重启redis，数据能不能恢复过来，可以恢复过来</p>
<p>脑子一热，再关掉redis，手动修改配置文件，打开aof，再重启redis，数据又没了，空的aof文件，所有数据又没了</p>
<p>在数据安全丢失的情况下，基于rdb冷备，如何完美的恢复数据，同时还保持aof和rdb的双开</p>
<p>停止redis，关闭aof，拷贝rdb备份，重启redis，确认数据恢复，直接在命令行热修改redis配置，打开aof，这个redis就会将内存中的数据对应的日志，写入aof文件中</p>
<p>此时aof和rdb两份数据文件的数据就同步了</p>
<p>redis config set热修改配置参数，可能配置文件中的实际的参数没有被持久化的修改，再次停止redis，手动修改配置文件，打开aof的命令，再次重启redis</p>
<p>（4）如果当前机器上的所有RDB文件全部损坏，那么从远程的云服务上拉取最新的RDB快照回来恢复数据</p>
<p>（5）如果是发现有重大的数据错误，比如某个小时上线的程序一下子将数据全部污染了，数据全错了，那么可以选择某个更早的时间点，对数据进行恢复</p>
<p>举个例子，12点上线了代码，发现代码有bug，导致代码生成的所有的缓存数据，写入redis，全部错了</p>
<p>找到一份11点的rdb的冷备，然后按照上面的步骤，去恢复到11点的数据，不就可以了吗</p>
<h3 id="redis通过主从架构实现读写分离，完成10万-QPS"><a href="#redis通过主从架构实现读写分离，完成10万-QPS" class="headerlink" title="redis通过主从架构实现读写分离，完成10万+QPS"></a>redis通过主从架构实现读写分离，完成10万+QPS</h3><p>1、redis高并发跟整个系统的高并发之间的关系</p>
<p>redis，你要搞高并发的话，不可避免，要把底层的缓存搞得很好</p>
<p>mysql，高并发，做到了，那么也是通过一系列复杂的分库分表，订单系统，事务要求的，QPS到几万，比较高了</p>
<p>要做一些电商的商品详情页，真正的超高并发，QPS上十万，甚至是百万，一秒钟百万的请求量</p>
<p>光是redis是不够的，但是redis是整个大型的缓存架构中，支撑高并发的架构里面，非常重要的一个环节</p>
<p>首先，你的底层的缓存中间件，缓存系统，必须能够支撑的起我们说的那种高并发，其次，再经过良好的整体的缓存架构的设计（多级缓存架构、热点缓存），支撑真正的上十万，甚至上百万的高并发</p>
<p>2、redis不能支撑高并发的瓶颈在哪里？</p>
<p>单机</p>
<p>3、如果redis要支撑超过10万+的并发，那应该怎么做？</p>
<p>单机的redis几乎不太可能说QPS超过10万+，除非一些特殊情况，比如你的机器性能特别好，配置特别高，物理机，维护做的特别好，而且你的整体的操作不是太复杂</p>
<p>单机在几万</p>
<p>读写分离，一般来说，对缓存，一般都是用来支撑读高并发的，写的请求是比较少的，可能写请求也就一秒钟几千，一两千</p>
<p>大量的请求都是读，一秒钟二十万次读</p>
<p>读写分离</p>
<p>主从架构 -&gt; 读写分离 -&gt; 支撑10万+读QPS的架构</p>
<p>4、接下来要讲解的一个topic</p>
<p>redis replication</p>
<p>redis主从架构 -&gt; 读写分离架构 -&gt; 可支持水平扩展的读高并发架构</p>
<h3 id="redis-replication（主从架构）基本原理"><a href="#redis-replication（主从架构）基本原理" class="headerlink" title="redis replication（主从架构）基本原理"></a>redis replication（主从架构）基本原理</h3><p>课程大纲</p>
<p>1、图解redis replication基本原理<br>2、redis replication的核心机制<br>3、master持久化对于主从架构的安全保障的意义</p>
<p>redis replication -&gt; 主从架构 -&gt; 读写分离 -&gt; 水平扩容支撑读高并发</p>
<p>redis replication的最最基本的原理，铺垫</p>
<hr>
<p>1、图解redis replication基本原理</p>
<hr>
<p>2、redis replication的核心机制</p>
<p>（1）redis采用异步方式复制数据到slave节点，不过redis 2.8开始，slave node会周期性地确认自己每次复制的数据量<br>（2）一个master node是可以配置多个slave node的<br>（3）slave node也可以连接其他的slave node<br>（4）slave node做复制的时候，是不会block master node的正常工作的<br>（5）slave node在做复制的时候，也不会block对自己的查询操作，它会用旧的数据集来提供服务; 但是复制完成的时候，需要删除旧数据集，加载新数据集，这个时候就会暂停对外服务了<br>（6）slave node主要用来进行横向扩容，做读写分离，扩容的slave node可以提高读的吞吐量</p>
<p>slave，高可用性，有很大的关系</p>
<hr>
<p>3、master持久化对于主从架构的安全保障的意义</p>
<p>如果采用了主从架构，那么建议必须开启master node的持久化！</p>
<p>不建议用slave node作为master node的数据热备，因为那样的话，如果你关掉master的持久化，可能在master宕机重启的时候数据是空的，然后可能一经过复制，salve node数据也丢了</p>
<p>master -&gt; RDB和AOF都关闭了 -&gt; 全部在内存中</p>
<p>master宕机，重启，是没有本地数据可以恢复的，然后就会直接认为自己IDE数据是空的</p>
<p>master就会将空的数据集同步到slave上去，所有slave的数据全部清空</p>
<p>100%的数据丢失</p>
<p>master节点，必须要使用持久化机制</p>
<p>第二个，master的各种备份方案，要不要做，万一说本地的所有文件丢失了; 从备份中挑选一份rdb去恢复master; 这样才能确保master启动的时候，是有数据的</p>
<p>即使采用了后续讲解的高可用机制，slave node可以自动接管master node，但是也可能sentinal还没有检测到master failure，master node就自动重启了，还是可能导致上面的所有slave node数据清空故障</p>
<h1 id="9-30"><a href="#9-30" class="headerlink" title="9.30"></a>9.30</h1><h3 id="redis主从复制原理细讲"><a href="#redis主从复制原理细讲" class="headerlink" title="redis主从复制原理细讲"></a>redis主从复制原理细讲</h3><p>1、复制的完整流程</p>
<p>（1）slave node启动，仅仅保存master node的信息，包括master node的host和ip，但是复制流程没开始</p>
<p>master host和ip是从哪儿来的，redis.conf里面的slaveof配置的</p>
<p>（2）slave node内部有个定时任务，每秒检查是否有新的master node要连接和复制，如果发现，就跟master node建立socket网络连接<br>（3）slave node发送ping命令给master node<br>（4）口令认证，如果master设置了requirepass，那么salve node必须发送masterauth的口令过去进行认证<br>（5）master node第一次执行全量复制，将所有数据发给slave node<br>（6）master node后续持续将写命令，异步复制给slave node</p>
<p>2、数据同步相关的核心机制</p>
<p>指的就是第一次slave连接msater的时候，执行的全量复制，那个过程里面你的一些细节的机制</p>
<p>（1）master和slave都会维护一个offset</p>
<p>master会在自身不断累加offset，slave也会在自身不断累加offset<br>slave每秒都会上报自己的offset给master，同时master也会保存每个slave的offset</p>
<p>这个倒不是说特定就用在全量复制的，主要是master和slave都要知道各自的数据的offset，才能知道互相之间的数据不一致的情况</p>
<p>（2）backlog</p>
<p>master node有一个backlog，默认是1MB大小<br>master node给slave node复制数据时，也会将数据在backlog中同步写一份<br>backlog主要是用来做全量复制中断候的增量复制的</p>
<p>（3）master run id</p>
<p>info server，可以看到master run id<br>如果根据host+ip定位master node，是不靠谱的，如果master node重启或者数据出现了变化，那么slave node应该根据不同的run id区分，run id不同就做全量复制<br>如果需要不更改run id重启redis，可以使用redis-cli debug reload命令</p>
<p>（4）psync</p>
<p>从节点使用psync从master node进行复制，psync runid offset<br>master node会根据自身的情况返回响应信息，可能是FULLRESYNC runid offset触发全量复制，可能是CONTINUE触发增量复制</p>
<p>3、全量复制</p>
<p>（1）master执行bgsave，在本地生成一份rdb快照文件<br>（2）master node将rdb快照文件发送给salve node，如果rdb复制时间超过60秒（repl-timeout），那么slave node就会认为复制失败，可以适当调节大这个参数<br>（3）对于千兆网卡的机器，一般每秒传输100MB，6G文件，很可能超过60s<br>（4）master node在生成rdb时，会将所有新的写命令缓存在内存中，在salve node保存了rdb之后，再将新的写命令复制给salve node<br>（5）client-output-buffer-limit slave 256MB 64MB 60，如果在复制期间，内存缓冲区持续消耗超过64MB，或者一次性超过256MB，那么停止复制，复制失败<br>（6）slave node接收到rdb之后，清空自己的旧数据，然后重新加载rdb到自己的内存中，同时基于旧的数据版本对外提供服务<br>（7）如果slave node开启了AOF，那么会立即执行BGREWRITEAOF，重写AOF</p>
<p>rdb生成、rdb通过网络拷贝、slave旧数据的清理、slave aof rewrite，很耗费时间</p>
<p>如果复制的数据量在4G~6G之间，那么很可能全量复制时间消耗到1分半到2分钟</p>
<p>4、增量复制</p>
<p>（1）如果全量复制过程中，master-slave网络连接断掉，那么salve重新连接master时，会触发增量复制<br>（2）master直接从自己的backlog中获取部分丢失的数据，发送给slave node，默认backlog就是1MB<br>（3）msater就是根据slave发送的psync中的offset来从backlog中获取数据的</p>
<p>5、heartbeat</p>
<p>主从节点互相都会发送heartbeat信息</p>
<p>master默认每隔10秒发送一次heartbeat，salve node每隔1秒发送一个heartbeat</p>
<p>6、异步复制</p>
<p>master每次接收到写命令之后，现在内部写入数据，然后异步发送给slave node</p>
<h3 id="搭建redis主从节点"><a href="#搭建redis主从节点" class="headerlink" title="搭建redis主从节点"></a>搭建redis主从节点</h3><p>之前几讲都是在铺垫各种redis replication的原理，和知识，主从，读写分离，画图</p>
<p>知道了这些东西，关键是怎么搭建呢？？？</p>
<p>一主一从，往主节点去写，在从节点去读，可以读到，主从架构就搭建成功了</p>
<p>1、启用复制，部署slave node</p>
<p>wget <a href="http://downloads.sourceforge.net/tcl/tcl8.6.1-src.tar.gz" target="_blank" rel="noopener">http://downloads.sourceforge.net/tcl/tcl8.6.1-src.tar.gz</a><br>tar -xzvf tcl8.6.1-src.tar.gz<br>cd  /usr/local/tcl8.6.1/unix/<br>./configure<br>make &amp;&amp; make install</p>
<p>使用redis-3.2.8.tar.gz（截止2017年4月的最新稳定版）<br>tar -zxvf redis-3.2.8.tar.gz<br>cd redis-3.2.8<br>make &amp;&amp; make test &amp;&amp; make install</p>
<p>（1）redis utils目录下，有个redis_init_script脚本<br>（2）将redis_init_script脚本拷贝到linux的/etc/init.d目录中，将redis_init_script重命名为redis_6379，6379是我们希望这个redis实例监听的端口号<br>（3）修改redis_6379脚本的第6行的REDISPORT，设置为相同的端口号（默认就是6379）<br>（4）创建两个目录：/etc/redis（存放redis的配置文件），/var/redis/6379（存放redis的持久化文件）<br>（5）修改redis配置文件（默认在根目录下，redis.conf），拷贝到/etc/redis目录中，修改名称为6379.conf</p>
<p>（6）修改redis.conf中的部分配置为生产环境</p>
<p>daemonize    yes                            让redis以daemon进程运行<br>pidfile        /var/run/redis_6379.pid     设置redis的pid文件位置<br>port        6379                        设置redis的监听端口号<br>dir         /var/redis/6379                设置持久化文件的存储位置   (设置持久化文件的位置)</p>
<p>（7）让redis跟随系统启动自动启动</p>
<p>在redis_6379脚本中，最上面，加入两行注释</p>
<h1 id="chkconfig-2345-90-10"><a href="#chkconfig-2345-90-10" class="headerlink" title="chkconfig:   2345 90 10"></a>chkconfig:   2345 90 10</h1><h1 id="description-Redis-is-a-persistent-key-value-database"><a href="#description-Redis-is-a-persistent-key-value-database" class="headerlink" title="description:  Redis is a persistent key-value database"></a>description:  Redis is a persistent key-value database</h1><p>chkconfig redis_6379 on（随着系统启动+）</p>
<p>在slave node上配置（redis.conf文件中只要修改slaveof相关配置）：</p>
<p>slaveof 192.168.1.1（主节点） 6379（redis端口号），即可也可以使用slaveof命令</p>
<p>则配置成自己是从节点<br>2、强制读写分离</p>
<p>基于主从复制架构，实现读写分离</p>
<p>redis slave node只读，默认开启，slave-read-only</p>
<p>开启了只读的redis slave node，会拒绝所有的写操作，这样可以强制搭建成读写分离的架构</p>
<p>3、集群安全认证</p>
<p>master上启用安全认证，requirepass<br>master连接口令，masterauth</p>
<p>4、读写分离架构的测试</p>
<p>先启动主节点，eshop-cache01上的redis实例<br>再启动从节点，eshop-cache02上的redis实例</p>
<p>刚才我调试了一下，redis slave node一直说没法连接到主节点的6379的端口</p>
<p>在搭建生产环境的集群的时候，不要忘记修改一个配置，bind</p>
<p>bind 127.0.0.1 -&gt; 本地的开发调试的模式，就只能127.0.0.1本地才能访问到6379的端口</p>
<p>每个redis.conf中的bind 127.0.0.1 -&gt; bind自己的ip地址<br>在每个节点上都: iptables -A INPUT -ptcp –dport  6379 -j ACCEPT</p>
<p>redis-cli -h ipaddr<br>info replication</p>
<p>在主上写，在从上读<br>ps -ef | grep redis<br>查看redis进程是否已经启动</p>
<h3 id="哨兵架构基础知识讲解"><a href="#哨兵架构基础知识讲解" class="headerlink" title="哨兵架构基础知识讲解"></a>哨兵架构基础知识讲解</h3><p>1、哨兵的介绍</p>
<p>sentinal，中文名是哨兵</p>
<p>哨兵是redis集群架构中非常重要的一个组件，主要功能如下</p>
<p>（1）集群监控，负责监控redis master和slave进程是否正常工作<br>（2）消息通知，如果某个redis实例有故障，那么哨兵负责发送消息作为报警通知给管理员<br>（3）故障转移，如果master node挂掉了，会自动转移到slave node上<br>（4）配置中心，如果故障转移发生了，通知client客户端新的master地址</p>
<p>哨兵本身也是分布式的，作为一个哨兵集群去运行，互相协同工作</p>
<p>（1）故障转移时，判断一个master node是宕机了，需要大部分的哨兵都同意才行，涉及到了分布式选举的问题<br>（2）即使部分哨兵节点挂掉了，哨兵集群还是能正常工作的，因为如果一个作为高可用机制重要组成部分的故障转移系统本身是单点的，那就很坑爹了</p>
<p>目前采用的是sentinal 2版本，sentinal 2相对于sentinal 1来说，重写了很多代码，主要是让故障转移的机制和算法变得更加健壮和简单</p>
<p>2、哨兵的核心知识</p>
<p>（1）哨兵至少需要3个实例，来保证自己的健壮性<br>（2）哨兵 + redis主从的部署架构，是不会保证数据零丢失的，只能保证redis集群的高可用性<br>（3）对于哨兵 + redis主从这种复杂的部署架构，尽量在测试环境和生产环境，都进行充足的测试和演练</p>
<p>3、为什么redis哨兵集群只有2个节点无法正常工作？</p>
<p>哨兵集群必须部署2个以上节点</p>
<p>如果哨兵集群仅仅部署了个2个哨兵实例，quorum=1</p>
<p>+—-+         +—-+<br>| M1 |———| R1 |<br>| S1 |         | S2 |<br>+—-+         +—-+</p>
<p>Configuration: quorum = 1</p>
<p>master宕机，s1和s2中只要有1个哨兵认为master宕机就可以还行切换，同时s1和s2中会选举出一个哨兵来执行故障转移</p>
<p>同时这个时候，需要majority，也就是大多数哨兵都是运行的，2个哨兵的majority就是2（2的majority=2，3的majority=2，5的majority=3，4的majority=2），2个哨兵都运行着，就可以允许执行故障转移</p>
<p>但是如果整个M1和S1运行的机器宕机了，那么哨兵只有1个了，此时就没有majority来允许执行故障转移，虽然另外一台机器还有一个R1，但是故障转移不会执行</p>
<p>4、经典的3节点哨兵集群</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">+----+</span><br><span class="line">| M1 |</span><br><span class="line">| S1 |</span><br><span class="line">+----+</span><br><span class="line">   |</span><br></pre></td></tr></table></figure>
<p>+—-+    |    +—-+<br>| R2 |—-+—-| R3 |<br>| S2 |         | S3 |<br>+—-+         +—-+</p>
<p>Configuration: quorum = 2，majority = 2</p>
<p>如果M1所在机器宕机了，那么三个哨兵还剩下2个，S2和S3可以一致认为master宕机，然后选举出一个来执行故障转移</p>
<p>同时3个哨兵的majority是2，所以还剩下的2个哨兵运行着，就可以允许执行故障转移</p>
<h3 id="redis哨兵主备切换的数据丢失问题：异步复制，集群脑裂"><a href="#redis哨兵主备切换的数据丢失问题：异步复制，集群脑裂" class="headerlink" title="redis哨兵主备切换的数据丢失问题：异步复制，集群脑裂"></a>redis哨兵主备切换的数据丢失问题：异步复制，集群脑裂</h3><p>课程大纲</p>
<p>1、两种数据丢失的情况<br>2、解决异步复制和脑裂导致的数据丢失</p>
<hr>
<p>1、两种数据丢失的情况</p>
<p>主备切换的过程，可能会导致数据丢失</p>
<p>（1）异步复制导致的数据丢失</p>
<p>因为master -&gt; slave的复制是异步的，所以可能有部分数据还没复制到slave，master就宕机了，此时这些部分数据就丢失了</p>
<p>（2）脑裂导致的数据丢失</p>
<p>脑裂，也就是说，某个master所在机器突然脱离了正常的网络，跟其他slave机器不能连接，但是实际上master还运行着</p>
<p>此时哨兵可能就会认为master宕机了，然后开启选举，将其他slave切换成了master</p>
<p>这个时候，集群里就会有两个master，也就是所谓的脑裂</p>
<p>此时虽然某个slave被切换成了master，但是可能client还没来得及切换到新的master，还继续写向旧master的数据可能也丢失了</p>
<p>因此旧master再次恢复的时候，会被作为一个slave挂到新的master上去，自己的数据会清空，重新从新的master复制数据</p>
<hr>
<p>2、解决异步复制和脑裂导致的数据丢失</p>
<p>min-slaves-to-write 1<br>min-slaves-max-lag 10</p>
<p>要求至少有1个slave，数据复制和同步的延迟不能超过10秒</p>
<p>如果说一旦所有的slave，数据复制和同步的延迟都超过了10秒钟，那么这个时候，master就不会再接收任何请求了</p>
<p>上面两个配置可以减少异步复制和脑裂导致的数据丢失</p>
<p>（1）减少异步复制的数据丢失</p>
<p>有了min-slaves-max-lag这个配置，就可以确保说，一旦slave复制数据和ack延时太长，就认为可能master宕机后损失的数据太多了，那么就拒绝写请求，这样可以把master宕机时由于部分数据未同步到slave导致的数据丢失降低的可控范围内</p>
<p>（2）减少脑裂的数据丢失</p>
<p>如果一个master出现了脑裂，跟其他slave丢了连接，那么上面两个配置可以确保说，如果不能继续给指定数量的slave发送数据，而且slave超过10秒没有给自己ack消息，那么就直接拒绝客户端的写请求</p>
<p>这样脑裂后的旧master就不会接受client的新数据，也就避免了数据丢失</p>
<p>上面的配置就确保了，如果跟任何一个slave丢了连接，在10秒后发现没有slave给自己ack，那么就拒绝新的写请求</p>
<p>因此在脑裂场景下，最多就丢失10秒的数据</p>
<h3 id="redis哨兵的多个核心底层原理的深入解析"><a href="#redis哨兵的多个核心底层原理的深入解析" class="headerlink" title="redis哨兵的多个核心底层原理的深入解析"></a>redis哨兵的多个核心底层原理的深入解析</h3><p>1、sdown和odown转换机制</p>
<p>sdown和odown两种失败状态</p>
<p>sdown是主观宕机，就一个哨兵如果自己觉得一个master宕机了，那么就是主观宕机</p>
<p>odown是客观宕机，如果quorum数量的哨兵都觉得一个master宕机了，那么就是客观宕机</p>
<p>sdown达成的条件很简单，如果一个哨兵ping一个master，超过了is-master-down-after-milliseconds指定的毫秒数之后，就主观认为master宕机</p>
<p>sdown到odown转换的条件很简单，如果一个哨兵在指定时间内，收到了quorum指定数量的其他哨兵也认为那个master是sdown了，那么就认为是odown了，客观认为master宕机</p>
<p>2、哨兵集群的自动发现机制</p>
<p>哨兵互相之间的发现，是通过redis的pub/sub系统实现的，每个哨兵都会往<strong>sentinel</strong>:hello这个channel里发送一个消息，这时候所有其他哨兵都可以消费到这个消息，并感知到其他的哨兵的存在</p>
<p>每隔两秒钟，每个哨兵都会往自己监控的某个master+slaves对应的<strong>sentinel</strong>:hello channel里发送一个消息，内容是自己的host、ip和runid还有对这个master的监控配置</p>
<p>每个哨兵也会去监听自己监控的每个master+slaves对应的<strong>sentinel</strong>:hello channel，然后去感知到同样在监听这个master+slaves的其他哨兵的存在</p>
<p>每个哨兵还会跟其他哨兵交换对master的监控配置，互相进行监控配置的同步</p>
<p>3、slave配置的自动纠正</p>
<p>哨兵会负责自动纠正slave的一些配置，比如slave如果要成为潜在的master候选人，哨兵会确保slave在复制现有master的数据; 如果slave连接到了一个错误的master上，比如故障转移之后，那么哨兵会确保它们连接到正确的master上</p>
<p>4、slave-&gt;master选举算法</p>
<p>如果一个master被认为odown了，而且majority哨兵都允许了主备切换，那么某个哨兵就会执行主备切换操作，此时首先要选举一个slave来</p>
<p>会考虑slave的一些信息</p>
<p>（1）跟master断开连接的时长<br>（2）slave优先级<br>（3）复制offset<br>（4）run id</p>
<p>如果一个slave跟master断开连接已经超过了down-after-milliseconds的10倍，外加master宕机的时长，那么slave就被认为不适合选举为master</p>
<p>(down-after-milliseconds * 10) + milliseconds_since_master_is_in_SDOWN_state</p>
<p>接下来会对slave进行排序</p>
<p>（1）按照slave优先级进行排序，slave priority越低，优先级就越高(slave priority是在redis.conf文件中自己设置的)<br>（2）如果slave priority相同，那么看replica offset，哪个slave复制了越多的数据，offset越靠后，优先级就越高<br>（3）如果上面两个条件都相同，那么选择一个run id比较小的那个slave</p>
<p>5、quorum和majority</p>
<p>每次一个哨兵要做主备切换，首先需要quorum数量的哨兵认为odown，然后选举出一个哨兵来做切换，这个哨兵还得得到majority哨兵的授权，才能正式执行切换</p>
<p>如果quorum &lt; majority，比如5个哨兵，majority就是3，quorum设置为2，那么就3个哨兵授权就可以执行切换</p>
<p>但是如果quorum &gt;= majority，那么必须quorum数量的哨兵都授权，比如5个哨兵，quorum是5，那么必须5个哨兵都同意授权，才能执行切换</p>
<p>6、configuration epoch</p>
<p>哨兵会对一套redis master+slave进行监控，有相应的监控的配置</p>
<p>执行切换的那个哨兵，会从要切换到的新master（salve-&gt;master）那里得到一个configuration epoch，这就是一个version号，每次切换的version号都必须是唯一的</p>
<p>如果第一个选举出的哨兵切换失败了，那么其他哨兵，会等待failover-timeout时间，然后接替继续执行切换，此时会重新获取一个新的configuration epoch，作为新的version号</p>
<p>7、configuraiton传播</p>
<p>哨兵完成切换之后，会在自己本地更新生成最新的master配置，然后同步给其他的哨兵，就是通过之前说的pub/sub消息机制</p>
<p>这里之前的version号就很重要了，因为各种消息都是通过一个channel去发布和监听的，所以一个哨兵完成一次新的切换之后，新的master配置是跟着新的version号的</p>
<p>其他的哨兵都是根据版本号的大小来更新自己的master配置的</p>
<h3 id="redis哨兵集群的实战配置"><a href="#redis哨兵集群的实战配置" class="headerlink" title="redis哨兵集群的实战配置"></a>redis哨兵集群的实战配置</h3><p>quorum的解释如下：</p>
<p>（1）至少多少个哨兵要一致同意，master进程挂掉了，或者slave进程挂掉了，或者要启动一个故障转移操作<br>（2）quorum是用来识别故障的，真正执行故障转移的时候，还是要在哨兵集群执行选举，选举一个哨兵进程出来执行故障转移操作<br>（3）假设有5个哨兵，quorum设置了2，那么如果5个哨兵中的2个都认为master挂掉了; 2个哨兵中的一个就会做一个选举，选举一个哨兵出来，执行故障转移; 如果5个哨兵中有3个哨兵都是运行的，那么故障转移就会被允许执行</p>
<p>动手实操，练习如何操作部署哨兵集群，如何基于哨兵进行故障转移，还有一些企业级的配置方案</p>
<p>1、哨兵的配置文件<br>(存放在redis安装目录下)<br>sentinel.conf</p>
<p>最小的配置</p>
<p>每一个哨兵都可以去监控多个maser-slaves的主从架构</p>
<p>因为可能你的公司里，为不同的项目，部署了多个master-slaves的redis主从集群</p>
<p>相同的一套哨兵集群，就可以去监控不同的多个redis主从集群</p>
<p>你自己给每个redis主从集群分配一个逻辑的名称</p>
<p>sentinel monitor mymaster 127.0.0.1 6379 2<br>sentinel down-after-milliseconds mymaster 60000<br>sentinel failover-timeout mymaster 180000<br>sentinel parallel-syncs mymaster 1</p>
<p>sentinel monitor resque 192.168.1.3 6380 4<br>sentinel down-after-milliseconds resque 10000<br>sentinel failover-timeout resque 180000<br>sentinel parallel-syncs resque 5</p>
<p>sentinel monitor mymaster 127.0.0.1 6379 </p>
<p>类似这种配置，来指定对一个master的监控，给监控的master指定的一个名称，因为后面分布式集群架构里会讲解，可以配置多个master做数据拆分</p>
<p>sentinel down-after-milliseconds mymaster 60000<br>sentinel failover-timeout mymaster 180000<br>sentinel parallel-syncs mymaster 1</p>
<p>上面的三个配置，都是针对某个监控的master配置的，给其指定上面分配的名称即可</p>
<p>上面这段配置，就监控了两个master node</p>
<p>这是最小的哨兵配置，如果发生了master-slave故障转移，或者新的哨兵进程加入哨兵集群，那么哨兵会自动更新自己的配置文件</p>
<p>sentinel monitor master-group-name hostname port quorum</p>
<p>quorum的解释如下：</p>
<p>（1）至少多少个哨兵要一致同意，master进程挂掉了，或者slave进程挂掉了，或者要启动一个故障转移操作<br>（2）quorum是用来识别故障的，真正执行故障转移的时候，还是要在哨兵集群执行选举，选举一个哨兵进程出来执行故障转移操作<br>（3）假设有5个哨兵，quorum设置了2，那么如果5个哨兵中的2个都认为master挂掉了; 2个哨兵中的一个就会做一个选举，选举一个哨兵出来，执行故障转移; 如果5个哨兵中有3个哨兵都是运行的，那么故障转移就会被允许执行</p>
<p>down-after-milliseconds，超过多少毫秒跟一个redis实例断了连接，哨兵就可能认为这个redis实例挂了</p>
<p>parallel-syncs，新的master别切换之后，同时有多少个slave被切换到去连接新master，重新做同步，数字越低，花费的时间越多</p>
<p>假设你的redis是1个master，4个slave</p>
<p>然后master宕机了，4个slave中有1个切换成了master，剩下3个slave就要挂到新的master上面去</p>
<p>这个时候，如果parallel-syncs是1，那么3个slave，一个一个地挂接到新的master上面去，1个挂接完，而且从新的master sync完数据之后，再挂接下一个</p>
<p>如果parallel-syncs是3，那么一次性就会把所有slave挂接到新的master上去</p>
<p>failover-timeout，执行故障转移的timeout超时时长</p>
<p>2、在eshop-cache03上再部署一个redis</p>
<p>只要安装redis就可以了，不需要去部署redis实例的启动</p>
<p>wget <a href="http://downloads.sourceforge.net/tcl/tcl8.6.1-src.tar.gz" target="_blank" rel="noopener">http://downloads.sourceforge.net/tcl/tcl8.6.1-src.tar.gz</a><br>tar -xzvf tcl8.6.1-src.tar.gz<br>cd  /usr/local/tcl8.6.1/unix/<br>./configure<br>make &amp;&amp; make install</p>
<p>使用redis-3.2.8.tar.gz（截止2017年4月的最新稳定版）<br>tar -zxvf redis-3.2.8.tar.gz<br>cd redis-3.2.8<br>make &amp;&amp; make test<br>make install</p>
<p>2、正式的配置</p>
<p>哨兵默认用26379端口，默认不能跟其他机器在指定端口连通，只能在本地访问</p>
<p>mkdir /etc/sentinal<br>mkdir -p /var/sentinal/5000</p>
<p>/etc/sentinel/5000.conf</p>
<p>port 5000<br>bind 192.168.31.187<br>dir /var/sentinal/5000<br>sentinel monitor mymaster 192.168.31.187 6379 2<br>sentinel down-after-milliseconds mymaster 30000<br>sentinel failover-timeout mymaster 60000<br>sentinel parallel-syncs mymaster 1</p>
<p>port 5000<br>bind 192.168.31.19<br>dir /var/sentinal/5000<br>sentinel monitor mymaster 192.168.31.187 6379 2<br>sentinel down-after-milliseconds mymaster 30000<br>sentinel failover-timeout mymaster 60000<br>sentinel parallel-syncs mymaster 1</p>
<p>port 5000<br>bind 192.168.31.227<br>dir /var/sentinal/5000<br>sentinel monitor mymaster 192.168.31.187 6379 2<br>sentinel down-after-milliseconds mymaster 30000<br>sentinel failover-timeout mymaster 60000<br>sentinel parallel-syncs mymaster 1</p>
<p>3、启动哨兵进程</p>
<p>在eshop-cache01、eshop-cache02、eshop-cache03三台机器上，分别启动三个哨兵进程，组成一个集群，观察一下日志的输出</p>
<p>redis-sentinel /etc/sentinal/5000.conf<br>redis-server /etc/sentinal/5000.conf –sentinel</p>
<p>日志里会显示出来，每个哨兵都能去监控到对应的redis master，并能够自动发现对应的slave</p>
<p>哨兵之间，互相会自动进行发现，用的就是之前说的pub/sub，消息发布和订阅channel消息系统和机制</p>
<p>4、检查哨兵状态</p>
<p>redis-cli -h 192.168.31.187 -p 5000</p>
<p>sentinel master mymaster<br>SENTINEL slaves mymaster<br>SENTINEL sentinels mymaster</p>
<p>SENTINEL get-master-addr-by-name mymaster</p>
<h3 id="redis-cluster横向扩容master"><a href="#redis-cluster横向扩容master" class="headerlink" title="redis cluster横向扩容master"></a>redis cluster横向扩容master</h3><p>1、单机redis在海量数据面前的瓶颈</p>
<p>2、怎么才能够突破单机瓶颈，让redis支撑海量数据？</p>
<p>3、redis的集群架构</p>
<p>redis cluster</p>
<p>支撑N个redis master node，每个master node都可以挂载多个slave node</p>
<p>读写分离的架构，对于每个master来说，写就写到master，然后读就从mater对应的slave去读</p>
<p>高可用，因为每个master都有salve节点，那么如果mater挂掉，redis cluster这套机制，就会自动将某个slave切换成master</p>
<p>redis cluster（多master + 读写分离 + 高可用）</p>
<p>我们只要基于redis cluster去搭建redis集群即可，不需要手工去搭建replication复制+主从架构+读写分离+哨兵集群+高可用</p>
<p>4、redis cluster vs. replication + sentinal</p>
<p>如果你的数据量很少，主要是承载高并发高性能的场景，比如你的缓存一般就几个G，单机足够了</p>
<p>replication，一个mater，多个slave，要几个slave跟你的要求的读吞吐量有关系，然后自己搭建一个sentinal集群，去保证redis主从架构的高可用性，就可以了</p>
<p>redis cluster，主要是针对海量数据+高并发+高可用的场景，海量数据，如果你的数据量很大，那么建议就用redis cluster</p>
<h3 id="redis阶段性总结"><a href="#redis阶段性总结" class="headerlink" title="redis阶段性总结"></a>redis阶段性总结</h3><p>1、讲解redis是为了什么？</p>
<p>topic：高并发、亿级流量、高性能、海量数据的场景，电商网站的商品详情页系统的缓存架构</p>
<p>商品详情页系统，大型电商网站，会有很多部分组成，但是支撑高并发、亿级流量的，主要就是其中的大型的缓存架构</p>
<p>在这个大型的缓存架构中，redis是最最基础的一层</p>
<p>高并发，缓存架构中除了redis，还有其他的组成部分，但是redis至关重要</p>
<p>大量的离散请求，随机请求，各种你未知的用户过来的请求，上千万用户过来访问，每个用户访问10次; 集中式的请求，1个用户过来，一天访问1亿次</p>
<p>支撑商品展示的最重要的，就是redis cluster，去抗住每天上亿的请求流量，支撑高并发的访问</p>
<p>redis cluster在整个缓存架构中，如何跟其他几个部分搭配起来组成一个大型的缓存系统，后面再讲</p>
<p>2、讲解的redis可以实现什么效果？</p>
<p>我之前一直在redis的各个知识点的讲解之前都强调一下，我们要讲解的每个知识点，要解决的问题是什么？？？</p>
<p>redis：持久化、复制（主从架构）、哨兵（高可用，主备切换）、redis cluster（海量数据+横向扩容+高可用/主备切换）</p>
<p>持久化：高可用的一部分，在发生redis集群灾难的情况下（比如说部分master+slave全部死掉了），如何快速进行数据恢复，快速实现服务可用，才能实现整个系统的高可用</p>
<p>复制：主从架构，master -&gt; slave 复制，读写分离的架构，写master，读slave，横向扩容slave支撑更高的读吞吐，读高并发，10万，20万，30万，上百万，QPS，横向扩容</p>
<p>哨兵：高可用，主从架构，在master故障的时候，快速将slave切换成master，实现快速的灾难恢复，实现高可用性</p>
<p>redis cluster：多master读写，数据分布式的存储，横向扩容，水平扩容，快速支撑高达的数据量+更高的读写QPS，自动进行master -&gt; slave的主备切换，高可用</p>
<p>让底层的缓存系统，redis，实现能够任意水平扩容，支撑海量数据（1T+，几十T，10G * 600 redis = 6T），支撑很高的读写QPS（redis单机在几万QPS，10台，几十万QPS），高可用性（给我们每个redis实例都做好AOF+RDB的备份策略+容灾策略，slave -&gt; master主备切换）</p>
<p>1T+海量数据、10万+读写QPS、99.99%高可用性</p>
<p>3、redis的第一套企业级的架构</p>
<p>如果你的数据量不大，单master就可以容纳，一般来说你的缓存的总量在10G以内就可以，那么建议按照以下架构去部署redis</p>
<p>redis持久化+备份方案+容灾方案+replication（主从+读写分离）+sentinal（哨兵集群，3个节点，高可用性）</p>
<p>可以支撑的数据量在10G以内，可以支撑的写QPS在几万左右，可以支撑的读QPS可以上10万以上（随你的需求，水平扩容slave节点就可以），可用性在99.99%</p>
<p>4、redis的第二套企业级架构</p>
<p>如果你的数据量很大，比如我们课程的topic，大型电商网站的商品详情页的架构（对标那些国内排名前三的大电商网站，<em>宝，</em>东，*宁易购），数据量是很大的</p>
<p>海量数据</p>
<p>redis cluster</p>
<p>多master分布式存储数据，水平扩容</p>
<p>支撑更多的数据量，1T+以上没问题，只要扩容master即可</p>
<p>读写QPS分别都达到几十万都没问题，只要扩容master即可，redis cluster，读写分离，支持不太好，readonly才能去slave上读</p>
<p>支撑99.99%可用性，也没问题，slave -&gt; master的主备切换，冗余slave去进一步提升可用性的方案（每个master挂一个slave，但是整个集群再加个3个slave冗余一下）</p>
<p>我们课程里，两套架构都讲解了，后续的业务系统的开发，主要是基于redis cluster去做</p>
<p>5、我们现在课程讲解的项目进展到哪里了？</p>
<p>我们要做后续的业务系统的开发，redis的架构部署好，是第一件事情，也是非常重要的，也是你作为一个架构师而言，在对系统进行设计的时候，你必须要考虑到底层的redis的并发、性能、能支撑的数据量、可用性</p>
<p>redis：水平扩容，海量数据，上10万的读写QPS，99.99%高可用性</p>
<p>从架构的角度，我们的redis是可以做到的，水平扩容，只要机器足够，到1T数据量，50万读写QPS，99.99%</p>
<p>正式开始做大型电商网站的商品详情页系统，大规模的缓存架构设计</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/10/01/SQL注入/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Chen ZeTao">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/weixin.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="ddd `Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/10/01/SQL注入/" itemprop="url">SQL注入</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-10-01T17:50:41+08:00">
                2019-10-01
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  1.6k
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  6
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="SQL注入简介"><a href="#SQL注入简介" class="headerlink" title="SQL注入简介"></a>SQL注入简介</h2><p>SQL注入是网站存在最多也是最简单的漏洞，主要原因是程序员在开发用户和数据库交互的系统时，没有对用户输入的字符串进行过滤，转义，限制或处理不严谨，导致用户可以通过输入精心构造的字符串去非法获取到数据库中的数据。</p>
<h3 id="SQL注入原理"><a href="#SQL注入原理" class="headerlink" title="SQL注入原理"></a>SQL注入原理</h3><p>一般用户登录用的SQL语句为：SELECT <em> FROM user WHERE username=’admin’ AND password=’passwd’，此处admin和passwd分别为用户输入的用户名和密码，如果程序员没有对用户输入的用户名和密码做处理，就可以构造万能密码成功绕过登录验证，如用户输入<strong>‘or 1#</strong>,SQL语句将变为：SELECT </em> FROM user WHERE username=’’or 1#’ AND password=’’，‘’or 1为TRUE，#注释掉后面的内容，所以查询语句可以正确执行。</p>
<h3 id="mybatis是如何防止SQL注入的"><a href="#mybatis是如何防止SQL注入的" class="headerlink" title="mybatis是如何防止SQL注入的"></a>mybatis是如何防止SQL注入的</h3><h3 id="1、首先看一下下面两个sql语句的区别："><a href="#1、首先看一下下面两个sql语句的区别：" class="headerlink" title="1、首先看一下下面两个sql语句的区别："></a>1、首先看一下下面两个sql语句的区别：</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;select id="selectByNameAndPassword" parameterType="java.util.Map" resultMap="BaseResultMap"&gt;</span><br><span class="line"><span class="keyword">select</span> <span class="keyword">id</span>, username, <span class="keyword">password</span>, <span class="keyword">role</span></span><br><span class="line"><span class="keyword">from</span> <span class="keyword">user</span></span><br><span class="line"><span class="keyword">where</span> username = <span class="comment">#&#123;username,jdbcType=VARCHAR&#125;</span></span><br><span class="line"><span class="keyword">and</span> <span class="keyword">password</span> = <span class="comment">#&#123;password,jdbcType=VARCHAR&#125;</span></span><br><span class="line">&lt;/<span class="keyword">select</span>&gt;</span><br></pre></td></tr></table></figure>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;select id="selectByNameAndPassword" parameterType="java.util.Map" resultMap="BaseResultMap"&gt;</span><br><span class="line"><span class="keyword">select</span> <span class="keyword">id</span>, username, <span class="keyword">password</span>, <span class="keyword">role</span></span><br><span class="line"><span class="keyword">from</span> <span class="keyword">user</span></span><br><span class="line"><span class="keyword">where</span> username = $&#123;username,jdbcType=<span class="built_in">VARCHAR</span>&#125;</span><br><span class="line"><span class="keyword">and</span> <span class="keyword">password</span> = $&#123;<span class="keyword">password</span>,jdbcType=<span class="built_in">VARCHAR</span>&#125;</span><br><span class="line">&lt;/<span class="keyword">select</span>&gt;</span><br></pre></td></tr></table></figure>
<p><strong>mybatis中的#和$的区别：</strong></p>
<p>1、#将传入的数据都当成一个字符串，会对自动传入的数据加一个双引号。<br>如：where username=#{username}，如果传入的值是111,那么解析成sql时的值为where username=”111”, 如果传入的值是id，则解析成的sql为where username=”id”.　<br>2、$将传入的数据直接显示生成在sql中。<br>如：where username=${username}，如果传入的值是111,那么解析成sql时的值为where username=111；<br>如果传入的值是;drop table user;，则解析成的sql为：select id, username, password, role from user where username=;drop table user;<br>3、#方式能够很大程度防止sql注入，$方式无法防止Sql注入。<br>4、$方式一般用于传入数据库对象，例如传入表名.<br>5、一般能用#的就别用$，若不得不使用“${xxx}”这样的参数，要手工地做好过滤工作，来防止sql注入攻击。<br>6、在MyBatis中，“${xxx}”这样格式的参数会直接参与SQL编译，从而不能避免注入攻击。但涉及到动态表名和列名时，只能使用“${xxx}”这样的参数格式。所以，这样的参数需要我们在代码中手工进行处理来防止注入。<br>【结论】在编写MyBatis的映射语句时，尽量采用“#{xxx}”这样的格式。若不得不使用“${xxx}”这样的参数，要手工地做好过滤工作，来防止SQL注入攻击。</p>
<h3 id="2、什么是sql注入"><a href="#2、什么是sql注入" class="headerlink" title="2、什么是sql注入"></a>2、什么是sql注入</h3><p>　　<a href="https://en.wikipedia.org/wiki/SQL_injection" target="_blank" rel="noopener"> sql注入解释</a>：是一种代码注入技术，用于攻击数据驱动的应用，恶意的SQL语句被插入到执行的实体字段中（例如，为了转储数据库内容给攻击者）</p>
<p>　　<strong>SQL**</strong>注入<strong>，大家都不陌生，是一种常见的攻击方式。</strong>攻击者<strong>在界面的表单信息或URL上输入一些奇怪的SQL片段（例如“or ‘1’=’1’”这样的语句），有可能入侵</strong>参数检验不足<strong>的应用程序。所以，在我们的应用中需要做一些工作，来防备这样的攻击方式。在一些安全性要求很高的应用中（比如银行软件），经常使用将</strong>SQL<strong>**语句</strong>全部替换为<strong>存储过程</strong>这样的方式，来防止SQL注入。这当然是<strong>一种很安全的方式</strong>，但我们平时开发中，可能不需要这种死板的方式。</p>
<h3 id="3、mybatis是如何做到防止sql注入的"><a href="#3、mybatis是如何做到防止sql注入的" class="headerlink" title="3、mybatis是如何做到防止sql注入的"></a>3、mybatis是如何做到防止sql注入的</h3><p>　　<a href="https://mybatis.github.io/mybatis-3/" target="_blank" rel="noopener">MyBatis</a>框架作为一款半自动化的持久层框架，其SQL语句都要我们自己手动编写，这个时候当然需要防止SQL注入。其实，MyBatis的SQL是一个具有“<strong>输入+输出</strong>”的功能，类似于函数的结构，参考上面的两个例子。其中，parameterType表示了输入的参数类型，resultType表示了输出的参数类型。回应上文，如果我们想防止SQL注入，理所当然地要在输入参数上下功夫。上面代码中使用 <strong>#</strong> 的即输入参数在SQL中拼接的部分，传入参数后，打印出执行的SQL语句，会看到SQL是这样的：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select id, username, password, role from user where username=? and password=?</span><br></pre></td></tr></table></figure>
<p>　　不管输入什么参数，打印出的SQL都是这样的。这是因为MyBatis启用了预编译功能，在SQL执行前，会先将上面的SQL发送给数据库进行编译；执行时，直接使用编译好的SQL，替换占位符“?”就可以了。因为SQL注入只能对编译过程起作用，所以这样的方式就很好地避免了SQL注入的问题。</p>
<p>　　【底层实现原理】MyBatis是如何做到SQL预编译的呢？其实在框架底层，是JDBC中的PreparedStatement类在起作用，PreparedStatement是我们很熟悉的Statement的子类，它的对象包含了编译好的SQL语句。这种“准备好”的方式不仅能提高安全性，而且在多次执行同一个SQL时，能够提高效率。原因是SQL已编译好，再次执行时无需再编译。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">//安全的，预编译了的</span><br><span class="line">Connection conn = getConn();//获得连接</span><br><span class="line">String sql = &quot;select id, username, password, role from user where id=?&quot;; //执行sql前会预编译号该条语句</span><br><span class="line">PreparedStatement pstmt = conn.prepareStatement(sql); </span><br><span class="line">pstmt.setString(1, id); </span><br><span class="line">ResultSet rs=pstmt.executeUpdate(); </span><br><span class="line">......</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">//不安全的，没进行预编译</span><br><span class="line">private String getNameByUserId(String userId) &#123;</span><br><span class="line">    Connection conn = getConn();//获得连接</span><br><span class="line">    String sql = &quot;select id,username,password,role from user where id=&quot; + id;</span><br><span class="line">    //当id参数为&quot;3;drop table user;&quot;时，执行的sql语句如下:</span><br><span class="line">    //select id,username,password,role from user where id=3; drop table user;  </span><br><span class="line">    PreparedStatement pstmt =  conn.prepareStatement(sql);</span><br><span class="line">    ResultSet rs=pstmt.executeUpdate();</span><br><span class="line">    ......</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>【 <strong>结论</strong>：】</p>
<table>
<thead>
<tr>
<th>#{}：相当于JDBC中的PreparedStatement</th>
</tr>
</thead>
<tbody>
<tr>
<td>${}：是输出变量的值</td>
</tr>
</tbody>
</table>
<p>简单说，#{}是经过预编译的，是安全的；${}是未经过预编译的，仅仅是取变量的值，是非安全的，存在SQL注入。<br>如果我们order by语句后用了${}，那么不做任何处理的时候是存在SQL注入危险的。你说怎么防止，那我只能悲惨的告诉你，你得手动处理过滤一下输入的内容。如判断一下输入的参数的长度是否正常（注入语句一般很长），更精确的过滤则可以查询一下输入的参数是否在预期的参数集合中。</p>
<p>作者：<a href="http://www.cnblogs.com/mmzs/" target="_blank" rel="noopener">淼淼之森</a></p>
<p>### </p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/10/01/JAVA锁/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Chen ZeTao">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/weixin.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="ddd `Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/10/01/JAVA锁/" itemprop="url">JAVA锁</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-10-01T17:48:43+08:00">
                2019-10-01
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  4.1k
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  14
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="JAVA锁"><a href="#JAVA锁" class="headerlink" title="JAVA锁"></a>JAVA锁</h1><p>Java SE1.6为了减少获得锁和释放锁所带来的性能消耗，引入了“偏向锁”和“轻量级锁”，所以在Java SE1.6里锁一共有四种状态，无锁状态，偏向锁状态，轻量级锁状态和重量级锁状态，它会随着竞争情况逐渐升级。<strong>锁可以升级但不能降级，意味着偏向锁升级成轻量级锁后不能降级成偏向锁。这种锁升级却不能降级的策略，目的是为了提高获得锁和释放锁的效率。</strong></p>
<h3 id="悲观锁与乐观锁"><a href="#悲观锁与乐观锁" class="headerlink" title="悲观锁与乐观锁"></a>悲观锁与乐观锁</h3><h4 id="悲观锁"><a href="#悲观锁" class="headerlink" title="悲观锁"></a>悲观锁</h4><p>总是假设最坏的情况，每次去拿数据的时候都认为别人会修改，所以每次在拿数据的时候都会上锁。传统的关系型数据库里边就用到了很多这种锁机制，比如行锁，表锁，读锁，写锁等，都是在做操作之前先上锁。JAVA中synchronize和ReentrantLock等独占锁就是悲观锁思想的实现。</p>
<h4 id="乐观锁"><a href="#乐观锁" class="headerlink" title="乐观锁"></a>乐观锁</h4><p>总是假设最好的情况，每次拿数据都认为别人不会修改，所以不会上锁。<strong>但是在更新的时候会判断一下在此期间别人有没有去更新这个数据，可以使用版本号机制和CAS算法实现。</strong></p>
<p>乐观锁适用于多读的应用类型，这样可以提高吞吐量。</p>
<p><strong>java中的4种锁，分别是重量级锁，自旋锁，轻量级锁和偏向锁。重量级锁是悲观锁的一种，自旋锁，轻量级锁和偏向锁属于乐观锁。</strong></p>
<h5 id="乐观锁常见的两种实现方式"><a href="#乐观锁常见的两种实现方式" class="headerlink" title="乐观锁常见的两种实现方式"></a>乐观锁常见的两种实现方式</h5><blockquote>
<p><strong>乐观锁一般会使用版本号机制或CAS算法实现。</strong></p>
</blockquote>
<h4 id="1-版本号机制"><a href="#1-版本号机制" class="headerlink" title="1. 版本号机制"></a>1. 版本号机制</h4><p>一般是在数据表中加上一个数据版本号version字段，表示数据被修改的次数，当数据被修改时，version值会加一。当线程A要更新数据值时，在读取数据的同时也会读取version值，在提交更新时，若刚才读取到的version值为当前数据库中的version值相等时才更新，否则重试更新操作，直到更新成功。</p>
<p><strong>举一个简单的例子：</strong> 假设数据库中帐户信息表中有一个 version 字段，当前值为 1 ；而当前帐户余额字段（ balance ）为 $100 。</p>
<ol>
<li>操作员 A 此时将其读出（ version=1 ），并从其帐户余额中扣除 $50（ $100-$50 ）。</li>
<li>在操作员 A 操作的过程中，操作员B 也读入此用户信息（ version=1 ），并从其帐户余额中扣除 $20 （ $100-$20 ）。</li>
<li>操作员 A 完成了修改工作，将数据版本号加一（ version=2 ），连同帐户扣除后余额（ balance=$50 ），提交至数据库更新，此时由于提交数据版本大于数据库记录当前版本，数据被更新，数据库记录 version 更新为 2 。</li>
<li>操作员 B 完成了操作，也将版本号加一（ version=2 ）试图向数据库提交数据（ balance=$80 ），但此时比对数据库记录版本时发现，操作员 B 提交的数据版本号为 2 ，数据库记录当前版本也为 2 ，不满足 “ 提交版本必须大于记录当前版本才能执行更新 “ 的乐观锁策略，因此，操作员 B 的提交被驳回。</li>
</ol>
<p>这样，就避免了操作员 B 用基于 version=1 的旧数据修改的结果覆盖操作员A 的操作结果的可能。</p>
<h4 id="2-简单回顾一下CAS算法"><a href="#2-简单回顾一下CAS算法" class="headerlink" title="2.简单回顾一下CAS算法"></a>2.简单回顾一下CAS算法</h4><p><strong>CAS算法</strong> 即compare and swap（比较与交换），是一种有名的无锁算法。无锁编程，即不使用锁的情况下实现多线程之间的变量同步，也就是在没有线程被阻塞的情况下实现变量的同步，所以也叫非阻塞同步（Non-blocking Synchronization）。CAS算法涉及到三个操作数</p>
<ul>
<li>需要读写的内存值 V</li>
<li>进行比较的值 A</li>
<li>拟写入的新值 B</li>
</ul>
<p>当且仅当 V 的值等于 A时，CAS通过原子方式用新值B来更新V的值，否则不会执行任何操作（比较和替换是一个原子操作）。一般情况下是一个自旋操作，即不断的重试。</p>
<h3 id="乐观锁的缺点"><a href="#乐观锁的缺点" class="headerlink" title="乐观锁的缺点"></a>乐观锁的缺点</h3><blockquote>
<p>ABA 问题是乐观锁一个常见的问题</p>
</blockquote>
<h4 id="1-ABA-问题"><a href="#1-ABA-问题" class="headerlink" title="1 ABA 问题"></a>1 ABA 问题</h4><p>如果一个变量V初次读取的时候是A值，并且在准备赋值的时候检查到它仍然是A值，那我们就能说明它的值没有被其他线程修改过了吗？很明显是不能的，因为在这段时间它的值可能被改为其他值，然后又改回A，那CAS操作就会误认为它从来没有被修改过。这个问题被称为CAS操作的 <strong>“ABA”问题。</strong></p>
<p>JDK 1.5 以后的 <code>AtomicStampedReference 类</code>就提供了此种能力，其中的 <code>compareAndSet 方法</code>就是首先检查当前引用是否等于预期引用，并且当前标志是否等于预期标志，如果全部相等，则以原子方式将该引用和该标志的值设置为给定的更新值。</p>
<h4 id="2-循环时间长开销大"><a href="#2-循环时间长开销大" class="headerlink" title="2 循环时间长开销大"></a>2 循环时间长开销大</h4><p><strong>自旋CAS（也就是不成功就一直循环执行直到成功）如果长时间不成功，会给CPU带来非常大的执行开销。</strong> 如果JVM能支持处理器提供的pause指令那么效率会有一定的提升，pause指令有两个作用，第一它可以延迟流水线执行指令（de-pipeline）,使CPU不会消耗过多的执行资源，延迟的时间取决于具体实现的版本，在一些处理器上延迟时间是零。第二它可以避免在退出循环的时候因内存顺序冲突（memory order violation）而引起CPU流水线被清空（CPU pipeline flush），从而提高CPU的执行效率。</p>
<h4 id="3-只能保证一个共享变量的原子操作"><a href="#3-只能保证一个共享变量的原子操作" class="headerlink" title="3 只能保证一个共享变量的原子操作"></a>3 只能保证一个共享变量的原子操作</h4><p>CAS 只对单个共享变量有效，当操作涉及跨多个共享变量时 CAS 无效。但是从 JDK 1.5开始，提供了<code>AtomicReference类</code>来保证引用对象之间的原子性，你可以把多个变量放在一个对象里来进行 CAS 操作.所以我们可以使用锁或者利用<code>AtomicReference类</code>把多个共享变量合并成一个共享变量来操作。</p>
<h3 id="什么是自旋锁？"><a href="#什么是自旋锁？" class="headerlink" title="什么是自旋锁？"></a>什么是自旋锁？</h3><p>自旋锁（spinlock）：是指当一个线程在获取锁的时候，如果锁已经被其它线程获取，那么该线程将循环等待，然后不断的判断锁是否能够被成功获取，直到获取到锁才会退出循环。</p>
<p>获取锁的线程一直处于活跃状态，但是并没有执行任何有效的任务，使用这种锁会造成<a href="https://en.wikipedia.org/wiki/Busy_waiting" target="_blank" rel="noopener">busy-waiting</a>。</p>
<p>它是为实现保护共享资源而提出一种锁机制。其实，自旋锁与互斥锁比较类似，它们都是为了解决对某项资源的互斥使用。无论是互斥锁，还是自旋锁，在任何时刻，最多只能有一个保持者，也就说，在任何时刻最多只能有一个执行单元获得锁。但是两者在调度机制上略有不同。对于互斥锁，如果资源已经被占用，资源申请者只能进入睡眠状态。但是自旋锁不会引起调用者睡眠，如果自旋锁已经被别的执行单元保持，调用者就一直循环在那里看是否该自旋锁的保持者已经释放了锁，”自旋”一词就是因此而得名。</p>
<h3 id="Java如何实现自旋锁？"><a href="#Java如何实现自旋锁？" class="headerlink" title="Java如何实现自旋锁？"></a>Java如何实现自旋锁？</h3><p>下面是个简单的例子：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">SpinLock</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> AtomicReference&lt;Thread&gt; cas = <span class="keyword">new</span> AtomicReference&lt;Thread&gt;();</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">lock</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        Thread current = Thread.currentThread();</span><br><span class="line">        <span class="comment">// 利用CAS</span></span><br><span class="line">        <span class="keyword">while</span> (!cas.compareAndSet(<span class="keyword">null</span>, current)) &#123;</span><br><span class="line">            <span class="comment">// DO nothing</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">unlock</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        Thread current = Thread.currentThread();</span><br><span class="line">        cas.compareAndSet(current, <span class="keyword">null</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;<span class="number">1234567891011121314</span></span><br></pre></td></tr></table></figure>
<p>lock（)方法利用的CAS，当第一个线程A获取锁的时候，能够成功获取到，不会进入while循环，如果此时线程A没有释放锁，另一个线程B又来获取锁，此时由于不满足CAS，所以就会进入while循环，不断判断是否满足CAS，直到A线程调用unlock方法释放了该锁。</p>
<h3 id="自旋锁存在的问题"><a href="#自旋锁存在的问题" class="headerlink" title="自旋锁存在的问题"></a>自旋锁存在的问题</h3><ol>
<li>如果某个线程持有锁的时间过长，就会导致其它等待获取锁的线程进入循环等待，消耗CPU。使用不当会造成CPU使用率极高。</li>
<li>上面Java实现的自旋锁不是公平的，即无法满足等待时间最长的线程优先获取锁。不公平的锁就会存在“线程饥饿”问题。</li>
</ol>
<h3 id="自旋锁的优点"><a href="#自旋锁的优点" class="headerlink" title="自旋锁的优点"></a>自旋锁的优点</h3><ol>
<li>自旋锁不会使线程状态发生切换，一直处于用户态，即线程一直都是active的；不会使线程进入阻塞状态，减少了不必要的上下文切换，执行速度快</li>
<li>非自旋锁在获取不到锁的时候会进入阻塞状态，从而进入内核态，当获取到锁的时候需要从内核态恢复，需要线程上下文切换。 （线程被阻塞后便进入内核（Linux）调度状态，这个会导致系统在用户态与内核态之间来回切换，严重影响锁的性能）</li>
</ol>
<h3 id="TicketLock主要解决的是公平性的问题。"><a href="#TicketLock主要解决的是公平性的问题。" class="headerlink" title="TicketLock主要解决的是公平性的问题。"></a>TicketLock主要解决的是公平性的问题。</h3><p>思路：每当有线程获取锁的时候，就给该线程分配一个递增的id，我们称之为排队号，同时，锁对应一个服务号，每当有线程释放锁，服务号就会递增，此时如果服务号与某个线程排队号一致，那么该线程就获得锁，由于排队号是递增的，所以就保证了最先请求获取锁的线程可以最先获取到锁，就实现了公平性。</p>
<p>可以想象成银行办理业务排队，排队的每一个顾客都代表一个需要请求锁的线程，而银行服务窗口表示锁，每当有窗口服务完成就把自己的服务号加一，此时在排队的所有顾客中，只有自己的排队号与服务号一致的才可以得到服务。</p>
<h3 id="偏向锁"><a href="#偏向锁" class="headerlink" title="偏向锁"></a>偏向锁</h3><p>Java偏向锁(Biased Locking)是Java6引入的一项多线程优化。<br>偏向锁，顾名思义，它会偏向于第一个访问锁的线程，如果在运行过程中，同步锁只有一个线程访问，不存在多线程争用的情况，则线程是不需要触发同步的，这种情况下，就会给线程加一个偏向锁。<br><strong>如果在运行过程中，遇到了其他线程抢占锁，则持有偏向锁的线程会被挂起，JVM会消除它身上的偏向锁，将锁恢复到标准的轻量级锁。</strong></p>
<p>它通过消除资源无竞争情况下的同步原语，进一步提高了程序的运行性能。</p>
<h4 id="偏向锁的实现"><a href="#偏向锁的实现" class="headerlink" title="偏向锁的实现"></a>偏向锁的实现</h4><p>偏向锁获取过程：</p>
<ol>
<li>访问Mark Word中偏向锁的标识是否设置成1，锁标志位是否为01，确认为可偏向状态。</li>
<li>如果为可偏向状态，则测试线程ID是否指向当前线程，如果是，进入步骤5，否则进入步骤3。</li>
<li>如果线程ID并未指向当前线程，则通过CAS操作竞争锁。如果竞争成功，则将Mark Word中线程ID设置为当前线程ID，然后执行5；如果竞争失败，执行4。</li>
<li>如果CAS获取偏向锁失败，则表示有竞争。当到达全局安全点（safepoint）时获得偏向锁的线程被挂起，偏向锁升级为轻量级锁，然后被阻塞在安全点的线程继续往下执行同步代码。（撤销偏向锁的时候会导致stop the word）</li>
<li>执行同步代码。</li>
</ol>
<p>注意：第四步中到达安全点safepoint会导致stop the word，时间很短。</p>
<h4 id="偏向锁的释放："><a href="#偏向锁的释放：" class="headerlink" title="偏向锁的释放："></a>偏向锁的释放：</h4><p>偏向锁的撤销在上述第四步骤中有提到。偏向锁只有遇到其他线程尝试竞争偏向锁时，持有偏向锁的线程才会释放锁，<strong>线程不会主动去释放偏向锁。</strong>偏向锁的撤销，需要等待全局安全点（在这个时间点上没有字节码正在执行），它会首先暂停拥有偏向锁的线程，判断锁对象是否处于被锁定状态，撤销偏向锁后恢复到未锁定（标志位为“01”）或轻量级锁（标志位为“00”）的状态。</p>
<h4 id="偏向锁的适用场景"><a href="#偏向锁的适用场景" class="headerlink" title="偏向锁的适用场景"></a>偏向锁的适用场景</h4><p>始终只有一个线程在执行同步块，在它没有执行完释放锁之前，没有其它线程去执行同步块，在锁无竞争的情况下使用，一旦有了竞争就升级为轻量级锁，升级为轻量级锁的时候需要撤销偏向锁，撤销偏向锁的时候会导致stop the word操作；<br>在有锁的竞争时，偏向锁会多做很多额外操作，尤其是撤销偏向所的时候会导致进入安全点，安全点会导致stw，导致性能下降，这种情况下应当禁用； </p>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><h3 id="自旋锁"><a href="#自旋锁" class="headerlink" title="自旋锁"></a>自旋锁</h3><p>线程的阻塞和唤醒需要CPU从用户态转为核心态，频繁的阻塞和唤醒对CPU来说是一件负担很重的工作。同时我们可以发现，很多对象锁的锁定状态只会持续很短的一段时间，例如整数的自加操作，在很短的时间内阻塞并唤醒线程显然不值得，为此引入了自旋锁。</p>
<p>所谓“自旋”，就是让线程去执行一个无意义的循环，循环结束后再去重新竞争锁，如果竞争不到继续循环，循环过程中线程会一直处于running状态，但是基于JVM的线程调度，会出让时间片，所以其他线程依旧有申请锁和释放锁的机会。</p>
<p>自旋锁省去了阻塞锁的时间空间（队列的维护等）开销，但是长时间自旋就变成了“忙式等待”，忙式等待显然还不如阻塞锁。所以自旋的次数一般控制在一个范围内，例如10,100等，在超出这个范围后，自旋锁会升级为阻塞锁。（即从轻量级锁转变为重量级锁）</p>
<h3 id="轻量级锁"><a href="#轻量级锁" class="headerlink" title="轻量级锁"></a>轻量级锁</h3><p>加锁</p>
<p>线程在执行同步块之前，JVM会先在当前线程的栈桢中创建用于存储锁记录的空间，并将对象头中的Mark Word复制到锁记录中，官方称为Displaced Mark Word。<strong>然后线程尝试使用CAS将对象头中的Mark Word替换为指向锁记录的指针。如果成功，当前线程获得锁，如果失败，则自旋获取锁，当自旋获取锁仍然失败时，表示存在其他线程竞争锁(两条或两条以上的线程竞争同一个锁)，则轻量级锁会膨胀成重量级锁。</strong></p>
<p>解锁</p>
<p><strong>轻量级解锁时，会使用原子的CAS操作来将Displaced Mark Word替换回到对象头，如果成功，则表示同步过程已完成。</strong>如果失败，表示有其他线程尝试过获取该锁，则要在释放锁的同时唤醒被挂起的线程。</p>
<h3 id="重量级锁"><a href="#重量级锁" class="headerlink" title="重量级锁"></a>重量级锁</h3><p>重量锁在JVM中又叫对象监视器（Monitor），它很像C中的Mutex，除了具备Mutex(0|1)互斥的功能，它还负责实现了Semaphore(信号量)的功能，也就是说它至少包含一个竞争锁的队列，和一个信号阻塞队列（wait队列），前者负责做互斥，后一个用于做线程同步。</p>
<p><strong>如果说轻量级锁是在无竞争的情况下使用CAS操作去消除同步使用的互斥量，那偏向锁就是在无竞争的情况下把整个同步都消除掉，连CAS都不做了。</strong></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/10/01/解决缓存数据库双写不一致/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Chen ZeTao">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/weixin.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="ddd `Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/10/01/解决缓存数据库双写不一致/" itemprop="url">解决缓存数据库双写不一致</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-10-01T17:19:51+08:00">
                2019-10-01
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  4.8k
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  16
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>在讲双写不一致的时候，先将为什么会发生双写不一致。<br>数据发生了变更，先删除了缓存，然后要去修改数据库，此时还没修改</p>
<p>一个请求过来，去读缓存，发现缓存空了，去查询数据库，查到了修改前的旧数据，放到了缓存中</p>
<p>数据变更的程序完成了数据库的修改</p>
<p>完了，数据库和缓存中的数据不一样了。。。。</p>
<p><strong>hash路由的算法，跟HashMap中的hash算法是一样的。</strong>    </p>
<ul>
<li>直接调用hashcode函数，求得的hash值过大，不适合拿来直接做下标，所以要通过将hash做一次扰动再跟已有的队列-1再取模。</li>
</ul>
<p>通过线程池 +内存队列+通过同个商品的ID路由到同一个队列中，将写请求，和读请求做到一个串行化的效果。只有当写请求完成之后，工作线程才会进行读请求的进行。</p>
<p>更新请求：删除缓存，修改数据库</p>
<p>读请求：读缓存，发现空，进入队列中等待，排到了则读数据库，并将数据写入缓存，返回数据</p>
<p>问题1：当写请求不断积压，读请求等待的时间过长，超过最大等待时间，会直接读数据库，造成双写不一致。</p>
<p>所以在这时候需要添加机器，分散队列的写请求服务。</p>
<p>少量情况下，可能遇到读跟数据更新冲突的情况，如上所述，那么此时更新操作如果先入队列，之后可能会瞬间来了对这个数据大量的读请求，但是因为做了去重的优化，所以也就一个更新缓存的操作跟在它后面</p>
<p>等数据更新完了，读请求触发的缓存更新操作也完成，然后临时等待的读请求全部可以读到缓存中的数据</p>
<p>问题2：大量的读请求在服务上等待。</p>
<p>当有大量的读请求时，此时若缓存为空，那么会通过去重，只让一个读请求进入队列中等待操作。</p>
<p>但可能发生，队列中的读操作还没完成，大量的读请求在服务中等待，造成服务宕机。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">进入队列后，读请求会有一个等待的时间，等待同步更新操作完成，这样的话，一个数据变更的操作，先执行，删除缓存，然后再去更新数据库，但是还没完成更新</span><br><span class="line"></span><br><span class="line">此时如果一个读请求过来，读到了空的缓存，那么可以先将缓存更新的请求发送到队列中，此时会在队列中积压，然后同步等待缓存更新完成</span><br><span class="line">这里有一个优化点，一个队列中，其实多个更新缓存请求串在一起是没意义的，因此可以做过滤，如果发现队列中已经有一个更新缓存的请求了，那么就不用再放个更新请求操作进去了，直接等待前面的更新操作请求完成即可</span><br><span class="line"></span><br><span class="line">待那个队列对应的工作线程完成了上一个操作的数据库的修改之后，才会去执行下一个操作，也就是缓存更新的操作，此时会从数据库中读取最新的值，然后写入缓存中</span><br><span class="line"></span><br><span class="line">如果请求还在等待时间范围内，不断轮询发现可以取到值了，那么就直接返回; 如果请求等待的时间超过一定时长，那么这一次直接从数据库中读取当前的旧值</span><br></pre></td></tr></table></figure>
<h3 id="高并发下的缓存与-数据库双写不一致问题分析与设计"><a href="#高并发下的缓存与-数据库双写不一致问题分析与设计" class="headerlink" title="高并发下的缓存与+数据库双写不一致问题分析与设计"></a>高并发下的缓存与+数据库双写不一致问题分析与设计</h3><p>马上开始去开发业务系统</p>
<p>从哪一步开始做，从比较简单的那一块开始做，实时性要求比较高的那块数据的缓存去做</p>
<p>实时性比较高的数据缓存，选择的就是库存的服务</p>
<p>库存可能会修改，每次修改都要去更新这个缓存数据; 每次库存的数据，在缓存中一旦过期，或者是被清理掉了，前端的nginx服务都会发送请求给库存服务，去获取相应的数据</p>
<p>库存这一块，写数据库的时候，直接更新redis缓存</p>
<p>实际上没有这么的简单，这里，其实就涉及到了一个问题，<strong>数据库与缓存双写，数据不一致的问题</strong></p>
<p>围绕和结合实时性较高的库存服务，把数据库与缓存双写不一致问题以及其解决方案，给大家讲解一下</p>
<p>数据库与缓存双写不一致，很常见的问题，大型的缓存架构中，第一个解决方案</p>
<p>大型的缓存架构全部讲解完了以后，整套架构是非常复杂，架构可以应对各种各样奇葩和极端的情况</p>
<p>也有一种可能，不是说，来讲课的就是超人，万能的</p>
<p>讲课，就跟写书一样，很可能会写错，也可能有些方案里的一些地方，我没考虑到</p>
<p>也可能说，有些方案只是适合某些场景，在某些场景下，可能需要你进行方案的优化和调整才能适用于你自己的项目</p>
<p>大家觉得对这些方案有什么疑问或者见解，都可以找我，沟通一下</p>
<p>如果的确我觉得是我讲解的不对，或者有些地方考虑不周，那么我可以在视频里补录，更新到网站上面去</p>
<p>多多包涵</p>
<p>1、最初级的缓存不一致问题以及解决方案</p>
<p>问题：先修改数据库，再删除缓存，如果删除缓存失败了，那么会导致数据库中是新数据，缓存中是旧数据，数据出现不一致</p>
<p>解决思路</p>
<p>先删除缓存，再修改数据库，如果删除缓存成功了，如果修改数据库失败了，那么数据库中是旧数据，缓存中是空的，那么数据不会不一致</p>
<p>因为读的时候缓存没有，则读数据库中旧数据，然后更新到缓存中</p>
<p>2、比较复杂的数据不一致问题分析</p>
<p>数据发生了变更，先删除了缓存，然后要去修改数据库，此时还没修改</p>
<p>一个请求过来，去读缓存，发现缓存空了，去查询数据库，查到了修改前的旧数据，放到了缓存中</p>
<p>数据变更的程序完成了数据库的修改</p>
<p>完了，数据库和缓存中的数据不一样了。。。。</p>
<p>3、为什么上亿流量高并发场景下，缓存会出现这个问题？</p>
<p>只有在对一个数据在并发的进行读写的时候，才可能会出现这种问题</p>
<p>其实如果说你的并发量很低的话，特别是读并发很低，每天访问量就1万次，那么很少的情况下，会出现刚才描述的那种不一致的场景</p>
<p>但是问题是，如果每天的是上亿的流量，每秒并发读是几万，每秒只要有数据更新的请求，就可能会出现上述的数据库+缓存不一致的情况</p>
<p>高并发了以后，问题是很多的</p>
<p><strong>4、数据库与缓存更新与读取操作进行异步串行化</strong></p>
<p>更新数据的时候，根据数据的唯一标识，将操作路由之后，发送到一个jvm内部的队列中</p>
<p>读取数据的时候，如果发现数据不在缓存中，那么将重新读取数据+更新缓存的操作，根据唯一标识路由之后，也发送同一个jvm内部的队列中</p>
<p>一个队列对应一个工作线程</p>
<p>每个工作线程串行拿到对应的操作，然后一条一条的执行</p>
<p>这样的话，一个数据变更的操作，先执行，删除缓存，然后再去更新数据库，但是还没完成更新</p>
<p>此时如果一个读请求过来，读到了空的缓存，那么可以先将缓存更新的请求发送到队列中，此时会在队列中积压，然后同步等待缓存更新完成</p>
<p>这里有一个优化点，一个队列中，其实多个更新缓存请求串在一起是没意义的，因此可以做过滤，如果发现队列中已经有一个更新缓存的请求了，那么就不用再放个更新请求操作进去了，直接等待前面的更新操作请求完成即可</p>
<p>待那个队列对应的工作线程完成了上一个操作的数据库的修改之后，才会去执行下一个操作，也就是缓存更新的操作，此时会从数据库中读取最新的值，然后写入缓存中</p>
<p>如果请求还在等待时间范围内，不断轮询发现可以取到值了，那么就直接返回; 如果请求等待的时间超过一定时长，那么这一次直接从数据库中读取当前的旧值</p>
<p>5、高并发的场景下，该解决方案要注意的问题</p>
<p><strong>（1）读请求长时阻塞</strong></p>
<p>由于读请求进行了非常轻度的异步化，所以一定要注意读超时的问题，每个读请求必须在超时时间范围内返回</p>
<p>该解决方案，最大的风险点在于说，可能数据更新很频繁，导致队列中积压了大量更新操作在里面，然后读请求会发生大量的超时，最后导致大量的请求直接走数据库</p>
<p>务必通过一些模拟真实的测试，看看更新数据的频繁是怎样的</p>
<p>另外一点，因为一个队列中，可能会积压针对多个数据项的更新操作，因此需要根据自己的业务情况进行测试，可能需要部署多个服务，每个服务分摊一些数据的更新操作</p>
<p>如果一个内存队列里居然会挤压100个商品的库存修改操作，每隔库存修改操作要耗费10ms区完成，那么最后一个商品的读请求，可能等待10 * 100 = 1000ms = 1s后，才能得到数据</p>
<p>这个时候就导致读请求的长时阻塞</p>
<p>一定要做根据实际业务系统的运行情况，去进行一些压力测试，和模拟线上环境，去看看最繁忙的时候，内存队列可能会挤压多少更新操作，可能会导致最后一个更新操作对应的读请求，会hang多少时间，如果读请求在200ms返回，如果你计算过后，哪怕是最繁忙的时候，积压10个更新操作，最多等待200ms，那还可以的</p>
<p>如果一个内存队列可能积压的更新操作特别多，那么你就要加机器，让每个机器上部署的服务实例处理更少的数据，那么每个内存队列中积压的更新操作就会越少</p>
<p>其实根据之前的项目经验，一般来说数据的写频率是很低的，因此实际上正常来说，在队列中积压的更新操作应该是很少的</p>
<p>针对读高并发，读缓存架构的项目，一般写请求相对读来说，是非常非常少的，每秒的QPS能到几百就不错了</p>
<p>一秒，500的写操作，5份，每200ms，就100个写操作</p>
<p>单机器，20个内存队列，每个内存队列，可能就积压5个写操作，每个写操作性能测试后，一般在20ms左右就完成</p>
<p>那么针对每个内存队列中的数据的读请求，也就最多hang一会儿，200ms以内肯定能返回了</p>
<p>写QPS扩大10倍，但是经过刚才的测算，就知道，单机支撑写QPS几百没问题，那么就扩容机器，扩容10倍的机器，10台机器，每个机器20个队列，200个队列</p>
<p>大部分的情况下，应该是这样的，大量的读请求过来，都是直接走缓存取到数据的</p>
<p>少量情况下，可能遇到读跟数据更新冲突的情况，如上所述，那么此时更新操作如果先入队列，之后可能会瞬间来了对这个数据大量的读请求，但是因为做了去重的优化，所以也就一个更新缓存的操作跟在它后面</p>
<p>等数据更新完了，读请求触发的缓存更新操作也完成，然后临时等待的读请求全部可以读到缓存中的数据</p>
<p>（2）读请求并发量过高</p>
<p>这里还必须做好压力测试，确保恰巧碰上上述情况的时候，还有一个风险，就是突然间大量读请求会在几十毫秒的延时hang在服务上，看服务能不能抗的住，需要多少机器才能抗住最大的极限情况的峰值</p>
<p>但是因为并不是所有的数据都在同一时间更新，缓存也不会同一时间失效，所以每次可能也就是少数数据的缓存失效了，然后那些数据对应的读请求过来，并发量应该也不会特别大</p>
<p>按1:99的比例计算读和写的请求，每秒5万的读QPS，可能只有500次更新操作</p>
<p>如果一秒有500的写QPS，那么要测算好，可能写操作影响的数据有500条，这500条数据在缓存中失效后，可能导致多少读请求，发送读请求到库存服务来，要求更新缓存</p>
<p>一般来说，1:1，1:2，1:3，每秒钟有1000个读请求，会hang在库存服务上，每个读请求最多hang多少时间，200ms就会返回</p>
<p>在同一时间最多hang住的可能也就是单机200个读请求，同时hang住</p>
<p>单机hang200个读请求，还是ok的</p>
<p>1:20，每秒更新500条数据，这500秒数据对应的读请求，会有20 * 500 = 1万</p>
<p>1万个读请求全部hang在库存服务上，就死定了</p>
<p>（3）多服务实例部署的请求路由</p>
<p>可能这个服务部署了多个实例，那么必须保证说，执行数据更新操作，以及执行缓存更新操作的请求，都通过nginx服务器路由到相同的服务实例上</p>
<p>（4）热点商品的路由问题，导致请求的倾斜</p>
<p>万一某个商品的读写请求特别高，全部打到相同的机器的相同的队列里面去了，可能造成某台机器的压力过大</p>
<p>就是说，因为只有在商品数据更新的时候才会清空缓存，然后才会导致读写并发，所以更新频率不是太高的话，这个问题的影响并不是特别大</p>
<p>但是的确可能某些机器的负载会高一些</p>
<h3 id="在库存服务中实现缓存与数据库双写一致性保障方案"><a href="#在库存服务中实现缓存与数据库双写一致性保障方案" class="headerlink" title="在库存服务中实现缓存与数据库双写一致性保障方案"></a>在库存服务中实现缓存与数据库双写一致性保障方案</h3><p>更新数据的时候，根据数据的唯一标识，将操作路由之后，发送到一个jvm内部的队列中</p>
<p>读取数据的时候，如果发现数据 不在缓存中，那么将重新读取数据+更新缓存的操作，根据唯一标识路由之后，也发送同一个jvm内部的队列中</p>
<p>一个队列对应一个工作线程</p>
<p>每个工作线程串行拿到对应的操作，然后一条一条的执行</p>
<p>这样的话，一个数据变更的操作，先执行，删除缓存，然后再去更新数据库，但是还没完成更新</p>
<p>此时如果一个读请求过来，读到了空的缓存，那么可以先将缓存更新的请求发送到队列中，此时会在队列中积压，然后同步等待缓存更新完成</p>
<p>这里有一个优化点，一个队列中，其实多个更新缓存请求串在一起是没意义的，因此可以做过滤，如果发现队列中已经有一个更新缓存的请求了，那么就不用再放个更新请求操作进去了，直接等待前面的更新操作请求完成即可</p>
<p>待那个队列对应的工作线程完成了上一个操作的数据库的修改之后，才会去执行下一个操作，也就是缓存更新的操作，此时会从数据库中读取最新的值，然后写入缓存中</p>
<p>如果请求还在等待时间范围内，不断轮询发现可以取到值了，那么就直接返回; 如果请求等待的时间超过一定时长，那么这一次直接从数据库中读取当前的旧值</p>
<p>int h;<br>return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16);</p>
<p>(queueNum - 1) &amp; hash</p>
<p>1、线程池+内存队列 化</p>
<p>@Bean<br>public ServletListenerRegistrationBean servletListenerRegistrationBean(){<br>    ServletListenerRegistrationBean servletListenerRegistrationBean = new ServletListenerRegistrationBean();<br>    servletListenerRegistrationBean.setListener(new InitListener());<br>    return servletListenerRegistrationBean;<br>}</p>
<p>java web应用，做系统的初始化，一般在哪里做呢？</p>
<p>ServletContextListener里面做，listener，会跟着整个web应用的启动，就初始化，类似于线程池初始化的构建</p>
<p><strong>使用单例初始化线程池，基于静态内部类（静态代码块）初始化线程池的方式，</strong></p>
<p>spring boot应用，Application，搞一个listener的注册</p>
<p>2、两种请求对象封装</p>
<p>3、请求异步执行Service封装</p>
<p>4、两种请求Controller接口封装</p>
<p>5、读请求去重优化</p>
<p>6、空数据读请求过滤优化</p>
<p>队列</p>
<p>对一个商品的库存的数据库更新操作已经在内存队列中了</p>
<p>然后对这个商品的库存的读取操作，要求读取数据库的库存数据，然后更新到缓存中，多个读</p>
<p>这多个读，其实只要有一个读请求操作压到队列里就可以了</p>
<p>其他的读操作，全部都wait那个读请求的操作，刷新缓存，就可以读到缓存中的最新数据了</p>
<p>如果读请求发现redis缓存中没有数据，就会发送读请求给库存服务，但是此时缓存中为空，可能是因为写请求先删除了缓存，也可能是数据库里压根儿没这条数据</p>
<p>如果是数据库中压根儿没这条数据的场景，那么就不应该将读请求操作给压入队列中，而是直接返回空就可以了</p>
<p>都是为了减少内存队列中的请求积压，内存队列中积压的请求越多，就可能导致每个读请求hang住的时间越长，也可能导致多个读请求被hang住</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/09/29/扩展/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Chen ZeTao">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/weixin.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="ddd `Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/09/29/扩展/" itemprop="url">扩展</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-09-29T20:07:54+08:00">
                2019-09-29
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  3.1k
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  11
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="9-28"><a href="#9-28" class="headerlink" title="9.28"></a>9.28</h1><p>在订单详情部分实现多缓存处理</p>
<p>redis 分布式缓存 +  tomcat 堆缓存 二级缓存架构</p>
<h4 id="redis搭建方案"><a href="#redis搭建方案" class="headerlink" title="redis搭建方案"></a>redis搭建方案</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">redis持久化+备份方案+容灾方案+replication（主从+读写分离）+sentinal（哨兵集群，3个节点，高可用性）</span><br><span class="line"></span><br><span class="line">可以支撑的数据量在10G以内，可以支撑的写QPS在几万左右，可以支撑的读QPS可以上10万以上（随你的需求，水平扩容slave节点就可以），可用性在99.99%</span><br><span class="line">可以用公司里的一些已有的数据，导入进去，几百万，一千万，进去</span><br><span class="line"></span><br><span class="line">做各种压力测试，性能，redis-benchmark，并发，QPS，高可用的演练，每台机器最大能存储多少数据量，横向扩容支撑更多数据</span><br><span class="line"></span><br><span class="line">基于测试环境还有测试数据，做各种演练，去摸索一些最适合自己的一些细节的东西</span><br></pre></td></tr></table></figure>
<p>如果页面的数据有变更，及时监听到，并且写入缓存中，提供高并发，高性能的访问</p>
<p>前端请求，请求服务器，先从redis中拿，redis中没有，本地搭建ehcache没有，再调用商品服务，从数据库中拿</p>
<p>企业级的大型缓存架构</p>
<h3 id="保证数据库与缓存的双写一致性"><a href="#保证数据库与缓存的双写一致性" class="headerlink" title="保证数据库与缓存的双写一致性"></a>保证数据库与缓存的双写一致性</h3><h3 id="分布式缓存重建问题，使用分布式锁实现"><a href="#分布式缓存重建问题，使用分布式锁实现" class="headerlink" title="分布式缓存重建问题，使用分布式锁实现"></a>分布式缓存重建问题，使用分布式锁实现</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">详细在文章关于zookeeper搭建分布式锁中</span><br></pre></td></tr></table></figure>
<h4 id="服务本地堆缓存，避免数据库直接裸奔"><a href="#服务本地堆缓存，避免数据库直接裸奔" class="headerlink" title="服务本地堆缓存，避免数据库直接裸奔"></a>服务本地堆缓存，避免数据库直接裸奔</h4><p>因为之前跟大家提过，三级缓存，多级缓存，服务本地堆缓存 + redis分布式缓存 + nginx本地缓存组成的</p>
<p>每一层缓存在高并发的场景下，都有其特殊的用途，需要综合利用多级的缓存，才能支撑住高并发场景下各种各样的特殊情况</p>
<p>服务本地堆缓存，作用，预防redis层的彻底崩溃，作为缓存的最后一道防线，避免数据库直接裸奔</p>
<p>服务本地堆缓存，我们用什么来做缓存，难道我们自己手写一个类或者程序去管理内存吗？？？java最流行的缓存的框架，ehcache</p>
<p>所以我们也是用ehcache来做本地的堆缓存</p>
<p>spring boot + ehcache整合起来，演示一下是怎么使用的</p>
<p>spring boot整合ehcache</p>
<p>（1）依赖</p>
<dependency><br>  <groupid>org.springframework.boot</groupid><br>  <artifactid>spring-boot-starter-data-jpa</artifactid><br></dependency><br><dependency><br>  <groupid>org.springframework</groupid><br>  <artifactid>spring-context-support</artifactid><br></dependency><br><dependency><br>  <groupid>net.sf.ehcache</groupid><br>  <artifactid>ehcache</artifactid><br>  <version>2.8.3</version><br></dependency>

<p>（2）缓存配置管理类</p>
<p>@Configuration<br>@EnableCaching<br>public class CacheConfiguration {</p>
<pre><code>@Bean
public EhCacheManagerFactoryBean ehCacheManagerFactoryBean(){
  EhCacheManagerFactoryBean cacheManagerFactoryBean = new EhCacheManagerFactoryBean();
  cacheManagerFactoryBean.setConfigLocation(new ClassPathResource(&quot;ehcache.xml&quot;));
  cacheManagerFactoryBean.setShared(true);
  return cacheManagerFactoryBean;
}

@Bean
public EhCacheCacheManager ehCacheCacheManager(EhCacheManagerFactoryBean bean){
  return new EhCacheCacheManager(bean.getObject());
}
</code></pre><p>}</p>
<p>（3）ehcache.xml</p>
<p>&lt;?xml version=”1.0” encoding=”UTF-8”?&gt;</p>
<ehcache xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:nonamespaceschemalocation="http://ehcache.org/ehcache.xsd" updatecheck="false"><br><br>    <diskstore path="java.io.tmpdir/Tmp_EhCache"><br><br>    <defaultcache eternal="false" maxelementsinmemory="1000" overflowtodisk="false" diskpersistent="false" timetoidleseconds="0" timetoliveseconds="0" memorystoreevictionpolicy="LRU"><br><br>    <cache name="local" eternal="false" maxelementsinmemory="1000" overflowtodisk="false" diskpersistent="false" timetoidleseconds="0" timetoliveseconds="0" memorystoreevictionpolicy="LRU"><br><br></cache></defaultcache></diskstore></ehcache>

<p>（4）CacheService</p>
<p>@Service(“cacheService”)<br>public class CacheServiceImpl implements CacheService {</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> String CACHE_NAME = <span class="string">"local"</span>;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Cacheable</span>(value = CACHE_NAME, key = <span class="string">"'key_'+#id"</span>)</span><br><span class="line"><span class="function"><span class="keyword">public</span> ProductInfo <span class="title">findById</span><span class="params">(Long id)</span></span>&#123;</span><br><span class="line">   <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">&#125;</span><br><span class="line">   </span><br><span class="line"><span class="meta">@CachePut</span>(value = CACHE_NAME, key = <span class="string">"'key_'+#productInfo.getId()"</span>)</span><br><span class="line"><span class="function"><span class="keyword">public</span> ProductInfo <span class="title">saveProductInfo</span><span class="params">(ProductInfo productInfo)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">return</span> productInfo;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>}</p>
<p>（5）写一个Controller测试一下ehcache的整合</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="meta">@Controller</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CacheTestController</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="meta">@Resource</span></span><br><span class="line">  <span class="keyword">private</span> CacheService cacheService;</span><br><span class="line"></span><br><span class="line">  <span class="meta">@RequestMapping</span>(<span class="string">"/testPutCache"</span>)</span><br><span class="line">  <span class="meta">@ResponseBody</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">testPutCache</span><span class="params">(ProductInfo productInfo)</span> </span>&#123;</span><br><span class="line">    System.out.println(productInfo.getId() + <span class="string">":"</span> + productInfo.getName());  </span><br><span class="line">    cacheService.saveProductInfo(productInfo);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="meta">@RequestMapping</span>(<span class="string">"/testGetCache"</span>)</span><br><span class="line">  <span class="meta">@ResponseBody</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> ProductInfo <span class="title">testGetCache</span><span class="params">(Long id)</span> </span>&#123;</span><br><span class="line">    ProductInfo productInfo = cacheService.findById(id);</span><br><span class="line">    System.out.println(productInfo.getId() + <span class="string">":"</span> + productInfo.getName()); </span><br><span class="line">    <span class="keyword">return</span> productInfo;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>ehcache已经整合进了我们的系统，spring boot</p>
<p>封装好了对ehcache本地缓存进行添加和获取的方法和service</p>
<p>小程序写入操作，防止并发中，HashMap的使用，改成使用ConcurrentHashMap</p>
<h1 id="10-1"><a href="#10-1" class="headerlink" title="10.1"></a>10.1</h1><h3 id="商品详情页的多级缓存架构"><a href="#商品详情页的多级缓存架构" class="headerlink" title="商品详情页的多级缓存架构"></a>商品详情页的多级缓存架构</h3><p>我们之前的三十讲，主要是在讲解redis如何支撑海量数据、高并发读写、高可用服务的架构，redis架构</p>
<p>redis架构，在我们的真正类似商品详情页读高并发的系统中，redis就是底层的缓存存储的支持</p>
<p>从这一讲开始，我们正式开始做业务系统的开发</p>
<p>亿级流量以上的电商网站的商品详情页的系统，商品详情页系统，大量的业务，十几个人做一两年，堆出来复杂的业务系统</p>
<p>几十个小时的课程，讲解复杂的业务</p>
<p>把整体的架构给大家讲解清楚，然后浓缩和精炼里面的业务，提取部分业务，做一些简化，把整个详情页系统的流程跑出来</p>
<p>架构，骨架，有少量的业务，血和肉，把整个项目串起来，在业务背景下，去学习架构</p>
<p>讲解商品详情页系统，缓存架构，90%大量的业务代码（没有什么技术含量），10%的最优技术含量的就是架构，上亿流量，每秒QPS几万，上十万的，读并发</p>
<p>读并发，缓存架构</p>
<p>1、上亿流量的商品详情页系统的多级缓存架构</p>
<p>很多人以为，做个缓存，其实就是用一下redis，访问一下，就可以了，简单的缓存</p>
<p>做复杂的缓存，支撑电商复杂的场景下的高并发的缓存，遇到的问题，非常非常之多，绝对不是说简单的访问一下redsi就可以了</p>
<p>采用三级缓存：nginx本地缓存+redis分布式缓存+tomcat堆缓存的多级缓存架构</p>
<p>时效性要求非常高的数据：库存</p>
<p>一般来说，显示的库存，都是时效性要求会相对高一些，因为随着商品的不断的交易，库存会不断的变化</p>
<p>当然，我们就希望当库存变化的时候，尽可能更快将库存显示到页面上去，而不是说等了很长时间，库存才反应到页面上去</p>
<p>时效性要求不高的数据：商品的基本信息（名称、颜色、版本、规格参数，等等）</p>
<p>时效性要求不高的数据，就还好，比如说你现在改变了商品的名称，稍微晚个几分钟反应到商品页面上，也还能接受</p>
<p>商品价格/库存等时效性要求高的数据，而且种类较少，采取相关的服务系统每次发生了变更的时候，直接采取数据库和redis缓存双写的方案，这样缓存的时效性最高</p>
<p>商品基本信息等时效性不高的数据，而且种类繁多，来自多种不同的系统，采取MQ异步通知的方式，写一个数据生产服务，监听MQ消息，然后异步拉取服务的数据，更新tomcat jvm缓存+redis缓存</p>
<p>nginx+lua脚本做页面动态生成的工作，每次请求过来，优先从nginx本地缓存中提取各种数据，结合页面模板，生成需要的页面</p>
<p>如果nginx本地缓存过期了，那么就从nginx到redis中去拉取数据，更新到nginx本地</p>
<p>如果redis中也被LRU算法清理掉了，那么就从nginx走http接口到后端的服务中拉取数据，数据生产服务中，现在本地tomcat里的jvm堆缓存中找，ehcache，如果也被LRU清理掉了，那么就重新发送请求到源头的服务中去拉取数据，然后再次更新tomcat堆内存缓存+redis缓存，并返回数据给nginx，nginx缓存到本地</p>
<p>2、多级缓存架构中每一层的意义</p>
<p>nginx本地缓存，抗的是热数据的高并发访问，一般来说，商品的购买总是有热点的，比如每天购买iphone、nike、海尔等知名品牌的东西的人，总是比较多的</p>
<p>这些热数据，利用nginx本地缓存，由于经常被访问，所以可以被锁定在nginx的本地缓存内</p>
<p>大量的热数据的访问，就是经常会访问的那些数据，就会被保留在nginx本地缓存内，那么对这些热数据的大量访问，就直接走nginx就可以了</p>
<p>那么大量的访问，直接就可以走到nginx就行了，不需要走后续的各种网络开销了</p>
<p>redis分布式大规模缓存，抗的是很高的离散访问，支撑海量的数据，高并发的访问，高可用的服务</p>
<p>redis缓存最大量的数据，最完整的数据和缓存，1T+数据; 支撑高并发的访问，QPS最高到几十万; 可用性，非常好，提供非常稳定的服务</p>
<p>nginx本地内存有限，也就能cache住部分热数据，除了各种iphone、nike等热数据，其他相对不那么热的数据，可能流量会经常走到redis那里</p>
<p>利用redis cluster的多master写入，横向扩容，1T+以上海量数据支持，几十万的读写QPS，99.99%高可用性，那么就可以抗住大量的离散访问请求</p>
<p>tomcat jvm堆内存缓存，主要是抗redis大规模灾难的，如果redis出现了大规模的宕机，导致nginx大量流量直接涌入数据生产服务，那么最后的tomcat堆内存缓存至少可以再抗一下，不至于让数据库直接裸奔</p>
<p>同时tomcat jvm堆内存缓存，也可以抗住redis没有cache住的最后那少量的部分缓存</p>
<h3 id="Cache-Aside-Pattern缓存-数据库读写模式的分析"><a href="#Cache-Aside-Pattern缓存-数据库读写模式的分析" class="headerlink" title="Cache Aside Pattern缓存 + 数据库读写模式的分析"></a>Cache Aside Pattern缓存 + 数据库读写模式的分析</h3><p>最经典的缓存+数据库读写的模式，cache aside pattern</p>
<p>1、Cache Aside Pattern</p>
<p>（1）读的时候，先读缓存，缓存没有的话，那么就读数据库，然后取出数据后放入缓存，同时返回响应</p>
<p>（2）更新的时候，先删除缓存，然后再更新数据库</p>
<p>2、为什么是删除缓存，而不是更新缓存呢？</p>
<p>原因很简单，很多时候，复杂点的缓存的场景，因为缓存有的时候，不简单是数据库中直接取出来的值</p>
<p>商品详情页的系统，修改库存，只是修改了某个表的某些字段，但是要真正把这个影响的最终的库存计算出来，可能还需要从其他表查询一些数据，然后进行一些复杂的运算，才能最终计算出</p>
<p>现在最新的库存是多少，然后才能将库存更新到缓存中去</p>
<p>比如可能更新了某个表的一个字段，然后其对应的缓存，是需要查询另外两个表的数据，并进行运算，才能计算出缓存最新的值的</p>
<p>更新缓存的代价是很高的</p>
<p>是不是说，每次修改数据库的时候，都一定要将其对应的缓存去跟新一份？也许有的场景是这样的，但是对于比较复杂的缓存数据计算的场景，就不是这样了</p>
<p>如果你频繁修改一个缓存涉及的多个表，那么这个缓存会被频繁的更新，频繁的更新缓存</p>
<p>但是问题在于，这个缓存到底会不会被频繁访问到？？？</p>
<p>举个例子，一个缓存涉及的表的字段，在1分钟内就修改了20次，或者是100次，那么缓存跟新20次，100次; 但是这个缓存在1分钟内就被读取了1次，有大量的冷数据</p>
<p>28法则，黄金法则，20%的数据，占用了80%的访问量</p>
<p>实际上，如果你只是删除缓存的话，那么1分钟内，这个缓存不过就重新计算一次而已，开销大幅度降低</p>
<p>每次数据过来，就只是删除缓存，然后修改数据库，如果这个缓存，在1分钟内只是被访问了1次，那么只有那1次，缓存是要被重新计算的，用缓存才去算缓存</p>
<p>其实删除缓存，而不是更新缓存，就是一个lazy计算的思想，不要每次都重新做复杂的计算，不管它会不会用到，而是让它到需要被使用的时候再重新计算</p>
<p>mybatis，hibernate，懒加载，思想</p>
<p>查询一个部门，部门带了一个员工的list，没有必要说每次查询部门，都里面的1000个员工的数据也同时查出来啊</p>
<p>80%的情况，查这个部门，就只是要访问这个部门的信息就可以了</p>
<p>先查部门，同时要访问里面的员工，那么这个时候只有在你要访问里面的员工的时候，才会去数据库里面查询1000个员工</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/09/28/网络零散知识/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Chen ZeTao">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/weixin.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="ddd `Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/09/28/网络零散知识/" itemprop="url">网络零散知识</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-09-28T09:57:00+08:00">
                2019-09-28
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/计算机网络/" itemprop="url" rel="index">
                    <span itemprop="name">计算机网络</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  1.5k
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  5
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="TCP和UDP的区别"><a href="#TCP和UDP的区别" class="headerlink" title="TCP和UDP的区别"></a>TCP和UDP的区别</h2><p>（1）TCP是面向连接的，udp是无连接的即发送数据前不需要先建立链接。</p>
<p>（2）TCP提供可靠的服务。也就是说，通过TCP连接传送的数据，无差错，不丢失，不重复，且按序到达;UDP尽最大努力交付，即不保证可靠交付。 并且因为tcp可靠，面向连接，不会丢失数据因此适合大数据量的交换。</p>
<p>（3）TCP是面向字节流，UDP面向报文，并且网络出现拥塞不会使得发送速率降低（因此会出现丢包，对实时的应用比如IP电话和视频会议等）。</p>
<p>（4）TCP只能是1对1的，UDP支持1对1,1对多。</p>
<p>（5）TCP的首部较大为20字节，而UDP只有8字节。</p>
<p>（6）TCP是面向连接的可靠性传输，而UDP是不可靠的。</p>
<ul>
<li>基于TCP的应用层协议有：POP3、SMTP（简单邮件传输协议）、TELNET（远程登陆协议）、HTTP（超文本传输协议）、HTTPS（超文本传输安全协议）、FTP（文件传输协议）</li>
<li>基于UDP的应用层协议：TFTP（简单文件传输协议）、RIP（路由信息协议）、DHCP（动态主机设置协议）、BOOTP（引导程序协议，DHCP的前身）、IGMP（Internet组管理协议）</li>
<li>基于TCP和UDP协议：DNS（域名系统）、ECHO（回绕协议）</li>
</ul>
<p>以下内容来自：公众号 前端指南，作者 前端指南</p>
<h2 id="简述-http-1-1-与-http-1-0-的区别"><a href="#简述-http-1-1-与-http-1-0-的区别" class="headerlink" title="简述 http 1.1 与 http 1.0 的区别"></a>简述 http 1.1 与 http 1.0 的区别</h2><ul>
<li>http 1.0 对于每个连接都得建立一次连接, 一次只能传送一个请求和响应, 请求就会关闭, http1.0 没有 Host 字段</li>
<li>而 http1.1 在同一个连接中可以传送多个请求和响应, 多个请求可以重叠和同时进行, http1.1 必须有 host 字段</li>
<li>http1.1 中引入了 ETag 头, 它的值 entity tag 可以用来唯一的描述一个资源. 请求消息中可以使用 If-None-Match 头域来匹配资源的 entitytag 是否有变化</li>
<li>http1.1 新增了 Cache-Control 头域(消息请求和响应请求都可以使用), 它支持一个可扩展的指令子集</li>
<li>http1.0 中只定义了 16 个状态响应码, 对错误或警告的提示不够具体. http1.1 引入了一个 Warning 头域, 增加对错误或警告信息的描述. 且新增了 24 个状态响应码</li>
</ul>
<h2 id="从输入-URL-到页面加载发生了什么-必考"><a href="#从输入-URL-到页面加载发生了什么-必考" class="headerlink" title="从输入 URL 到页面加载发生了什么[必考]"></a>从输入 URL 到页面加载发生了什么[必考]</h2><p>总体来说分为以下几个过程:</p>
<ul>
<li>DNS 解析</li>
<li>TCP 连接</li>
<li>发送 HTTP 请求</li>
<li>服务器处理请求并返回 HTTP 报文</li>
<li>浏览器解析渲染页面</li>
<li>连接结束</li>
</ul>
<h2 id="Socket-连接与-HTTP-连接的联系与区别"><a href="#Socket-连接与-HTTP-连接的联系与区别" class="headerlink" title="Socket 连接与 HTTP 连接的联系与区别"></a>Socket 连接与 HTTP 连接的联系与区别</h2><p>由于通常情况下 Socket 连接就是 TCP 连接，因此 Socket 连接一旦建立，通信双方即可开始相互发送数据内容，直到双方连接断开。但在实际网络应用中，客户端到服务器之间的通信往往需要穿越多个中间节点，例如路由器、网关、防火墙等，大部分防火墙默认会关闭长时间处于非活跃状态的连接而导致 Socket 连接断连，因此需要通过轮询告诉网络，该连接处于活跃状态。</p>
<p>而 HTTP 连接使用的是“请求—响应”的方式，不仅在请求时需要先建立连接，而且需要客户端向服务器发出请求后，服务器端才能回复数据。</p>
<p>很多情况下，需要服务器端主动向客户端推送数据，保持客户端与服务器数据的实时与同步。此时若双方建立的是 Socket 连接，服务器就可以直接将数据传送给客户端;若双方建立的是 HTTP 连接，则服务器需要等到客户端发送一次请求后才能将数据传回给客户端，因此，客户端定时向服务器端发送连接请求，不仅可以保持在线，同时也是在“询问”服务器是否有新的数据，如果有就将数据传给客户端。</p>
<h2 id="Http2-0-与-http1-x-相比有什么优点-常考"><a href="#Http2-0-与-http1-x-相比有什么优点-常考" class="headerlink" title="Http2.0 与 http1.x 相比有什么优点(常考)"></a>Http2.0 与 http1.x 相比有什么优点(常考)</h2><ul>
<li>二进制格式:http1.x 是文本协议，而 http2.0 是二进制以帧为基本单位，是一个二进制协议，一帧中除了包含数据外同时还包含该帧的标识：Stream Identifier，即标识了该帧属于哪个 request,使得网络传输变得十分灵活。</li>
<li>多路复用: 一个很大的改进，原先 http1.x 一个连接一个请求的情况有比较大的局限性，也引发了很多问题，如建立多个连接的消耗以及效率问题。</li>
<li><ul>
<li>http1.x 为了解决效率问题，可能会尽量多的发起并发的请求去加载资源，然而浏览器对于同一域名下的并发请求有限制，而优化的手段一般是将请求的资源放到不同的域名下来突破这种限制。</li>
<li>而 http2.0 支持的多路复用可以很好的解决这个问题，多个请求共用一个 TCP 连接，多个请求可以同时在这个 TCP 连接上并发，一个是解决了建立多个 TCP 连接的消耗问题，一个也解决了效率的问题。那么是什么原理支撑多个请求可以在一个 TCP 连接上并发呢？基本原理就是上面的二进制分帧，因为每一帧都有一个身份标识，所以多个请求的不同帧可以并发的无序发送出去，在服务端会根据每一帧的身份标识，将其整理到对应的 request 中。</li>
</ul>
</li>
<li>header 头部压缩:主要是通过压缩 header 来减少请求的大小，减少流量消耗，提高效率。因为之前存在一个问题是，每次请求都要带上 header，而这个 header 中的数据通常是一层不变的。</li>
<li>支持服务端推送</li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/09/26/查漏补缺/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Chen ZeTao">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/weixin.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="ddd `Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/09/26/查漏补缺/" itemprop="url">查漏补缺</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-09-26T15:35:49+08:00">
                2019-09-26
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  9.4k
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  33
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p><strong>自19.09.26开始，对复习的知识遗漏点进行总结</strong></p>
<h2 id="19-09-26"><a href="#19-09-26" class="headerlink" title="19.09.26"></a>19.09.26</h2><h1 id="JAVA锁"><a href="#JAVA锁" class="headerlink" title="JAVA锁"></a>JAVA锁</h1><p>Java SE1.6为了减少获得锁和释放锁所带来的性能消耗，引入了“偏向锁”和“轻量级锁”，所以在Java SE1.6里锁一共有四种状态，无锁状态，偏向锁状态，轻量级锁状态和重量级锁状态，它会随着竞争情况逐渐升级。<strong>锁可以升级但不能降级，意味着偏向锁升级成轻量级锁后不能降级成偏向锁。这种锁升级却不能降级的策略，目的是为了提高获得锁和释放锁的效率。</strong></p>
<h3 id="悲观锁与乐观锁"><a href="#悲观锁与乐观锁" class="headerlink" title="悲观锁与乐观锁"></a>悲观锁与乐观锁</h3><h4 id="悲观锁"><a href="#悲观锁" class="headerlink" title="悲观锁"></a>悲观锁</h4><p>总是假设最坏的情况，每次去拿数据的时候都认为别人会修改，所以每次在拿数据的时候都会上锁。传统的关系型数据库里边就用到了很多这种锁机制，比如行锁，表锁，读锁，写锁等，都是在做操作之前先上锁。JAVA中synchronize和ReentrantLock等独占锁就是悲观锁思想的实现。</p>
<h4 id="乐观锁"><a href="#乐观锁" class="headerlink" title="乐观锁"></a>乐观锁</h4><p>总是假设最好的情况，每次拿数据都认为别人不会修改，所以不会上锁。<strong>但是在更新的时候会判断一下在此期间别人有没有去更新这个数据，可以使用版本号机制和CAS算法实现。</strong></p>
<p>乐观锁适用于多读的应用类型，这样可以提高吞吐量。</p>
<p><strong>java中的4种锁，分别是重量级锁，自旋锁，轻量级锁和偏向锁。重量级锁是悲观锁的一种，自旋锁，轻量级锁和偏向锁属于乐观锁。</strong></p>
<h5 id="乐观锁常见的两种实现方式"><a href="#乐观锁常见的两种实现方式" class="headerlink" title="乐观锁常见的两种实现方式"></a>乐观锁常见的两种实现方式</h5><blockquote>
<p><strong>乐观锁一般会使用版本号机制或CAS算法实现。</strong></p>
</blockquote>
<h4 id="1-版本号机制"><a href="#1-版本号机制" class="headerlink" title="1. 版本号机制"></a>1. 版本号机制</h4><p>一般是在数据表中加上一个数据版本号version字段，表示数据被修改的次数，当数据被修改时，version值会加一。当线程A要更新数据值时，在读取数据的同时也会读取version值，在提交更新时，若刚才读取到的version值为当前数据库中的version值相等时才更新，否则重试更新操作，直到更新成功。</p>
<p><strong>举一个简单的例子：</strong> 假设数据库中帐户信息表中有一个 version 字段，当前值为 1 ；而当前帐户余额字段（ balance ）为 $100 。</p>
<ol>
<li>操作员 A 此时将其读出（ version=1 ），并从其帐户余额中扣除 $50（ $100-$50 ）。</li>
<li>在操作员 A 操作的过程中，操作员B 也读入此用户信息（ version=1 ），并从其帐户余额中扣除 $20 （ $100-$20 ）。</li>
<li>操作员 A 完成了修改工作，将数据版本号加一（ version=2 ），连同帐户扣除后余额（ balance=$50 ），提交至数据库更新，此时由于提交数据版本大于数据库记录当前版本，数据被更新，数据库记录 version 更新为 2 。</li>
<li>操作员 B 完成了操作，也将版本号加一（ version=2 ）试图向数据库提交数据（ balance=$80 ），但此时比对数据库记录版本时发现，操作员 B 提交的数据版本号为 2 ，数据库记录当前版本也为 2 ，不满足 “ 提交版本必须大于记录当前版本才能执行更新 “ 的乐观锁策略，因此，操作员 B 的提交被驳回。</li>
</ol>
<p>这样，就避免了操作员 B 用基于 version=1 的旧数据修改的结果覆盖操作员A 的操作结果的可能。</p>
<h4 id="2-简单回顾一下CAS算法"><a href="#2-简单回顾一下CAS算法" class="headerlink" title="2.简单回顾一下CAS算法"></a>2.简单回顾一下CAS算法</h4><p><strong>CAS算法</strong> 即compare and swap（比较与交换），是一种有名的无锁算法。无锁编程，即不使用锁的情况下实现多线程之间的变量同步，也就是在没有线程被阻塞的情况下实现变量的同步，所以也叫非阻塞同步（Non-blocking Synchronization）。CAS算法涉及到三个操作数</p>
<ul>
<li>需要读写的内存值 V</li>
<li>进行比较的值 A</li>
<li>拟写入的新值 B</li>
</ul>
<p>当且仅当 V 的值等于 A时，CAS通过原子方式用新值B来更新V的值，否则不会执行任何操作（比较和替换是一个原子操作）。一般情况下是一个自旋操作，即不断的重试。</p>
<h3 id="乐观锁的缺点"><a href="#乐观锁的缺点" class="headerlink" title="乐观锁的缺点"></a>乐观锁的缺点</h3><blockquote>
<p>ABA 问题是乐观锁一个常见的问题</p>
</blockquote>
<h4 id="1-ABA-问题"><a href="#1-ABA-问题" class="headerlink" title="1 ABA 问题"></a>1 ABA 问题</h4><p>如果一个变量V初次读取的时候是A值，并且在准备赋值的时候检查到它仍然是A值，那我们就能说明它的值没有被其他线程修改过了吗？很明显是不能的，因为在这段时间它的值可能被改为其他值，然后又改回A，那CAS操作就会误认为它从来没有被修改过。这个问题被称为CAS操作的 <strong>“ABA”问题。</strong></p>
<p>JDK 1.5 以后的 <code>AtomicStampedReference 类</code>就提供了此种能力，其中的 <code>compareAndSet 方法</code>就是首先检查当前引用是否等于预期引用，并且当前标志是否等于预期标志，如果全部相等，则以原子方式将该引用和该标志的值设置为给定的更新值。</p>
<h4 id="2-循环时间长开销大"><a href="#2-循环时间长开销大" class="headerlink" title="2 循环时间长开销大"></a>2 循环时间长开销大</h4><p><strong>自旋CAS（也就是不成功就一直循环执行直到成功）如果长时间不成功，会给CPU带来非常大的执行开销。</strong> 如果JVM能支持处理器提供的pause指令那么效率会有一定的提升，pause指令有两个作用，第一它可以延迟流水线执行指令（de-pipeline）,使CPU不会消耗过多的执行资源，延迟的时间取决于具体实现的版本，在一些处理器上延迟时间是零。第二它可以避免在退出循环的时候因内存顺序冲突（memory order violation）而引起CPU流水线被清空（CPU pipeline flush），从而提高CPU的执行效率。</p>
<h4 id="3-只能保证一个共享变量的原子操作"><a href="#3-只能保证一个共享变量的原子操作" class="headerlink" title="3 只能保证一个共享变量的原子操作"></a>3 只能保证一个共享变量的原子操作</h4><p>CAS 只对单个共享变量有效，当操作涉及跨多个共享变量时 CAS 无效。但是从 JDK 1.5开始，提供了<code>AtomicReference类</code>来保证引用对象之间的原子性，你可以把多个变量放在一个对象里来进行 CAS 操作.所以我们可以使用锁或者利用<code>AtomicReference类</code>把多个共享变量合并成一个共享变量来操作。</p>
<h3 id="什么是自旋锁？"><a href="#什么是自旋锁？" class="headerlink" title="什么是自旋锁？"></a>什么是自旋锁？</h3><p>自旋锁（spinlock）：是指当一个线程在获取锁的时候，如果锁已经被其它线程获取，那么该线程将循环等待，然后不断的判断锁是否能够被成功获取，直到获取到锁才会退出循环。</p>
<p>获取锁的线程一直处于活跃状态，但是并没有执行任何有效的任务，使用这种锁会造成<a href="https://en.wikipedia.org/wiki/Busy_waiting" target="_blank" rel="noopener">busy-waiting</a>。</p>
<p>它是为实现保护共享资源而提出一种锁机制。其实，自旋锁与互斥锁比较类似，它们都是为了解决对某项资源的互斥使用。无论是互斥锁，还是自旋锁，在任何时刻，最多只能有一个保持者，也就说，在任何时刻最多只能有一个执行单元获得锁。但是两者在调度机制上略有不同。对于互斥锁，如果资源已经被占用，资源申请者只能进入睡眠状态。但是自旋锁不会引起调用者睡眠，如果自旋锁已经被别的执行单元保持，调用者就一直循环在那里看是否该自旋锁的保持者已经释放了锁，”自旋”一词就是因此而得名。</p>
<h3 id="Java如何实现自旋锁？"><a href="#Java如何实现自旋锁？" class="headerlink" title="Java如何实现自旋锁？"></a>Java如何实现自旋锁？</h3><p>下面是个简单的例子：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">SpinLock</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> AtomicReference&lt;Thread&gt; cas = <span class="keyword">new</span> AtomicReference&lt;Thread&gt;();</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">lock</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        Thread current = Thread.currentThread();</span><br><span class="line">        <span class="comment">// 利用CAS</span></span><br><span class="line">        <span class="keyword">while</span> (!cas.compareAndSet(<span class="keyword">null</span>, current)) &#123;</span><br><span class="line">            <span class="comment">// DO nothing</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">unlock</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        Thread current = Thread.currentThread();</span><br><span class="line">        cas.compareAndSet(current, <span class="keyword">null</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;<span class="number">1234567891011121314</span></span><br></pre></td></tr></table></figure>
<p>lock（)方法利用的CAS，当第一个线程A获取锁的时候，能够成功获取到，不会进入while循环，如果此时线程A没有释放锁，另一个线程B又来获取锁，此时由于不满足CAS，所以就会进入while循环，不断判断是否满足CAS，直到A线程调用unlock方法释放了该锁。</p>
<h3 id="自旋锁存在的问题"><a href="#自旋锁存在的问题" class="headerlink" title="自旋锁存在的问题"></a>自旋锁存在的问题</h3><ol>
<li>如果某个线程持有锁的时间过长，就会导致其它等待获取锁的线程进入循环等待，消耗CPU。使用不当会造成CPU使用率极高。</li>
<li>上面Java实现的自旋锁不是公平的，即无法满足等待时间最长的线程优先获取锁。不公平的锁就会存在“线程饥饿”问题。</li>
</ol>
<h3 id="自旋锁的优点"><a href="#自旋锁的优点" class="headerlink" title="自旋锁的优点"></a>自旋锁的优点</h3><ol>
<li><p>自旋锁不会使线程状态发生切换，一直处于用户态，即线程一直都是active的；不会使线程进入阻塞状态，减少了不必要的上下文切换，执行速度快</p>
</li>
<li><p>非自旋锁在获取不到锁的时候会进入阻塞状态，从而进入内核态，当获取到锁的时候需要从内核态恢复，需要线程上下文切换。 （线程被阻塞后便进入内核（Linux）调度状态，这个会导致系统在用户态与内核态之间来回切换，严重影响锁的性能）</p>
</li>
</ol>
<h3 id="TicketLock主要解决的是公平性的问题。"><a href="#TicketLock主要解决的是公平性的问题。" class="headerlink" title="TicketLock主要解决的是公平性的问题。"></a>TicketLock主要解决的是公平性的问题。</h3><p>思路：每当有线程获取锁的时候，就给该线程分配一个递增的id，我们称之为排队号，同时，锁对应一个服务号，每当有线程释放锁，服务号就会递增，此时如果服务号与某个线程排队号一致，那么该线程就获得锁，由于排队号是递增的，所以就保证了最先请求获取锁的线程可以最先获取到锁，就实现了公平性。</p>
<p>可以想象成银行办理业务排队，排队的每一个顾客都代表一个需要请求锁的线程，而银行服务窗口表示锁，每当有窗口服务完成就把自己的服务号加一，此时在排队的所有顾客中，只有自己的排队号与服务号一致的才可以得到服务。</p>
<h3 id="偏向锁"><a href="#偏向锁" class="headerlink" title="偏向锁"></a>偏向锁</h3><p>Java偏向锁(Biased Locking)是Java6引入的一项多线程优化。<br>偏向锁，顾名思义，它会偏向于第一个访问锁的线程，如果在运行过程中，同步锁只有一个线程访问，不存在多线程争用的情况，则线程是不需要触发同步的，这种情况下，就会给线程加一个偏向锁。<br><strong>如果在运行过程中，遇到了其他线程抢占锁，则持有偏向锁的线程会被挂起，JVM会消除它身上的偏向锁，将锁恢复到标准的轻量级锁。</strong></p>
<p>它通过消除资源无竞争情况下的同步原语，进一步提高了程序的运行性能。</p>
<h4 id="偏向锁的实现"><a href="#偏向锁的实现" class="headerlink" title="偏向锁的实现"></a>偏向锁的实现</h4><p>偏向锁获取过程：</p>
<ol>
<li>访问Mark Word中偏向锁的标识是否设置成1，锁标志位是否为01，确认为可偏向状态。</li>
<li>如果为可偏向状态，则测试线程ID是否指向当前线程，如果是，进入步骤5，否则进入步骤3。</li>
<li>如果线程ID并未指向当前线程，则通过CAS操作竞争锁。如果竞争成功，则将Mark Word中线程ID设置为当前线程ID，然后执行5；如果竞争失败，执行4。</li>
<li>如果CAS获取偏向锁失败，则表示有竞争。当到达全局安全点（safepoint）时获得偏向锁的线程被挂起，偏向锁升级为轻量级锁，然后被阻塞在安全点的线程继续往下执行同步代码。（撤销偏向锁的时候会导致stop the word）</li>
<li>执行同步代码。</li>
</ol>
<p>注意：第四步中到达安全点safepoint会导致stop the word，时间很短。</p>
<h4 id="偏向锁的释放："><a href="#偏向锁的释放：" class="headerlink" title="偏向锁的释放："></a>偏向锁的释放：</h4><p>偏向锁的撤销在上述第四步骤中有提到。偏向锁只有遇到其他线程尝试竞争偏向锁时，持有偏向锁的线程才会释放锁，<strong>线程不会主动去释放偏向锁。</strong>偏向锁的撤销，需要等待全局安全点（在这个时间点上没有字节码正在执行），它会首先暂停拥有偏向锁的线程，判断锁对象是否处于被锁定状态，撤销偏向锁后恢复到未锁定（标志位为“01”）或轻量级锁（标志位为“00”）的状态。</p>
<h4 id="偏向锁的适用场景"><a href="#偏向锁的适用场景" class="headerlink" title="偏向锁的适用场景"></a>偏向锁的适用场景</h4><p>始终只有一个线程在执行同步块，在它没有执行完释放锁之前，没有其它线程去执行同步块，在锁无竞争的情况下使用，一旦有了竞争就升级为轻量级锁，升级为轻量级锁的时候需要撤销偏向锁，撤销偏向锁的时候会导致stop the word操作；<br>在有锁的竞争时，偏向锁会多做很多额外操作，尤其是撤销偏向所的时候会导致进入安全点，安全点会导致stw，导致性能下降，这种情况下应当禁用； </p>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><h3 id="自旋锁"><a href="#自旋锁" class="headerlink" title="自旋锁"></a>自旋锁</h3><p>线程的阻塞和唤醒需要CPU从用户态转为核心态，频繁的阻塞和唤醒对CPU来说是一件负担很重的工作。同时我们可以发现，很多对象锁的锁定状态只会持续很短的一段时间，例如整数的自加操作，在很短的时间内阻塞并唤醒线程显然不值得，为此引入了自旋锁。</p>
<p>所谓“自旋”，就是让线程去执行一个无意义的循环，循环结束后再去重新竞争锁，如果竞争不到继续循环，循环过程中线程会一直处于running状态，但是基于JVM的线程调度，会出让时间片，所以其他线程依旧有申请锁和释放锁的机会。</p>
<p>自旋锁省去了阻塞锁的时间空间（队列的维护等）开销，但是长时间自旋就变成了“忙式等待”，忙式等待显然还不如阻塞锁。所以自旋的次数一般控制在一个范围内，例如10,100等，在超出这个范围后，自旋锁会升级为阻塞锁。（即从轻量级锁转变为重量级锁）</p>
<h3 id="轻量级锁"><a href="#轻量级锁" class="headerlink" title="轻量级锁"></a>轻量级锁</h3><p>加锁</p>
<p>线程在执行同步块之前，JVM会先在当前线程的栈桢中创建用于存储锁记录的空间，并将对象头中的Mark Word复制到锁记录中，官方称为Displaced Mark Word。<strong>然后线程尝试使用CAS将对象头中的Mark Word替换为指向锁记录的指针。如果成功，当前线程获得锁，如果失败，则自旋获取锁，当自旋获取锁仍然失败时，表示存在其他线程竞争锁(两条或两条以上的线程竞争同一个锁)，则轻量级锁会膨胀成重量级锁。</strong></p>
<p>解锁</p>
<p><strong>轻量级解锁时，会使用原子的CAS操作来将Displaced Mark Word替换回到对象头，如果成功，则表示同步过程已完成。</strong>如果失败，表示有其他线程尝试过获取该锁，则要在释放锁的同时唤醒被挂起的线程。</p>
<h3 id="重量级锁"><a href="#重量级锁" class="headerlink" title="重量级锁"></a>重量级锁</h3><p>重量锁在JVM中又叫对象监视器（Monitor），它很像C中的Mutex，除了具备Mutex(0|1)互斥的功能，它还负责实现了Semaphore(信号量)的功能，也就是说它至少包含一个竞争锁的队列，和一个信号阻塞队列（wait队列），前者负责做互斥，后一个用于做线程同步。</p>
<p><strong>如果说轻量级锁是在无竞争的情况下使用CAS操作去消除同步使用的互斥量，那偏向锁就是在无竞争的情况下把整个同步都消除掉，连CAS都不做了。</strong></p>
<h1 id="ConcurrentHashMap"><a href="#ConcurrentHashMap" class="headerlink" title="ConcurrentHashMap"></a>ConcurrentHashMap</h1><h2 id="JDk7版本"><a href="#JDk7版本" class="headerlink" title="JDk7版本"></a>JDk7版本</h2><ul>
<li><p>ConcurrentHashMap的锁分段技术可有效提升并发访问率</p>
<p>HashTable容器在竞争激烈的并发环境下表现出效率低下的原因是所有访问HashTable的线程都必须竞争同一把锁，假如容器中有多把锁，每一个把锁用于锁容器其中一部分数据，那么当多线程访问容器里不同数据段的数据时，线程间就不会存在锁竞争，从而可以有效提高并发访问效率，这就是ConcurrentHashMap所使用的锁分段技术。首先将数据分为一段一段地存储，然后给每一段数据配一把锁，当一个线程占用锁访问其中一个段数据的时候，其他段的数据也能够别其他数据访问。</p>
</li>
</ul>
<h3 id="ConcurrentHashMap的结构"><a href="#ConcurrentHashMap的结构" class="headerlink" title="ConcurrentHashMap的结构"></a>ConcurrentHashMap的结构</h3><p>ConcurrentHashMap是由Segment数组结构和HashEntry数组结构组成。Segment是一种可重入锁（ReentrantLock），在ConcurrentHashMap里扮演锁的角色；HashEntry则用于存储键值对数据。Segment的结构和HashMap类似，是一种数组和链表结构。一个Segment里包含一个HashEntry数组，每个HashEntry里是一个链表结构的元素，每个Segment守护着一个HashEntry数组里的元素，当对HashEntry数组的数据进行修改时，必须首先获得与它对应的Segment锁。</p>
<h3 id="get"><a href="#get" class="headerlink" title="get"></a>get</h3><p>JDK1.7的ConcurrentHashMap的get操作是不加锁的，因为在每个Segment中定义的HashEntry数组和在每个HashEntry中定义的value和next HashEntry节点都是volatile类型的，volatile类型的变量可以保证其在多线程之间的可见性，因此可以被多个线程同时读，从而不用加锁。而其get操作步骤也比较简单，定位Segment –&gt; 定位HashEntry –&gt; 通过getObjectVolatile()方法获取指定偏移量上的HashEntry –&gt; 通过循环遍历链表获取对应值。</p>
<p>定位Segment：(((h &gt;&gt;&gt; segmentShift) &amp; segmentMask) &lt;&lt; SSHIFT) + SBASE</p>
<p>定位HashEntry：(((tab.length - 1) &amp; h)) &lt;&lt; TSHIFT) + TBASE</p>
<h3 id="put"><a href="#put" class="headerlink" title="put"></a>put</h3><p>在Segment的put方法中，首先需要调用tryLock()方法获取锁，然后通过hash算法定位到对应的HashEntry，然后遍历整个链表，如果查到key值，则直接插入元素即可；而如果没有查询到对应的key，则需要调用rehash()方法对Segment中保存的table进行扩容，扩容为原来的2倍，并在扩容之后插入对应的元素。插入一个key/value对后，需要将统计Segment中元素个数的count属性加1。最后，插入成功之后，需要使用unLock()释放锁。</p>
<h2 id="JDK8版本"><a href="#JDK8版本" class="headerlink" title="JDK8版本"></a>JDK8版本</h2><p>在JDK1.7之前，ConcurrentHashMap是通过分段锁机制来实现的，所以其最大并发度受Segment的个数限制。因此，在JDK1.8中，ConcurrentHashMap的实现原理摒弃了这种设计，而是选择了与HashMap类似的数组+链表+红黑树的方式实现，而加锁则采用CAS和synchronized实现。</p>
<h3 id="数据结构"><a href="#数据结构" class="headerlink" title="数据结构"></a>数据结构</h3><p>JDK1.8的ConcurrentHashMap数据结构比JDK1.7之前的要简单的多，其使用的是HashMap一样的数据结构：数组+链表+红黑树。ConcurrentHashMap中包含一个table数组，其类型是一个Node数组；而Node是一个继承自Map.Entry&lt;K, V&gt;的链表，而当这个链表结构中的数据大于8，则将数据结构升级为TreeBin类型的红黑树结构。另外，</p>
<p>JDK1.8中的ConcurrentHashMap中还包含一个重要属性sizeCtl，其是一个控制标识符，不同的值代表不同的意思：其为0时，表示hash表还未初始化，而为正数时这个数值表示初始化或下一次扩容的大小，相当于一个阈值；即如果hash表的实际大小&gt;=sizeCtl，则进行扩容，默认情况下其是当前ConcurrentHashMap容量的0.75倍；而如果sizeCtl为-1，表示正在进行初始化操作；而为-N时，则表示有N-1个线程正在进行扩容。</p>
<h2 id="源码"><a href="#源码" class="headerlink" title="源码"></a>源码</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//内部类node里的val，next都使用了volatile关键字</span></span><br><span class="line"><span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">Node</span>&lt;<span class="title">K</span>,<span class="title">V</span>&gt; <span class="keyword">implements</span> <span class="title">Map</span>.<span class="title">Entry</span>&lt;<span class="title">K</span>,<span class="title">V</span>&gt; </span>&#123;</span><br><span class="line">        <span class="keyword">final</span> <span class="keyword">int</span> hash;</span><br><span class="line">        <span class="keyword">final</span> K key;</span><br><span class="line">        <span class="keyword">volatile</span> V val;</span><br><span class="line">        <span class="keyword">volatile</span> Node&lt;K,V&gt; next;</span><br><span class="line"></span><br><span class="line">        Node(<span class="keyword">int</span> hash, K key, V val, Node&lt;K,V&gt; next) &#123;</span><br><span class="line">            <span class="keyword">this</span>.hash = hash;</span><br><span class="line">            <span class="keyword">this</span>.key = key;</span><br><span class="line">            <span class="keyword">this</span>.val = val;</span><br><span class="line">            <span class="keyword">this</span>.next = next;</span><br><span class="line">        &#125;</span><br><span class="line"> &#125;</span><br><span class="line"><span class="comment">// 使用node数组， 也是用volatile数组</span></span><br><span class="line"><span class="keyword">transient</span> <span class="keyword">volatile</span> Node&lt;K,V&gt;[] table;</span><br></pre></td></tr></table></figure>
<p><strong>get方法同1.7的一致，由于node都是使用volatile修饰，在get的源码实现中，并不用加锁。</strong></p>
<h2 id="SQL注入简介"><a href="#SQL注入简介" class="headerlink" title="SQL注入简介"></a>SQL注入简介</h2><p>SQL注入是网站存在最多也是最简单的漏洞，主要原因是程序员在开发用户和数据库交互的系统时，没有对用户输入的字符串进行过滤，转义，限制或处理不严谨，导致用户可以通过输入精心构造的字符串去非法获取到数据库中的数据。</p>
<h3 id="SQL注入原理"><a href="#SQL注入原理" class="headerlink" title="SQL注入原理"></a>SQL注入原理</h3><p>一般用户登录用的SQL语句为：SELECT <em> FROM user WHERE username=’admin’ AND password=’passwd’，此处admin和passwd分别为用户输入的用户名和密码，如果程序员没有对用户输入的用户名和密码做处理，就可以构造万能密码成功绕过登录验证，如用户输入<strong>‘or 1#</strong>,SQL语句将变为：SELECT </em> FROM user WHERE username=’’or 1#’ AND password=’’，‘’or 1为TRUE，#注释掉后面的内容，所以查询语句可以正确执行。</p>
<h3 id="mybatis是如何防止SQL注入的"><a href="#mybatis是如何防止SQL注入的" class="headerlink" title="mybatis是如何防止SQL注入的"></a>mybatis是如何防止SQL注入的</h3><h3 id="1、首先看一下下面两个sql语句的区别："><a href="#1、首先看一下下面两个sql语句的区别：" class="headerlink" title="1、首先看一下下面两个sql语句的区别："></a>1、首先看一下下面两个sql语句的区别：</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;select id="selectByNameAndPassword" parameterType="java.util.Map" resultMap="BaseResultMap"&gt;</span><br><span class="line"><span class="keyword">select</span> <span class="keyword">id</span>, username, <span class="keyword">password</span>, <span class="keyword">role</span></span><br><span class="line"><span class="keyword">from</span> <span class="keyword">user</span></span><br><span class="line"><span class="keyword">where</span> username = <span class="comment">#&#123;username,jdbcType=VARCHAR&#125;</span></span><br><span class="line"><span class="keyword">and</span> <span class="keyword">password</span> = <span class="comment">#&#123;password,jdbcType=VARCHAR&#125;</span></span><br><span class="line">&lt;/<span class="keyword">select</span>&gt;</span><br></pre></td></tr></table></figure>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;select id="selectByNameAndPassword" parameterType="java.util.Map" resultMap="BaseResultMap"&gt;</span><br><span class="line"><span class="keyword">select</span> <span class="keyword">id</span>, username, <span class="keyword">password</span>, <span class="keyword">role</span></span><br><span class="line"><span class="keyword">from</span> <span class="keyword">user</span></span><br><span class="line"><span class="keyword">where</span> username = $&#123;username,jdbcType=<span class="built_in">VARCHAR</span>&#125;</span><br><span class="line"><span class="keyword">and</span> <span class="keyword">password</span> = $&#123;<span class="keyword">password</span>,jdbcType=<span class="built_in">VARCHAR</span>&#125;</span><br><span class="line">&lt;/<span class="keyword">select</span>&gt;</span><br></pre></td></tr></table></figure>
<p><strong>mybatis中的#和$的区别：</strong></p>
<p>1、#将传入的数据都当成一个字符串，会对自动传入的数据加一个双引号。<br>如：where username=#{username}，如果传入的值是111,那么解析成sql时的值为where username=”111”, 如果传入的值是id，则解析成的sql为where username=”id”.　<br>2、$将传入的数据直接显示生成在sql中。<br>如：where username=${username}，如果传入的值是111,那么解析成sql时的值为where username=111；<br>如果传入的值是;drop table user;，则解析成的sql为：select id, username, password, role from user where username=;drop table user;<br>3、#方式能够很大程度防止sql注入，$方式无法防止Sql注入。<br>4、$方式一般用于传入数据库对象，例如传入表名.<br>5、一般能用#的就别用$，若不得不使用“${xxx}”这样的参数，要手工地做好过滤工作，来防止sql注入攻击。<br>6、在MyBatis中，“${xxx}”这样格式的参数会直接参与SQL编译，从而不能避免注入攻击。但涉及到动态表名和列名时，只能使用“${xxx}”这样的参数格式。所以，这样的参数需要我们在代码中手工进行处理来防止注入。<br>【结论】在编写MyBatis的映射语句时，尽量采用“#{xxx}”这样的格式。若不得不使用“${xxx}”这样的参数，要手工地做好过滤工作，来防止SQL注入攻击。</p>
<h3 id="2、什么是sql注入"><a href="#2、什么是sql注入" class="headerlink" title="2、什么是sql注入"></a>2、什么是sql注入</h3><p>　　<a href="https://en.wikipedia.org/wiki/SQL_injection" target="_blank" rel="noopener"> sql注入解释</a>：是一种代码注入技术，用于攻击数据驱动的应用，恶意的SQL语句被插入到执行的实体字段中（例如，为了转储数据库内容给攻击者）</p>
<p>　　<strong>SQL**</strong>注入<strong>，大家都不陌生，是一种常见的攻击方式。</strong>攻击者<strong>在界面的表单信息或URL上输入一些奇怪的SQL片段（例如“or ‘1’=’1’”这样的语句），有可能入侵</strong>参数检验不足<strong>的应用程序。所以，在我们的应用中需要做一些工作，来防备这样的攻击方式。在一些安全性要求很高的应用中（比如银行软件），经常使用将</strong>SQL<strong>**语句</strong>全部替换为<strong>存储过程</strong>这样的方式，来防止SQL注入。这当然是<strong>一种很安全的方式</strong>，但我们平时开发中，可能不需要这种死板的方式。</p>
<h3 id="3、mybatis是如何做到防止sql注入的"><a href="#3、mybatis是如何做到防止sql注入的" class="headerlink" title="3、mybatis是如何做到防止sql注入的"></a>3、mybatis是如何做到防止sql注入的</h3><p>　　<a href="https://mybatis.github.io/mybatis-3/" target="_blank" rel="noopener">MyBatis</a>框架作为一款半自动化的持久层框架，其SQL语句都要我们自己手动编写，这个时候当然需要防止SQL注入。其实，MyBatis的SQL是一个具有“<strong>输入+输出</strong>”的功能，类似于函数的结构，参考上面的两个例子。其中，parameterType表示了输入的参数类型，resultType表示了输出的参数类型。回应上文，如果我们想防止SQL注入，理所当然地要在输入参数上下功夫。上面代码中使用 <strong>#</strong> 的即输入参数在SQL中拼接的部分，传入参数后，打印出执行的SQL语句，会看到SQL是这样的：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select id, username, password, role from user where username=? and password=?</span><br></pre></td></tr></table></figure>
<p>　　不管输入什么参数，打印出的SQL都是这样的。这是因为MyBatis启用了预编译功能，在SQL执行前，会先将上面的SQL发送给数据库进行编译；执行时，直接使用编译好的SQL，替换占位符“?”就可以了。因为SQL注入只能对编译过程起作用，所以这样的方式就很好地避免了SQL注入的问题。</p>
<p>　　【底层实现原理】MyBatis是如何做到SQL预编译的呢？其实在框架底层，是JDBC中的PreparedStatement类在起作用，PreparedStatement是我们很熟悉的Statement的子类，它的对象包含了编译好的SQL语句。这种“准备好”的方式不仅能提高安全性，而且在多次执行同一个SQL时，能够提高效率。原因是SQL已编译好，再次执行时无需再编译。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">//安全的，预编译了的</span><br><span class="line">Connection conn = getConn();//获得连接</span><br><span class="line">String sql = &quot;select id, username, password, role from user where id=?&quot;; //执行sql前会预编译号该条语句</span><br><span class="line">PreparedStatement pstmt = conn.prepareStatement(sql); </span><br><span class="line">pstmt.setString(1, id); </span><br><span class="line">ResultSet rs=pstmt.executeUpdate(); </span><br><span class="line">......</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">//不安全的，没进行预编译</span><br><span class="line">private String getNameByUserId(String userId) &#123;</span><br><span class="line">    Connection conn = getConn();//获得连接</span><br><span class="line">    String sql = &quot;select id,username,password,role from user where id=&quot; + id;</span><br><span class="line">    //当id参数为&quot;3;drop table user;&quot;时，执行的sql语句如下:</span><br><span class="line">    //select id,username,password,role from user where id=3; drop table user;  </span><br><span class="line">    PreparedStatement pstmt =  conn.prepareStatement(sql);</span><br><span class="line">    ResultSet rs=pstmt.executeUpdate();</span><br><span class="line">    ......</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>【 <strong>结论</strong>：】</p>
<table>
<thead>
<tr>
<th>#{}：相当于JDBC中的PreparedStatement</th>
</tr>
</thead>
<tbody>
<tr>
<td>${}：是输出变量的值</td>
</tr>
</tbody>
</table>
<p>简单说，#{}是经过预编译的，是安全的；${}是未经过预编译的，仅仅是取变量的值，是非安全的，存在SQL注入。<br>如果我们order by语句后用了${}，那么不做任何处理的时候是存在SQL注入危险的。你说怎么防止，那我只能悲惨的告诉你，你得手动处理过滤一下输入的内容。如判断一下输入的参数的长度是否正常（注入语句一般很长），更精确的过滤则可以查询一下输入的参数是否在预期的参数集合中。</p>
<p>作者：<a href="http://www.cnblogs.com/mmzs/" target="_blank" rel="noopener">淼淼之森</a></p>
<p>### </p>
<h2 id="19-09-27"><a href="#19-09-27" class="headerlink" title="19.09.27"></a>19.09.27</h2><p><a href="https://blog.csdn.net/a745233700/article/details/80977133" target="_blank" rel="noopener">mybatis面试题总结</a></p>
<p><a href="https://blog.csdn.net/a745233700/article/details/80977133" target="_blank" rel="noopener">Spring常见面试</a></p>
<h1 id="docker"><a href="#docker" class="headerlink" title="docker"></a>docker</h1><p>Docker 可以让开发者打包他们的应用以及依赖包到一个轻量级、可移植的容器中，然后发布到任何流行的 Linux 机器上，也可以实现虚拟化。</p>
<p><strong>容器虚拟化的是操作系统而不是硬件，容器之间是共享同一套操作系统资源的。虚拟机技术是虚拟出一套硬件后，在其上运行一个完整操作系统。因此容器的隔离级别会稍低一些。</strong></p>
<p>容器是完全使用沙箱机制，相互之间不会有任何接口（类似 iPhone 的 app）,更重要的是容器性能开销极低。</p>
<h1 id="Spring-Security"><a href="#Spring-Security" class="headerlink" title="Spring Security"></a>Spring Security</h1><h3 id="区分认证-Authentication-和授权-Authorization"><a href="#区分认证-Authentication-和授权-Authorization" class="headerlink" title="区分认证 (Authentication) 和授权 (Authorization)"></a>区分认证 (Authentication) 和授权 (Authorization)</h3><p>这是一个绝大多数人都会混淆的问题。首先先从读音上来认识这两个名词，很多人都会把它俩的读音搞混，所以我建议你先先去查一查这两个单词到底该怎么读，他们的具体含义是什么。</p>
<p><strong>Authentication（认证）</strong> 是验证您的身份的凭据（例如用户名/用户ID和密码），通过这个凭据，系统得以知道你就是你，也就是说系统存在你这个用户。所以，Authentication 被称为身份/用户验证。</p>
<p><strong>Authorization（授权）</strong> 发生在 <strong>Authentication（认证）</strong>之后。授权嘛，光看意思大家应该就明白，它主要掌管我们访问系统的权限。比如有些特定资源只能具有特定权限的人才能访问比如admin，有些对系统资源操作比如删除、添加、更新只能特定人才具有。</p>
<p>这两个一般在我们的系统中被结合在一起使用，目的就是为了保护我们系统的安全性。</p>
<h1 id="Redis"><a href="#Redis" class="headerlink" title="Redis"></a>Redis</h1><h3 id="为什么要用-redis-为什么要用缓存"><a href="#为什么要用-redis-为什么要用缓存" class="headerlink" title="为什么要用 redis/为什么要用缓存"></a>为什么要用 redis/为什么要用缓存</h3><p>主要从“高性能”和“高并发”这两点来看待这个问题。</p>
<p><strong>高性能：</strong></p>
<p>假如用户第一次访问数据库中的某些数据。这个过程会比较慢，因为是从硬盘上读取的。将该用户访问的数据存在缓存中，这样下一次再访问这些数据的时候就可以直接从缓存中获取了。操作缓存就是直接操作内存，所以速度相当快。如果数据库中的对应数据改变的之后，同步改变缓存中相应的数据即可！</p>
<p><img src="http://my-blog-to-use.oss-cn-beijing.aliyuncs.com/18-9-24/54316596.jpg" alt></p>
<p><strong>高并发：</strong></p>
<p>直接操作缓存能够承受的请求是远远大于直接访问数据库的，所以我们可以考虑把数据库中的部分数据转移到缓存中去，这样用户的一部分请求会直接到缓存这里而不用经过数据库。</p>
<p><img src="http://my-blog-to-use.oss-cn-beijing.aliyuncs.com/18-9-24/85146760.jpg" alt></p>
<h3 id="redis-设置过期时间"><a href="#redis-设置过期时间" class="headerlink" title="redis 设置过期时间"></a>redis 设置过期时间</h3><p>Redis中有个设置时间过期的功能，即对存储在 redis 数据库中的值可以设置一个过期时间。作为一个缓存数据库，这是非常实用的。如我们一般项目中的 token 或者一些登录信息，尤其是短信验证码都是有时间限制的，按照传统的数据库处理方式，一般都是自己判断过期，这样无疑会严重影响项目性能。</p>
<p>我们 set key 的时候，都可以给一个 expire time，就是过期时间，通过过期时间我们可以指定这个 key 可以存活的时间。</p>
<p>如果假设你设置了一批 key 只能存活1个小时，那么接下来1小时后，redis是怎么对这批key进行删除的？</p>
<p><strong>定期删除+惰性删除。</strong></p>
<p>通过名字大概就能猜出这两个删除方式的意思了。</p>
<ul>
<li><strong>定期删除</strong>：redis默认是每隔 100ms 就<strong>随机抽取</strong>一些设置了过期时间的key，检查其是否过期，如果过期就删除。注意这里是随机抽取的。为什么要随机呢？你想一想假如 redis 存了几十万个 key ，每隔100ms就遍历所有的设置过期时间的 key 的话，就会给 CPU 带来很大的负载！</li>
<li><strong>惰性删除</strong> ：定期删除可能会导致很多过期 key 到了时间并没有被删除掉。所以就有了惰性删除。假如你的过期 key，靠定期删除没有被删除掉，还停留在内存里，除非你的系统去查一下那个 key，才会被redis给删除掉。这就是所谓的惰性删除，也是够懒的哈！</li>
</ul>
<p>但是仅仅通过设置过期时间还是有问题的。我们想一下：如果定期删除漏掉了很多过期 key，然后你也没及时去查，也就没走惰性删除，此时会怎么样？如果大量过期key堆积在内存里，导致redis内存块耗尽了。怎么解决这个问题呢？ <strong>redis 内存淘汰机制。</strong></p>
<h3 id="redis-持久化机制-怎么保证-redis-挂掉之后再重启数据可以进行恢复"><a href="#redis-持久化机制-怎么保证-redis-挂掉之后再重启数据可以进行恢复" class="headerlink" title="redis 持久化机制(怎么保证 redis 挂掉之后再重启数据可以进行恢复)"></a>redis 持久化机制(怎么保证 redis 挂掉之后再重启数据可以进行恢复)</h3><p>很多时候我们需要持久化数据也就是将内存中的数据写入到硬盘里面，大部分原因是为了之后重用数据（比如重启机器、机器故障之后恢复数据），或者是为了防止系统故障而将数据备份到一个远程位置。</p>
<p>Redis不同于Memcached的很重一点就是，Redis支持持久化，而且支持两种不同的持久化操作。<strong>Redis的一种持久化方式叫快照（snapshotting，RDB），另一种方式是只追加文件（append-only file,AOF）</strong>。这两种方法各有千秋，下面我会详细这两种持久化方法是什么，怎么用，如何选择适合自己的持久化方法。</p>
<p><strong>快照（snapshotting）持久化（RDB）</strong></p>
<p>Redis可以通过创建快照来获得存储在内存里面的数据在某个时间点上的副本。Redis创建快照之后，可以对快照进行备份，可以将快照复制到其他服务器从而创建具有相同数据的服务器副本（Redis主从结构，主要用来提高Redis性能），还可以将快照留在原地以便重启服务器的时候使用。</p>
<p>快照持久化是Redis默认采用的持久化方式，在redis.conf配置文件中默认有此下配置：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">save 900 1           #在900秒(15分钟)之后，如果至少有1个key发生变化，Redis就会自动触发BGSAVE命令创建快照。</span><br><span class="line"></span><br><span class="line">save 300 10          #在300秒(5分钟)之后，如果至少有10个key发生变化，Redis就会自动触发BGSAVE命令创建快照。</span><br><span class="line"></span><br><span class="line">save 60 10000        #在60秒(1分钟)之后，如果至少有10000个key发生变化，Redis就会自动触发BGSAVE命令创建快照。</span><br></pre></td></tr></table></figure>
<p><strong>AOF（append-only file）持久化</strong></p>
<p>与快照持久化相比，AOF持久化 的实时性更好，因此已成为主流的持久化方案。默认情况下Redis没有开启AOF（append only file）方式的持久化，可以通过appendonly参数开启：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">appendonly yes</span><br></pre></td></tr></table></figure>
<p>开启AOF持久化后每执行一条会更改Redis中的数据的命令，Redis就会将该命令写入硬盘中的AOF文件。AOF文件的保存位置和RDB文件的位置相同，都是通过dir参数设置的，默认的文件名是appendonly.aof。</p>
<p>在Redis的配置文件中存在三种不同的 AOF 持久化方式，它们分别是：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">appendfsync always    #每次有数据修改发生时都会写入AOF文件,这样会严重降低Redis的速度</span><br><span class="line">appendfsync everysec  #每秒钟同步一次，显示地将多个写命令同步到硬盘</span><br><span class="line">appendfsync no        #让操作系统决定何时进行同步</span><br></pre></td></tr></table></figure>
<p>为了兼顾数据和写入性能，用户可以考虑 appendfsync everysec选项 ，让Redis每秒同步一次AOF文件，Redis性能几乎没受到任何影响。而且这样即使出现系统崩溃，用户最多只会丢失一秒之内产生的数据。当硬盘忙于执行写入操作的时候，Redis还会优雅的放慢自己的速度以便适应硬盘的最大写入速度。</p>
<p><strong>Redis 4.0 对于持久化机制的优化</strong></p>
<p>Redis 4.0 开始支持 RDB 和 AOF 的混合持久化（默认关闭，可以通过配置项 <code>aof-use-rdb-preamble</code> 开启）。</p>
<p>如果把混合持久化打开，AOF 重写的时候就直接把 RDB 的内容写到 AOF 文件开头。这样做的好处是可以结合 RDB 和 AOF 的优点, 快速加载同时避免丢失过多的数据。当然缺点也是有的， AOF 里面的 RDB 部分是压缩格式不再是 AOF 格式，可读性较差。</p>
<h3 id="缓存雪崩和缓存穿透问题解决方案"><a href="#缓存雪崩和缓存穿透问题解决方案" class="headerlink" title="缓存雪崩和缓存穿透问题解决方案"></a>缓存雪崩和缓存穿透问题解决方案</h3><p><strong>缓存雪崩</strong></p>
<p>简介：缓存同一时间大面积的失效，所以，后面的请求都会落到数据库上，造成数据库短时间内承受大量请求而崩掉。</p>
<p>解决办法（中华石杉老师在他的视频中提到过，视频地址在最后一个问题中有提到）：</p>
<ul>
<li>事前：尽量保证整个 redis 集群的高可用性，发现机器宕机尽快补上。选择合适的内存淘汰策略。</li>
<li>事中：本地ehcache缓存 + hystrix限流&amp;降级，避免MySQL崩掉</li>
<li>事后：利用 redis 持久化机制保存的数据尽快恢复缓存</li>
</ul>
<p><img src="http://my-blog-to-use.oss-cn-beijing.aliyuncs.com/18-9-25/6078367.jpg" alt="img"></p>
<p><strong>缓存穿透</strong></p>
<p>简介：一般是黑客故意去请求缓存中不存在的数据，导致所有的请求都落到数据库上，造成数据库短时间内承受大量请求而崩掉。</p>
<p>解决办法： 有很多种方法可以有效地解决缓存穿透问题，最常见的则是采用布隆过滤器，将所有可能存在的数据哈希到一个足够大的bitmap中，一个一定不存在的数据会被 这个bitmap拦截掉，从而避免了对底层存储系统的查询压力。另外也有一个更为简单粗暴的方法（我们采用的就是这种），如果一个查询返回的数据为空（不管是数 据不存在，还是系统故障），我们仍然把这个空结果进行缓存，但它的过期时间会很短，最长不超过五分钟。</p>
<h1 id="ThreadLocal"><a href="#ThreadLocal" class="headerlink" title="ThreadLocal"></a>ThreadLocal</h1><p><img src="https://images0.cnblogs.com/blog/288799/201408/241109342846403.jpg" alt></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/09/10/计算机网络/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Chen ZeTao">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/weixin.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="ddd `Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/09/10/计算机网络/" itemprop="url">计算机网络</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-09-10T21:49:01+08:00">
                2019-09-10
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/复习/" itemprop="url" rel="index">
                    <span itemprop="name">复习</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  1.9k
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  6
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="OSI参考模型"><a href="#OSI参考模型" class="headerlink" title="OSI参考模型"></a>OSI参考模型</h2><h3 id="OSI参考模型结构包括以下7层：物理层，数据链路层，网络层，传输层，会话层，表示层和应用层。"><a href="#OSI参考模型结构包括以下7层：物理层，数据链路层，网络层，传输层，会话层，表示层和应用层。" class="headerlink" title="OSI参考模型结构包括以下7层：物理层，数据链路层，网络层，传输层，会话层，表示层和应用层。"></a>OSI参考模型结构包括以下7层：物理层，数据链路层，网络层，传输层，会话层，表示层和应用层。</h3><ol>
<li>物理层<br>实现比特流的透明传输，为数据链路层提供数据传输服务<br>物理层的数据传输单位是比特（bit）</li>
<li>数据链路层<br>数据链路层在物理层提供比特流传输的基础上，通过建立数据链路连接，采用差错控制与流量控制方法，使有差错的物理线路变成无差错的数据链路。<br>数据链路层的数据传输单位是帧。</li>
<li>网络层<br>网络层通过路由选择算法为分组通过通信子网选择适当的传输路径，实现流量控制，拥塞控制与网络互联的功能。<br>网络层的数据传输功能是分组。</li>
<li>传输层<br>传输层为分布在不同地理位置计算机的进程通信提供可靠的端-端连接与数据传输服务。<br>传输层的数据传输单元是报文。<h2 id="TCP-IP参考模型"><a href="#TCP-IP参考模型" class="headerlink" title="TCP/IP参考模型"></a>TCP/IP参考模型</h2><h3 id="TCP-IP起源"><a href="#TCP-IP起源" class="headerlink" title="TCP/IP起源"></a>TCP/IP起源</h3>目前TCP/IP已经成为公认的Internet工业标准与事实上的Internet协议标准。目前使用的TCP/IP是版本4，即IPv4。<h3 id="TCP-IP参考模型的层次"><a href="#TCP-IP参考模型的层次" class="headerlink" title="TCP/IP参考模型的层次"></a>TCP/IP参考模型的层次</h3><h4 id="主机-网络层"><a href="#主机-网络层" class="headerlink" title="主机-网络层"></a>主机-网络层</h4>与OSI参考模型的数据链路层和物理层对应。TCP/IP协议对主机-网络层并没有规定具体的协议。<h4 id="互联网络层（网络层）-IP"><a href="#互联网络层（网络层）-IP" class="headerlink" title="互联网络层（网络层）(IP)"></a>互联网络层（网络层）(IP)</h4>使用的是IP协议，IP是一种不可控，无连接的数据报传输服务协议，它提供的是一种“尽力而为”的服务。<h4 id="传输层（UDP，TCP）"><a href="#传输层（UDP，TCP）" class="headerlink" title="传输层（UDP，TCP）"></a>传输层（UDP，TCP）</h4>传输层定义两种不同的协议，传输控制层（Transport Control Protocol,TCP）与用户数据报协议（User Datagram Protocol，UDP）。<br>TCP是一种可靠的，面向连接，面向字节流的传输层协议。TCP提供比较完善的流量控制与拥塞控制功能。UDP是一种不可靠的，无连接的传输层协议。<h5 id="TCP（Transmisson-Control-Protocol）"><a href="#TCP（Transmisson-Control-Protocol）" class="headerlink" title="TCP（Transmisson Control Protocol）"></a>TCP（Transmisson Control Protocol）</h5>TCP 是面向连接的（需要先建立连接）；<br>每一条 TCP 连接只能有两个端点，每一条 TCP 连接只能是一对一；<br>TCP提供可靠交付的服务。通过TCP连接传送的数据，无差错、不丢失、不重复、并且按序到达；<br>TCP 提供全双工通信。TCP 允许通信双方的应用进程在任何时候都能发送数据。TCP 连接的两端都设有发送缓存和接收缓存，用来临时存放双方通信的数据；<br>面向字节流。TCP 中的“流”（Stream）指的是流入进程或从进程流出的字节序列。<h5 id="UDP（User-Datagram-Protocol）"><a href="#UDP（User-Datagram-Protocol）" class="headerlink" title="UDP（User Datagram Protocol）"></a>UDP（User Datagram Protocol）</h5>UDP 是无连接的；<br>UDP 是尽最大努力交付，即不保证可靠交付，因此主机不需要维持复杂的链接状态；<br>UDP 是面向报文的；<br>UDP 没有拥塞控制，因此网络出现拥塞不会使源主机的发送速率降低（对实时应用很有用，如直播，实时视频会议等）；<br>UDP 支持一对一、一对多、多对一和多对多的交互通信；<br>UDP 的首部开销小，只有 8 个字节，比 TCP 的 20 个字节的首部要短。</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">1.单工数据传输只支持数据在一个方向上传输</span><br><span class="line">2.半双工数据传输允许数据在两个方向上传输，但是，在某一时刻，只允许数据在一个方向上传输，它实际上是一种切换方向的单工通信；</span><br><span class="line">3.全双工数据通信允许数据同时在两个方向上传输，因此，全双工通信是两个单工通信方式的结合，它要求发送设备和接收设备都有独立的接收和发送能力。</span><br></pre></td></tr></table></figure>
<h4 id="应用层"><a href="#应用层" class="headerlink" title="应用层()"></a>应用层()</h4><p>应用层包括各种标准的网络应用协议，并且总有不断有新的协议加入。<br>TCP/IP应用层基本的协议主要有：</p>
<ol>
<li>远程登录协议（TELNET）</li>
<li>文件传输协议（File Transfer Protocol,FTP）</li>
<li>超文本传输协议（HTTP）</li>
<li>域名服务协议（DNS）<h2 id="IPv4协议的基本内容"><a href="#IPv4协议的基本内容" class="headerlink" title="IPv4协议的基本内容"></a>IPv4协议的基本内容</h2><h3 id="IP协议的主要特点"><a href="#IP协议的主要特点" class="headerlink" title="IP协议的主要特点"></a>IP协议的主要特点</h3></li>
<li>IP协议是一种无连接，不可靠的分组传送服务的协议。<ol>
<li>无连接意味着IP协议并不维护IP分组发送后的任何状态信息。每个分组的传输过程是相互独立的。</li>
<li>不可靠意味着IP协议不能保证每个IP分组都能够正确地，不丢失和顺序地到达目的主机。</li>
</ol>
</li>
<li>IP协议是点-点的网络层通信协议。<br>网络层需要在Internet中为通信的两个主机之间寻找一条路径，而这条路径通常是由多个路由器，点-点链路组成。因此，IP协议是针对源主机-路由器，路由器-路由器，路由器-目的主机之间的数据传输的点-点线路的网络层通信协议。<h3 id="IP地址的点分十进制的表示方法"><a href="#IP地址的点分十进制的表示方法" class="headerlink" title="IP地址的点分十进制的表示方法"></a>IP地址的点分十进制的表示方法</h3><strong>“网络号-主机号”的两级IP地址结构。</strong><br>IPv4的地址长度为32位，用点分十进制表示。通常采用x.x.x.x的格式来表示，每个x为8位，每个X的值为0~255.</li>
</ol>
<h3 id="标准IP地址的分类"><a href="#标准IP地址的分类" class="headerlink" title="标准IP地址的分类"></a>标准IP地址的分类</h3><ol>
<li>A类地址<br>A类地址网络号的第一位为0，其余的7位可以分配，<br>0   网络号（7位），主机号（24位）。A类地址共分为大小相同的128（2^7 = 128）,每一块的netID不同。</li>
<li>B类地址<br>B类地址的前两位为10，其余14位可以分配，可分配的网络号为2^14。B类地址的主机号长度为16位。<br>10 网络号（14） 主机号（16位）</li>
<li>C类地址<br>C类地址的前三位为110，其余的21位可以分配。主机号为8位。</li>
<li>D类地址<br>前4位为1110</li>
<li>E类地址<br>前5位为11110。<h3 id="特殊地址形式"><a href="#特殊地址形式" class="headerlink" title="特殊地址形式"></a>特殊地址形式</h3>特殊的IP地址包括以下四种类型</li>
<li>直接广播地址<br>在A类，B类与C类IP地址中，如果主机号是全1，那么这个地址为直接广播地址，路由器将这个分组以广播方式发送给特定网络的所有主机。</li>
<li>受限广播地址<br>32位网络号与主机号为全1的IP地址（255.255.255.255）为受限广播地址。它是用来将一个分组以广播方式发送给本网络中的所有主机。</li>
<li>“这个网络上的特定主机”地址<br>在A类，B类，C类IP地址中，如果网络号是全0（如0.0.0.25），该地址是这个网络上的特定主机地址。<h3 id="划分子网的三级地址结构"><a href="#划分子网的三级地址结构" class="headerlink" title="划分子网的三级地址结构"></a>划分子网的三级地址结构</h3>子网划分的基本思想是：借用主机号的一部分作为子网的子网号，划分出更多的子网IP地址。<h2 id="IPv6地址"><a href="#IPv6地址" class="headerlink" title="IPv6地址"></a>IPv6地址</h2>IPv6的128地址按每16位划分为一个位段，每个位段被转换为一个4位的十六进制数，并用冒号隔开，这种表示法称为“冒号十六进制表示法”。<br><strong>x:x:x:x:x:x:x:x</strong><h3 id="零压缩法"><a href="#零压缩法" class="headerlink" title="零压缩法"></a>零压缩法</h3>双冒号在一个地址中只能出现一次，<br>如何确定双冒号之间被压缩0的位数？可以数一下地址中还有多少个位段，然后用8减去这个数，再将结果乘以16。<br>例如，在地址FF02:3::5中有三个位段，可以根据公式计算：(8-3)*16=80,则 ::表示有80位的二进制数字0被压缩。2</li>
</ol>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/2/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/">1</a><a class="page-number" href="/page/2/">2</a><span class="page-number current">3</span><a class="page-number" href="/page/4/">4</a><span class="space">&hellip;</span><a class="page-number" href="/page/6/">6</a><a class="extend next" rel="next" href="/page/4/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image" src="/images/weixin.jpg" alt="Chen ZeTao">
            
              <p class="site-author-name" itemprop="name">Chen ZeTao</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">56</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">15</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">32</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          

          

          
          

          
          

          

        </div>
      </section>

      

      
        <div class="back-to-top">
          <i class="fa fa-arrow-up"></i>
          
            <span id="scrollpercent"><span>0</span>%</span>
          
        </div>
      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
<div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Chen ZeTao</span>

  
</div>


  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Muse</a> v5.1.4</div>



<div class="powered-by">
<i class="fa fa-user-md"></i><span id="busuanzi_container_site_uv">
  本站访客数:<span id="busuanzi_value_site_uv"></span>
</span>
</div>
<div class="theme-info">
  <div class="powered-by"></div>
  <span class="post-count">博客全站共109.6k字</span>
</div>

        
<div class="busuanzi-count">
  <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  
    <span class="site-uv">
      
      <span class="busuanzi-value" id="busuanzi_value_site_uv"></span>
      
    </span>
  

  
    <span class="site-pv">
      <i class="fa fa-eye"></i> 总访问量
      <span class="busuanzi-value" id="busuanzi_value_site_pv"></span>
      
    </span>
  
</div>








        
      </div>
    </footer>

    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  

  

  
  

  

  

  

  
<script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"debug":false,"model":{"jsonPath":"/live2dw/assets/tororo.model.json"},"display":{"position":"right","width":150,"height":300},"mobile":{"show":true},"react":{"opacity":0.7},"log":false});</script></body>
</html>
